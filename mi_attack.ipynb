{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ae4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"])\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"])\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_28K.csv', na_values=[\"?\"])\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_3K.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d14f7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio):\n",
    "    x, y, dim = transform_data(dataset)\n",
    "    \n",
    "    trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio):\n",
    "    x, y, _ = transform_data(dataset)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio, random_state=0, stratify=shadow_i_y)\n",
    "        #print('shadow_i_trainX = ', trainX, 'shadow_i_trainY = ', trainY)\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_adult{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_adult{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "                \n",
    "\n",
    "        model,_ = build_simple_mlp(n_class,dim,channel)\n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "#     print(\"\\n train predic\", full_sm_train_pred)\n",
    "#     print(\"\\n trian class\", full_sm_train_class)\n",
    "#     print(\"\\n members\", members)\n",
    "#     print(\"\\n nonmembers\", nonmembers)\n",
    "    \n",
    "#     print(\"\\n train class type \", type(full_sm_train_class))\n",
    "\n",
    "    \n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    \n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    \n",
    "    #print('attack dataset\\n', attack_dataset)\n",
    "    \n",
    "    #print(shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers):\n",
    "    memberX, memberY, _ = transform_data(members)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    #print(tra)\n",
    "    \n",
    "\n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "        over_sampler = SMOTE(k_neighbors=2)\n",
    "        full_cx_data, full_cy_data = over_sampler.fit_resample(full_cx_data, full_cy_data)\n",
    "        full_cy_data = to_categorical(full_cy_data)\n",
    "                  \n",
    "        classifier = define_attack_model(2)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        #classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(predict_y)\n",
    "        c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "        #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "        \n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "    #print('Testing Accuracy: {}'.format(accuracy_score(target_membership, predicted_membership)))\n",
    "        \n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall\n",
    "    #return target_membership, predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model test accuracy: 0.8330000042915344\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "(target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio)\n",
    "target_model,_ = build_simple_mlp (n_class,dim,channel)\n",
    "#get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95cd4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "\n",
      " pred (array([[0.70693576, 0.29306433],\n",
      "       [0.9424694 , 0.05753055],\n",
      "       [0.7752704 , 0.22472973],\n",
      "       ...,\n",
      "       [0.82069606, 0.17930397],\n",
      "       [0.48130596, 0.5186939 ],\n",
      "       [0.71933365, 0.28066635]], dtype=float32), array([[9.9954325e-01, 4.5674806e-04],\n",
      "       [9.3452084e-01, 6.5479159e-02],\n",
      "       [9.8139209e-01, 1.8607855e-02],\n",
      "       ...,\n",
      "       [7.9570818e-01, 2.0429181e-01],\n",
      "       [8.5826272e-01, 1.4173722e-01],\n",
      "       [4.0558290e-01, 5.9441704e-01]], dtype=float32))\n",
      "\n",
      " class (array([0, 1, 0, ..., 0, 1, 0]), array([0, 1, 0, ..., 0, 1, 1]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# prepare attack test data\n",
    "\n",
    "members = []\n",
    "nonmembers = []\n",
    "\n",
    "memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers)\n",
    "\n",
    "# member\n",
    "target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "target_model_member_class = np.argmax(memberY, axis=1)\n",
    "target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "#target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "members.append(np.ones(len(target_model_member_pred)))\n",
    "members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "# nonmember\n",
    "target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "#target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "print('\\n pred', full_attack_test_pred_val)\n",
    "print('\\n class', full_attack_test_class_status)\n",
    "print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab68eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save attack test dataset to csv\n",
    "df = pd.DataFrame()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,0])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,0])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "len(total)\n",
    "df['prob_upper_bound'] = total\n",
    "df = df.reset_index()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,1])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,1])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['prob_lower_bound'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_mem_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_mem_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['mem_status'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_class_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_class_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['class_status'] = total\n",
    "\n",
    "df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv('attack_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f2d70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare shadow dataset\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 10000\n",
    "test_ratio = 0.3\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68d46665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  84.42857265472412 Shadow Test acc :  82.89999961853027\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  81.08571171760559 Shadow Test acc :  80.76666593551636\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  84.84285473823547 Shadow Test acc :  84.16666388511658\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  83.60000252723694 Shadow Test acc :  83.89999866485596\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  82.54285454750061 Shadow Test acc :  82.73333311080933\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  75.92856884002686 Shadow Test acc :  75.76666474342346\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  80.47142624855042 Shadow Test acc :  80.33333420753479\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  84.60000157356262 Shadow Test acc :  83.39999914169312\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  83.47142934799194 Shadow Test acc :  80.63333630561829\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  84.01428461074829 Shadow Test acc :  83.03333520889282\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  83.17142724990845 Shadow Test acc :  83.36666822433472\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  83.62857103347778 Shadow Test acc :  82.30000138282776\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  83.82856845855713 Shadow Test acc :  84.0666651725769\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  84.82857346534729 Shadow Test acc :  83.36666822433472\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  85.01428365707397 Shadow Test acc :  84.16666388511658\n",
      "219/219 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  76.01428627967834 Shadow Test acc :  75.99999904632568\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  83.51428508758545 Shadow Test acc :  82.833331823349\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  83.55714082717896 Shadow Test acc :  83.33333134651184\n",
      "219/219 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  83.17142724990845 Shadow Test acc :  83.06666612625122\n",
      "219/219 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  84.21428799629211 Shadow Test acc :  84.13333296775818\n",
      "219/219 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f83f33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[0.99839157, 0.00160839],\n",
       "         [0.02946481, 0.97053516],\n",
       "         [0.58288836, 0.41711167],\n",
       "         ...,\n",
       "         [0.96216667, 0.03783327],\n",
       "         [0.38368672, 0.6163132 ],\n",
       "         [0.9652342 , 0.03476587]], dtype=float32),\n",
       "  array([[0.9946725 , 0.00532741],\n",
       "         [0.86897486, 0.1310251 ],\n",
       "         [0.7484791 , 0.25152078],\n",
       "         ...,\n",
       "         [0.00448923, 0.9955108 ],\n",
       "         [0.9429418 , 0.05705826],\n",
       "         [0.4461082 , 0.5538919 ]], dtype=float32)),\n",
       " (array([1, 1, 1, ..., 1, 1, 1], dtype=int32),\n",
       "  array([0, 0, 0, ..., 0, 0, 0], dtype=int32)),\n",
       " (array([0, 1, 1, ..., 0, 1, 0]), array([0, 0, 0, ..., 1, 0, 1])))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_attack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5f921fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://655eb6c7-6339-41a0-89f4-d5556bdff7e4/assets\n"
     ]
    }
   ],
   "source": [
    "#save the prepared attack data on disk\n",
    "np.savez(DATA_PATH + 'attack_adult_data.npz', n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ef36e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stored attack model training data \n",
    "data_name = 'attack_adult_data.npz'\n",
    "with np.load(DATA_PATH + data_name, allow_pickle=True) as f:\n",
    "        n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = [f['arr_%d' % i] for i in range(len(f.files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e06462e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class0/assets\n",
      "140/140 [==============================] - 0s 1ms/step\n",
      "[[0.70340914]\n",
      " [0.70340914]\n",
      " [0.70340914]\n",
      " ...\n",
      " [0.70340914]\n",
      " [0.70340914]\n",
      " [0.70340914]]\n",
      "Class :  1\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class1/assets\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "[[0.70024896]\n",
      " [0.70024896]\n",
      " [0.70024896]\n",
      " ...\n",
      " [0.70024896]\n",
      " [0.70024896]\n",
      " [0.70024896]]\n"
     ]
    }
   ],
   "source": [
    "#tp, fp, fn, tn, precision, advj, acc, recall, target_membership, predicted_membership, df = train_attack_model(n_attack_data, attack_test_data)\n",
    "target_membership, predicted_membership = train_attack_model(n_attack_data, attack_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25c4181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18687f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba7d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a1b2b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  predicted\n",
       "0          1          1\n",
       "1          1          1\n",
       "2          1          1\n",
       "3          1          1\n",
       "4          1          1\n",
       "...      ...        ...\n",
       "5995       0          1\n",
       "5996       0          1\n",
       "5997       0          1\n",
       "5998       0          1\n",
       "5999       0          1\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84deb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5ab86d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_data = n_attack_data\n",
    "check_membership = attack_test_data\n",
    "n_hidden=50\n",
    "learning_rate=0.01\n",
    "batch_size=200\n",
    "epochs=50\n",
    "model='nn'\n",
    "l2_ratio=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "19720640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,  classes = attack_data\n",
    "\n",
    "train_x = x[0]\n",
    "train_y = y[0]\n",
    "test_x = x[1]\n",
    "test_y = y[1]\n",
    "train_classes = classes[0]\n",
    "test_classes = classes[1]\n",
    "\n",
    "#print(tra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "55e47fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "\n",
    "checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "\n",
    "train_indices = np.arange(len(train_x))\n",
    "test_indices = np.arange(len(test_x))\n",
    "unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "predicted_membership, target_membership = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9285da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class0/assets\n",
      "Class :  1\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class1/assets\n"
     ]
    }
   ],
   "source": [
    "for c in unique_classes:\n",
    "    print(\"Class : \", c)\n",
    "    c_train_indices = train_indices[train_classes == c]\n",
    "    c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "    c_test_indices = test_indices[test_classes == c]\n",
    "    c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "    c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "\n",
    "    full_cx_data=(c_train_x,c_test_x)\n",
    "    full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "    full_cy_data=(c_train_y,c_test_y)\n",
    "    full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "\n",
    "    classifier = define_attack_model(2)\n",
    "    history = classifier.fit(full_cx_data, full_cy_data, epochs=200, batch_size=32, verbose=0)\n",
    "    classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "    #get predictions on real train and test data\n",
    "    #c_indices = np.where(checkmem_class_status==c)\n",
    "    #predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "    #print(predict_y)\n",
    "    #c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "    #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "\n",
    "    #c_target_y = checkmem_membership_status[c_indices]\n",
    "\n",
    "\n",
    "    #target_membership.append(c_target_y)\n",
    "    #predicted_membership.append(c_pred_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3cf72106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "c_indices = np.where(checkmem_class_status==c)\n",
    "predict_y = classifier.predict(checkmem_prediction_vals[c_indices], batch_size=32)\n",
    "c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "c_target_y = checkmem_membership_status[c_indices]\n",
    "target_membership.append(c_target_y)\n",
    "predicted_membership.append(c_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ee134168",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d36d591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1552     FP: 1488     FN: 0     TN: 0\n",
      "PPV: 0.5105\n",
      "Advantage: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1552, 1488, 0, 0, 0.5105263157894737, 0.0, 0.5105263157894737, 1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prety_print_result (target_membership,predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "59dccc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3040, 1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(predicted_membership).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "848224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership.reshape((len(predicted_membership))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "87ea656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  predicted\n",
       "0          1          1\n",
       "1          1          1\n",
       "2          1          1\n",
       "3          1          1\n",
       "4          1          1\n",
       "...      ...        ...\n",
       "3035       0          1\n",
       "3036       0          1\n",
       "3037       0          1\n",
       "3038       0          1\n",
       "3039       0          1\n",
       "\n",
       "[3040 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafc176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
