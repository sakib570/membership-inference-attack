{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ae4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"])\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"])\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_28K.csv', na_values=[\"?\"])\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_3K.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio):\n",
    "    x, y, dim = transform_data(dataset)\n",
    "    \n",
    "    trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio, random_state=0, stratify=shadow_i_y)\n",
    "        #print('shadow_i_trainX = ', trainX, 'shadow_i_trainY = ', trainY)\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_adult{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_adult{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "                \n",
    "\n",
    "        model,_ = build_simple_mlp(n_class,dim,channel)\n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "#     print(\"\\n train predic\", full_sm_train_pred)\n",
    "#     print(\"\\n trian class\", full_sm_train_class)\n",
    "#     print(\"\\n members\", members)\n",
    "#     print(\"\\n nonmembers\", nonmembers)\n",
    "    \n",
    "#     print(\"\\n train class type \", type(full_sm_train_class))\n",
    "\n",
    "    \n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    \n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    \n",
    "    #print('attack dataset\\n', attack_dataset)\n",
    "    \n",
    "    #print(shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers):\n",
    "    memberX, memberY, _ = transform_data(members)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    #print(tra)\n",
    "    \n",
    "\n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "                  \n",
    "        classifier = define_attack_model(2)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(predict_y)\n",
    "        c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "        #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "        \n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "    #print('Testing Accuracy: {}'.format(accuracy_score(target_membership, predicted_membership)))\n",
    "        \n",
    "    #tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    #return tp, fp, fn, tn, precision, advj, acc, recall, target_membership, predicted_membership, df\n",
    "    return target_membership, predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model test accuracy: 0.8366666436195374\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "(target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio)\n",
    "target_model,_ = build_simple_mlp (n_class,dim,channel)\n",
    "#get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "95cd4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 3ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "\n",
      " pred (array([[9.9940217e-01, 5.9780205e-04],\n",
      "       [8.3996409e-01, 1.6003579e-01],\n",
      "       [9.6907687e-01, 3.0923072e-02],\n",
      "       ...,\n",
      "       [4.4473365e-01, 5.5526632e-01],\n",
      "       [7.8718346e-01, 2.1281654e-01],\n",
      "       [9.9999994e-01, 3.5789357e-13]], dtype=float32), array([[9.8666012e-01, 1.3339914e-02],\n",
      "       [5.5249053e-04, 9.9944746e-01],\n",
      "       [4.5886430e-01, 5.4113567e-01],\n",
      "       ...,\n",
      "       [2.6075502e-05, 9.9997383e-01],\n",
      "       [9.9830103e-01, 1.6990970e-03],\n",
      "       [9.9545103e-01, 4.5490172e-03]], dtype=float32))\n",
      "\n",
      " class (array([0, 0, 0, ..., 1, 1, 0]), array([0, 1, 1, ..., 1, 0, 0]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# prepare attack test data\n",
    "\n",
    "members = []\n",
    "nonmembers = []\n",
    "\n",
    "memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers)\n",
    "\n",
    "# member\n",
    "target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "target_model_member_class = np.argmax(memberY, axis=1)\n",
    "target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "#target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "members.append(np.ones(len(target_model_member_pred)))\n",
    "members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "# nonmember\n",
    "target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "#target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "print('\\n pred', full_attack_test_pred_val)\n",
    "print('\\n class', full_attack_test_class_status)\n",
    "print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare shadow dataset\n",
    "n_shadow_models = 10\n",
    "shadow_data_size = 10000\n",
    "test_ratio = 0.3\n",
    "\n",
    "load_shadow_data(shadow_dataset, 10, 10000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d46665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train shadow model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f921fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the prepared attack data on disk\n",
    "np.savez(DATA_PATH + 'attack_adult_data.npz', n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ef36e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stored attack model training data \n",
    "data_name = 'attack_adult_data.npz'\n",
    "with np.load(DATA_PATH + data_name, allow_pickle=True) as f:\n",
    "        n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = [f['arr_%d' % i] for i in range(len(f.files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e06462e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class0/assets\n",
      "140/140 [==============================] - 0s 1ms/step\n",
      "[[0.3053663 0.6946337]\n",
      " [0.3053663 0.6946337]\n",
      " [0.3053663 0.6946337]\n",
      " ...\n",
      " [0.3053663 0.6946337]\n",
      " [0.3053663 0.6946337]\n",
      " [0.3053663 0.6946337]]\n",
      "Class :  1\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class1/assets\n",
      "48/48 [==============================] - 0s 4ms/step\n",
      "[[0.33041537 0.6695846 ]\n",
      " [0.33041537 0.6695846 ]\n",
      " [0.33041537 0.6695846 ]\n",
      " ...\n",
      " [0.33041537 0.6695846 ]\n",
      " [0.33041537 0.6695846 ]\n",
      " [0.33041537 0.6695846 ]]\n"
     ]
    }
   ],
   "source": [
    "#tp, fp, fn, tn, precision, advj, acc, recall, target_membership, predicted_membership, df = train_attack_model(n_attack_data, attack_test_data)\n",
    "target_membership, predicted_membership = train_attack_model(n_attack_data, attack_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "25c4181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "18687f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba7d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a1b2b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  predicted\n",
       "0          1          1\n",
       "1          1          1\n",
       "2          1          1\n",
       "3          1          1\n",
       "4          1          1\n",
       "...      ...        ...\n",
       "5995       0          1\n",
       "5996       0          1\n",
       "5997       0          1\n",
       "5998       0          1\n",
       "5999       0          1\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84deb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5ab86d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_data = n_attack_data\n",
    "check_membership = attack_test_data\n",
    "n_hidden=50\n",
    "learning_rate=0.01\n",
    "batch_size=200\n",
    "epochs=50\n",
    "model='nn'\n",
    "l2_ratio=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "19720640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,  classes = attack_data\n",
    "\n",
    "train_x = x[0]\n",
    "train_y = y[0]\n",
    "test_x = x[1]\n",
    "test_y = y[1]\n",
    "train_classes = classes[0]\n",
    "test_classes = classes[1]\n",
    "\n",
    "#print(tra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "55e47fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "\n",
    "checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "\n",
    "train_indices = np.arange(len(train_x))\n",
    "test_indices = np.arange(len(test_x))\n",
    "unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "predicted_membership, target_membership = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9285da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class0/assets\n",
      "Class :  1\n",
      "INFO:tensorflow:Assets written to: model/attack_model_class1/assets\n"
     ]
    }
   ],
   "source": [
    "for c in unique_classes:\n",
    "    print(\"Class : \", c)\n",
    "    c_train_indices = train_indices[train_classes == c]\n",
    "    c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "    c_test_indices = test_indices[test_classes == c]\n",
    "    c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "    c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "\n",
    "    full_cx_data=(c_train_x,c_test_x)\n",
    "    full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "    full_cy_data=(c_train_y,c_test_y)\n",
    "    full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "\n",
    "    classifier = define_attack_model(2)\n",
    "    history = classifier.fit(full_cx_data, full_cy_data, epochs=200, batch_size=32, verbose=0)\n",
    "    classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "    #get predictions on real train and test data\n",
    "    #c_indices = np.where(checkmem_class_status==c)\n",
    "    #predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "    #print(predict_y)\n",
    "    #c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "    #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "\n",
    "    #c_target_y = checkmem_membership_status[c_indices]\n",
    "\n",
    "\n",
    "    #target_membership.append(c_target_y)\n",
    "    #predicted_membership.append(c_pred_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3cf72106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "c_indices = np.where(checkmem_class_status==c)\n",
    "predict_y = classifier.predict(checkmem_prediction_vals[c_indices], batch_size=32)\n",
    "c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "c_target_y = checkmem_membership_status[c_indices]\n",
    "target_membership.append(c_target_y)\n",
    "predicted_membership.append(c_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ee134168",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d36d591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1552     FP: 1488     FN: 0     TN: 0\n",
      "PPV: 0.5105\n",
      "Advantage: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1552, 1488, 0, 0, 0.5105263157894737, 0.0, 0.5105263157894737, 1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prety_print_result (target_membership,predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "59dccc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3040, 1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(predicted_membership).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "848224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership.reshape((len(predicted_membership))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "87ea656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  predicted\n",
       "0          1          1\n",
       "1          1          1\n",
       "2          1          1\n",
       "3          1          1\n",
       "4          1          1\n",
       "...      ...        ...\n",
       "3035       0          1\n",
       "3036       0          1\n",
       "3037       0          1\n",
       "3038       0          1\n",
       "3039       0          1\n",
       "\n",
       "[3040 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafc176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
