{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3090c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = pd.DataFrame(data.iloc[1:20001,].values)\n",
    "# shadow_dataset = pd.DataFrame(data.iloc[15001:50001,].values)\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[75001:85001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[5001:15001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1378c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_puchase_data(dataset): \n",
    "    df_tot = dataset\n",
    "    df_tot.dropna(inplace=True)\n",
    "\n",
    "    trainX = df_tot.iloc[:,0:dataset.shape[1]-1]\n",
    "    trainY = df_tot.iloc[:,-1]\n",
    "\n",
    "    dim=trainX.shape[1]\n",
    "\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=100\n",
    "\n",
    "    trainX=np.array(trainX)\n",
    "    trainY=np.array(trainY)\n",
    "    \n",
    "    trainY = to_categorical(trainY)\n",
    "\n",
    "\n",
    "    return trainX, trainY, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, train_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_puchase_data(dataset)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:train_size,]\n",
    "    testX = x[14000:,]\n",
    "    trainY = y[0:train_size,]\n",
    "    testY = y[14000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6975c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_purchase_dnn(n_class,dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    #model.add(Dense(1024), kernel_regularizer=l2(0.001))\n",
    "    #model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio, is_synthetic):\n",
    "    x, y, _ = transform_puchase_data(dataset)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_purchase{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_purchase{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_purchase_dnn(n_class,dim)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9025164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "715aa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_train_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3ab0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers, is_synthetic):\n",
    "    memberX, memberY, _ = transform_puchase_data(members)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_puchase_data(nonmembers)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "#         over_sampler = SMOTE(k_neighbors=2)\n",
    "#         full_cx_data, full_cy_data = over_sampler.fit_resample(full_cx_data, full_cy_data)\n",
    "#         full_cy_data = to_categorical(full_cy_data)\n",
    "              \n",
    "        \n",
    "#         classifier = define_attack_model(2)\n",
    "#         history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f3f8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ba5e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, train_size, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, train_size, test_ratio, is_synthetic)\n",
    "    target_model,_ = build_purchase_dnn(n_class,dim)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2142e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic):\n",
    "    members = []\n",
    "    nonmembers = []\n",
    "\n",
    "    memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers, is_synthetic)\n",
    "\n",
    "    # member\n",
    "    target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "    target_model_member_class = np.argmax(memberY, axis=1)\n",
    "    target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "    #target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "    members.append(np.ones(len(target_model_member_pred)))\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "    # nonmember\n",
    "    target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "    target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "    target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "    #target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "    nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "    full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "    full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "    print('\\n pred', full_attack_test_pred_val)\n",
    "    print('\\n class', full_attack_test_class_status)\n",
    "    print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "    attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)\n",
    "    \n",
    "    return attack_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ff8ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aade910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 14000\n",
    "attack_test_size = 10000\n",
    "pur_data = np.load(DATA_PATH+'purchase100.npz')\n",
    "features = pur_data['features']\n",
    "labels = pur_data['labels']\n",
    "data = pd.DataFrame(features[:,:])\n",
    "labels = np.argmax(labels, axis=1)\n",
    "data['600'] = labels\n",
    "\n",
    "target_dataset = data.sample(n = 20000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 35000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[75001:85001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[5001:15001,].values)\n",
    "attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:train_size,:].sample(n = attack_test_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e6497b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77411</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26951</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164214</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38589</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111771</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4  5  6  7  8  9  ...  591  592  593  594  595  596  597  \\\n",
       "191433  0  0  1  1  0  0  1  0  1  1  ...    1    0    0    0    0    1    1   \n",
       "77411   0  1  0  1  0  0  1  0  0  0  ...    0    1    0    0    1    0    0   \n",
       "290     0  0  0  1  0  0  1  0  1  1  ...    0    1    0    1    0    0    0   \n",
       "106275  0  0  0  1  0  0  1  1  0  1  ...    0    0    0    1    0    1    0   \n",
       "26951   0  1  0  1  1  1  1  0  0  1  ...    0    1    0    1    0    0    0   \n",
       "...    .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "83286   0  0  0  1  0  0  0  0  1  1  ...    0    0    0    0    0    0    0   \n",
       "164214  0  1  1  1  1  1  1  1  0  1  ...    0    1    0    0    1    0    0   \n",
       "47867   0  0  0  1  0  0  1  0  0  1  ...    0    0    0    0    0    0    0   \n",
       "38589   0  1  0  1  0  0  1  1  0  0  ...    0    0    0    0    1    0    0   \n",
       "111771  0  0  0  1  1  0  1  1  0  0  ...    1    0    0    1    0    0    0   \n",
       "\n",
       "        598  599  600  \n",
       "191433    1    0   66  \n",
       "77411     0    0   48  \n",
       "290       0    0   18  \n",
       "106275    0    0    8  \n",
       "26951     1    0   44  \n",
       "...     ...  ...  ...  \n",
       "83286     0    0    3  \n",
       "164214    0    0   49  \n",
       "47867     1    0   95  \n",
       "38589     0    0   58  \n",
       "111771    0    0   85  \n",
       "\n",
       "[20000 rows x 601 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  98.64285588264465 Target Test acc :  73.65000247955322\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=50\n",
    "act_layer=6\n",
    "n_class = 100\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3746f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  7.555555552244186\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  14.666666090488434\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  11.55555546283722\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  9.333333373069763\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  9.777777642011642\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  7.555555552244186\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  13.333334028720856\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  11.55555546283722\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  15.111111104488373\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  12.444444745779037\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  11.999999731779099\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  12.444444745779037\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  12.888889014720917\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  9.777777642011642\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  12.444444745779037\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  12.888889014720917\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  9.333333373069763\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  13.777777552604675\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  8.444444090127945\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  13.333334028720856\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 750\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "117d2e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      " pred (array([[4.3964255e-06, 1.6211403e-05, 9.4731413e-06, ..., 3.5881261e-05,\n",
      "        3.5171019e-05, 1.3419745e-05],\n",
      "       [6.2163912e-05, 5.4614480e-05, 3.7005495e-05, ..., 4.7637277e-05,\n",
      "        5.6933015e-05, 3.7106263e-06],\n",
      "       [5.3402640e-05, 2.9141104e-04, 5.2738133e-06, ..., 4.3856632e-04,\n",
      "        1.6920932e-04, 7.9547543e-05],\n",
      "       ...,\n",
      "       [6.1987585e-04, 2.7877140e-05, 1.6566580e-04, ..., 5.0968497e-06,\n",
      "        1.0208837e-06, 5.3073887e-05],\n",
      "       [1.5488193e-05, 8.9001533e-06, 1.0927839e-05, ..., 7.0551664e-06,\n",
      "        1.3671079e-04, 7.0258146e-05],\n",
      "       [1.0156856e-04, 1.6025044e-05, 2.2576368e-04, ..., 2.3320847e-06,\n",
      "        1.9406822e-05, 5.6473091e-06]], dtype=float32), array([[2.3608627e-04, 1.0805344e-04, 9.7918615e-04, ..., 1.8779080e-02,\n",
      "        1.9779841e-03, 1.7132605e-03],\n",
      "       [2.9557839e-04, 6.4444978e-04, 6.8452448e-04, ..., 6.2287464e-03,\n",
      "        2.2831818e-03, 6.2352797e-04],\n",
      "       [1.5649254e-03, 1.0181955e-02, 2.5876463e-04, ..., 3.8854103e-03,\n",
      "        4.4707194e-04, 1.9493268e-03],\n",
      "       ...,\n",
      "       [1.2860597e-03, 2.9580994e-04, 5.0526601e-03, ..., 5.8818076e-02,\n",
      "        4.4236225e-03, 1.1479273e-03],\n",
      "       [2.2047322e-04, 1.7378265e-03, 1.7815235e-03, ..., 2.9971616e-03,\n",
      "        4.1515864e-03, 3.6700550e-04],\n",
      "       [1.1998421e-03, 1.3246150e-01, 5.8242720e-05, ..., 2.5363176e-03,\n",
      "        5.4870552e-04, 7.6697166e-03]], dtype=float32))\n",
      "\n",
      " class (array([55, 84, 65, 26, 15, 38, 20,  5, 22, 39, 34, 92, 33, 13, 34, 92, 97,\n",
      "       83, 18, 60, 82, 60, 79, 28, 12, 56, 81, 10, 61, 47, 57, 26, 75, 27,\n",
      "       99, 72, 56, 13, 74, 48, 40, 66, 14,  5, 55, 14, 52, 39, 41, 42, 38,\n",
      "       90, 30, 14, 17, 75, 53, 53,  7, 90, 40, 48,  2, 42, 22, 47, 18,  9,\n",
      "       18, 44,  3, 53, 38, 97, 58, 69, 21,  6, 17, 11, 26, 96,  4, 69, 22,\n",
      "       79, 26, 95, 98, 58, 22, 68, 77, 57, 18, 15,  6, 63, 27, 69, 68, 49,\n",
      "       63, 78, 32, 68, 12, 56, 14, 84, 59, 85, 52, 89,  9, 22, 15, 52,  5,\n",
      "       49, 49,  4, 80, 53, 13, 15, 74,  5, 22, 17, 34, 36, 44, 72, 33, 33,\n",
      "        0,  4, 36, 55, 82, 80, 54, 46, 13, 77,  8,  2, 10, 50, 93, 41, 44,\n",
      "       33, 76, 22, 68, 50, 30, 36, 66,  3, 57, 26, 84, 15, 89, 30, 41, 48,\n",
      "       30, 63, 16, 96, 67, 34,  0, 91,  2, 90, 99, 57,  2, 70, 14, 38, 60,\n",
      "       19, 92, 60, 86, 14, 18, 23, 39,  0, 45, 14, 17, 43, 97, 95, 99,  8,\n",
      "       49, 97, 50, 62, 23, 80, 49, 51, 22, 17, 10,  4, 59, 99, 40, 75, 90,\n",
      "       68, 54,  2, 97, 80,  1, 57, 26, 97, 82, 36, 99, 37, 52, 68, 44, 45,\n",
      "       13,  0, 80, 18, 63, 87, 73, 63, 38, 28, 39,  8]), array([47, 47, 51, 82, 48, 59, 19, 71, 66, 15, 80, 18, 73, 10, 68, 24, 22,\n",
      "       40, 52, 63, 13,  2, 82, 14, 48, 13, 76,  1, 17, 50, 15, 51,  1, 92,\n",
      "       38, 21,  6, 80, 31, 68, 24, 51, 39, 10, 68, 17, 72, 14, 52, 15, 15,\n",
      "       83, 55, 32, 31, 26, 64, 80, 22, 15, 90, 22,  1, 37,  4, 92,  2, 92,\n",
      "       77, 28, 32, 91, 54, 95, 43, 53, 78, 91, 57, 92, 59,  4, 92, 27, 59,\n",
      "       43, 39, 79,  2, 19, 59, 51, 15, 93, 60, 68, 94,  0, 37, 60, 30, 39,\n",
      "       26, 67, 76, 59, 45, 84, 59, 69, 51, 72, 33, 63, 78, 98, 89, 24, 60,\n",
      "       36, 33, 57,  6, 58, 20, 36,  0, 79, 18, 64, 31, 15, 47, 20,  8, 71,\n",
      "       18, 26, 66, 52, 64, 35,  3, 18, 70, 72, 65, 51,  5, 75, 27, 10,  2,\n",
      "       60, 47, 80, 40, 45, 26, 12, 94, 33, 36, 16, 65, 42, 16, 43, 27, 14,\n",
      "       10, 81, 80,  0, 68, 60, 27, 57, 47, 23, 25, 36,  5, 70,  0, 59, 98,\n",
      "       85, 97, 60,  8, 31, 84, 43, 26,  1, 22, 81, 10, 38, 66, 14, 68, 17,\n",
      "       58, 56, 33, 80, 80, 10, 51, 62, 88,  1, 23, 26, 61, 88, 42, 81, 83,\n",
      "       41, 28, 41, 53, 39, 16, 18, 61, 72,  6, 76, 57, 15, 19, 37, 75, 39,\n",
      "       33, 18, 21,  4, 14, 51, 18, 49, 61, 24, 37,  3]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n",
      "0\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27a323440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "4\n",
      "WARNING:tensorflow:6 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb279e55a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "7\n",
      "8\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "9\n",
      "10\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "11\n",
      "12\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "13\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "14\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "15\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "16\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "17\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "18\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "20\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "21\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "22\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "23\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "24\n",
      "25\n",
      "26\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "27\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "28\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "29\n",
      "30\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "31\n",
      "32\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "33\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "34\n",
      "35\n",
      "36\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "37\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "38\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "39\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "40\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "41\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "43\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "44\n",
      "45\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "46\n",
      "47\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "48\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "49\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "50\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "51\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "52\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "53\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "54\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "55\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "56\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "57\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "58\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "59\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "60\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "61\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "62\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "63\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "64\n",
      "65\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "66\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "67\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "68\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "69\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "70\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "71\n",
      "72\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "73\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "74\n",
      "75\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "76\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "77\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "78\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "79\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "80\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "81\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "82\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "83\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "84\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "85\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "90\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "91\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "92\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "93\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "94\n",
      "95\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "96\n",
      "97\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "98\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "99\n",
      "TP: 226     FP: 13     FN: 0     TN: 218\n",
      "PPV: 0.9456\n",
      "Advantage: 0.9437\n",
      "Accuracy:  0.9715536105032823 Precision:  0.9456066945606695\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ad620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fa532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e2bdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset\n",
    "train_size = 14000\n",
    "attack_test_size = 5000\n",
    "target_dataset = pd.read_csv('data/purchase100_sds_sdv_ctgan.csv', na_values=[\"?\"], header=None)\n",
    "\n",
    "\n",
    "pur_data = np.load(DATA_PATH+'purchase100.npz')\n",
    "features = pur_data['features']\n",
    "labels = pur_data['labels']\n",
    "data = pd.DataFrame(features[:,:])\n",
    "labels = np.argmax(labels, axis=1)\n",
    "data['600'] = labels\n",
    "\n",
    "shadow_dataset = data.iloc[25000:79000,].sample(n = 35000, replace = False)\n",
    "attack_test_nonmembers = data.iloc[80000:,].sample(n=5000, replace=False)\n",
    "attack_test_members = data.iloc[0:train_size,].sample(n=5000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0df049a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 14000\n",
    "attack_test_size = 10000\n",
    "target_dataset = pd.read_csv('data/purchase100_sds_sdv.csv', header=None)\n",
    "target_dataset = target_dataset.sample(n=20000, replace=False)\n",
    "\n",
    "#target_dataset = data.sample(n = 20000, replace = False)\n",
    "# df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "# shadow_dataset = df_rest.sample(n = 35000, replace = False)\n",
    "# df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "# # attack_test_nonmembers = pd.DataFrame(data.iloc[75001:85001,].values)\n",
    "# # attack_test_members = pd.DataFrame(data.iloc[5001:15001,].values)\n",
    "# attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "# attack_test_members =  target_dataset.iloc[:train_size,:].sample(n = attack_test_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b4db7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  14.478571712970734 Target Test acc :  1.9999999552965164\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=50\n",
    "act_layer=6\n",
    "n_class = 100\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafafdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f935bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, training_data_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_puchase_data(dataset)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:training_data_size,]\n",
    "    testX = x[15000:,]\n",
    "    trainY = y[0:training_data_size,]\n",
    "    testY = y[15000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97c86b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Data Size:  2 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  1.679999940097332\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  1.4800000004470348\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  2.4800000712275505\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  3.4800000488758087\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  1.4600000344216824\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  1.7999999225139618\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  1.6200000420212746\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  0.7799999788403511\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  2.759999968111515\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  1.3199999928474426\n",
      "\n",
      " Training Data Size:  5 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  3.9400000125169754\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  3.9400000125169754\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  3.799999877810478\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  2.7000000700354576\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  1.5200000256299973\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  2.119999937713146\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  3.7599999457597733\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  2.239999920129776\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  3.240000084042549\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  2.84000001847744\n",
      "\n",
      " Training Data Size:  10 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  3.3799998462200165\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  3.400000184774399\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  4.520000144839287\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  4.14000004529953\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  5.420000106096268\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  4.899999871850014\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  2.8200000524520874\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  5.539999902248383\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  4.259999841451645\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  4.580000042915344\n",
      "\n",
      " Training Data Size:  15 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  5.119999870657921\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  4.38000001013279\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  4.740000143647194\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  5.059999972581863\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  4.019999876618385\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  4.30000014603138\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  5.040000006556511\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  4.600000008940697\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  4.619999974966049\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  5.260000005364418\n",
      "\n",
      " Training Data Size:  20 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  4.340000078082085\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  3.660000115633011\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  5.200000107288361\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  5.719999969005585\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  6.1400000005960464\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  6.340000033378601\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  4.659999907016754\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  4.280000180006027\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  5.5799998342990875\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  4.800000041723251\n",
      "\n",
      " Training Data Size:  25 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  5.700000002980232\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  4.039999842643738\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  6.279999762773514\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  4.960000142455101\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  5.640000104904175\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  4.800000041723251\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  5.939999967813492\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  5.139999836683273\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  5.959999933838844\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  5.3199999034404755\n",
      "\n",
      " Training Data Size:  50 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  5.660000070929527\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  5.840000137686729\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  6.89999982714653\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  6.459999829530716\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  5.799999833106995\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  7.940000295639038\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  6.179999932646751\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  6.279999762773514\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  6.599999964237213\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  6.5800003707408905\n",
      "\n",
      " Training Data Size:  100 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  8.28000009059906\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  7.4799999594688416\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  7.800000160932541\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  6.599999964237213\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  7.360000163316727\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  7.320000231266022\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  8.299999684095383\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  7.580000162124634\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  6.6200003027915955\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  7.419999688863754\n",
      "\n",
      " Training Data Size:  200 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  8.399999886751175\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  9.059999883174896\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  8.780000358819962\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  9.319999814033508\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  8.980000019073486\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  7.8199997544288635\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  6.97999969124794\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  7.739999890327454\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  7.5599998235702515\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  7.999999821186066\n",
      "\n",
      " Training Data Size:  500 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  10.760000348091125\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  11.11999973654747\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  10.980000346899033\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  11.20000034570694\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  11.779999732971191\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  11.060000211000443\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  11.739999800920486\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  10.859999805688858\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  11.079999804496765\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  10.96000000834465\n",
      "\n",
      " Training Data Size:  1000 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  20.600000023841858\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  19.79999989271164\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  19.280000030994415\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  18.559999763965607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  19.220000505447388\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  18.960000574588776\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  19.97999995946884\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  18.60000044107437\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  18.719999492168427\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  19.259999692440033\n",
      "\n",
      " Training Data Size:  2000 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  47.45999872684479\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  46.639999747276306\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  45.100000500679016\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  45.80000042915344\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  45.260000228881836\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  43.59999895095825\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  45.260000228881836\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  46.059998869895935\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  46.66000008583069\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  45.159998536109924\n",
      "\n",
      " Training Data Size:  5000 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  64.99999761581421\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  66.72000288963318\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  66.46000146865845\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  65.6000018119812\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  66.10000133514404\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  66.36000275611877\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  65.82000255584717\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  66.57999753952026\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  66.25999808311462\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  67.59999990463257\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=6\n",
    "n_class = 100\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "accuracy_df = pd.DataFrame()\n",
    "accuracy_df['training data size'] = np.nan\n",
    "accuracy_df['training accuracy'] = np.nan\n",
    "accuracy_df['test accuracy'] = np.nan\n",
    "accuracy_df['error'] = np.nan\n",
    "\n",
    "pur_data = np.load(DATA_PATH+'purchase100.npz')\n",
    "features = pur_data['features']\n",
    "labels = pur_data['labels']\n",
    "data = pd.DataFrame(features[:,:])\n",
    "labels = np.argmax(labels, axis=1)\n",
    "data['600'] = labels\n",
    "\n",
    "for j in training_data_size:\n",
    "    print('\\n Training Data Size: ', j, '\\n')\n",
    "    for i in range(10):\n",
    "        target_dataset = data.sample(n = 20000, replace = False)\n",
    "        (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, j, test_ratio, is_synthetic)\n",
    "        target_model,_ = build_purchase_dnn(n_class,dim)\n",
    "        #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "        history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "        score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "        _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        print('Iteration ', i, \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "        accuracy_df = accuracy_df.append({'training data size':j, 'training accuracy' : (train_acc * 100.0), 'test accuracy': (test_acc * 100.0), 'error': ((train_acc * 100.0)-(test_acc * 100.0))}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72f6f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_df =pd.read_csv('data/adult_overfitting_test_trainsize')\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "\n",
    "avg_error_ci95_df = pd.DataFrame()\n",
    "avg_error_ci95_df['training data size'] = np.nan\n",
    "avg_error_ci95_df['average training accuracy'] = np.nan\n",
    "avg_error_ci95_df['average test accuracy'] = np.nan\n",
    "avg_error_ci95_df['average error'] = np.nan\n",
    "avg_error_ci95_df['ci95 low'] = np.nan\n",
    "avg_error_ci95_df['ci95 high'] = np.nan\n",
    "\n",
    "for i in training_data_size:\n",
    "    error = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'error'])\n",
    "    training_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'training accuracy'])\n",
    "    test_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'test accuracy'])\n",
    "    ci95 = stats.t.interval(alpha=0.95, df=len(error)-1, loc=np.mean(error), scale=stats.sem(error))\n",
    "    row = pd.DataFrame({'training data size': [i], 'average training accuracy': \\\n",
    "            [np.mean(training_accuracy)], 'average test accuracy': [np.mean(test_accuracy)], 'average error': [np.mean(error)],\\\n",
    "                                                  'ci95 low': [ci95[0]], 'ci95 high': [ci95[1]]})\n",
    "    avg_error_ci95_df = pd.concat([avg_error_ci95_df, row], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5534de51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training data size</th>\n",
       "      <th>average training accuracy</th>\n",
       "      <th>average test accuracy</th>\n",
       "      <th>average error</th>\n",
       "      <th>ci95 low</th>\n",
       "      <th>ci95 high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.886000</td>\n",
       "      <td>98.114000</td>\n",
       "      <td>97.546301</td>\n",
       "      <td>98.681699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>96.990000</td>\n",
       "      <td>96.372809</td>\n",
       "      <td>97.607191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.296000</td>\n",
       "      <td>95.704000</td>\n",
       "      <td>95.066273</td>\n",
       "      <td>96.341727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.714000</td>\n",
       "      <td>95.286000</td>\n",
       "      <td>94.996299</td>\n",
       "      <td>95.575701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.072000</td>\n",
       "      <td>94.928000</td>\n",
       "      <td>94.304213</td>\n",
       "      <td>95.551787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.378000</td>\n",
       "      <td>94.622000</td>\n",
       "      <td>94.145122</td>\n",
       "      <td>95.098878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.424000</td>\n",
       "      <td>93.576000</td>\n",
       "      <td>93.100538</td>\n",
       "      <td>94.051462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.476000</td>\n",
       "      <td>92.524000</td>\n",
       "      <td>92.112213</td>\n",
       "      <td>92.935787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.264000</td>\n",
       "      <td>91.736000</td>\n",
       "      <td>91.190583</td>\n",
       "      <td>92.281417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.154000</td>\n",
       "      <td>88.846000</td>\n",
       "      <td>88.600216</td>\n",
       "      <td>89.091784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.298000</td>\n",
       "      <td>80.702000</td>\n",
       "      <td>80.231073</td>\n",
       "      <td>81.172927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.700000</td>\n",
       "      <td>54.300000</td>\n",
       "      <td>53.527650</td>\n",
       "      <td>55.072350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.250001</td>\n",
       "      <td>33.749999</td>\n",
       "      <td>33.249761</td>\n",
       "      <td>34.250238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training data size  average training accuracy  average test accuracy  \\\n",
       "0                  2.0                      100.0               1.886000   \n",
       "1                  5.0                      100.0               3.010000   \n",
       "2                 10.0                      100.0               4.296000   \n",
       "3                 15.0                      100.0               4.714000   \n",
       "4                 20.0                      100.0               5.072000   \n",
       "5                 25.0                      100.0               5.378000   \n",
       "6                 50.0                      100.0               6.424000   \n",
       "7                100.0                      100.0               7.476000   \n",
       "8                200.0                      100.0               8.264000   \n",
       "9                500.0                      100.0              11.154000   \n",
       "10              1000.0                      100.0              19.298000   \n",
       "11              2000.0                      100.0              45.700000   \n",
       "12              5000.0                      100.0              66.250001   \n",
       "\n",
       "    average error   ci95 low  ci95 high  \n",
       "0       98.114000  97.546301  98.681699  \n",
       "1       96.990000  96.372809  97.607191  \n",
       "2       95.704000  95.066273  96.341727  \n",
       "3       95.286000  94.996299  95.575701  \n",
       "4       94.928000  94.304213  95.551787  \n",
       "5       94.622000  94.145122  95.098878  \n",
       "6       93.576000  93.100538  94.051462  \n",
       "7       92.524000  92.112213  92.935787  \n",
       "8       91.736000  91.190583  92.281417  \n",
       "9       88.846000  88.600216  89.091784  \n",
       "10      80.702000  80.231073  81.172927  \n",
       "11      54.300000  53.527650  55.072350  \n",
       "12      33.749999  33.249761  34.250238  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_error_ci95_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e733a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
