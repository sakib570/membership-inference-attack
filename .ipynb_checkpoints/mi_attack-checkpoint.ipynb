{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1027973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 12:36:35.496930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-16 12:36:35.496982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ae4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.read_csv('../MIA/datasets/adultODS10K.csv', na_values=[\"?\"])\n",
    "shadow_dataset = pd.read_csv('../MIA/datasets/adultODS10K_to_25K.csv', na_values=[\"?\"])\n",
    "attack_test_dataset = pd.read_csv('../MIA/datasets/adultODS25K_to_30K.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eef1b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model test accuracy: 0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "(target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio)\n",
    "model,_ = build_simple_mlp (n_class,dim,channel)\n",
    "#get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "history = model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "score = model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio, random_state=0, stratify=shadow_i_y)\n",
    "        #print('shadow_i_trainX = ', trainX, 'shadow_i_trainY = ', trainY)\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_adult{}_data.npz'.format(i), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "85033cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shadow_models = 1\n",
    "shadow_data_size = 10000\n",
    "test_ratio = 0.3\n",
    "\n",
    "load_shadow_data(shadow_dataset, 10, 10000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "                \n",
    "\n",
    "        model,_ = build_simple_mlp (n_class,dim,channel)\n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=0)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=0)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "    print(\"\\n train predic\", full_sm_train_pred)\n",
    "    print(\"\\n trian class\", full_sm_train_class)\n",
    "    print(\"\\n members\", members)\n",
    "    print(\"\\n nonmembers\", nonmembers)\n",
    "    \n",
    "    print(\"\\n train class type \", type(full_sm_train_class))\n",
    "\n",
    "    \n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    \n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e11e4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "#train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0bbd473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shadow = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b76e77e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "x_shadow trian\n",
      " [[ 0.66124743  2.         15.         ... -0.21952066 -0.07073478\n",
      "   6.        ]\n",
      " [-1.391348    2.         15.         ... -0.21952066  0.26406476\n",
      "   0.        ]\n",
      " [ 0.20511511  2.          1.         ... -0.21952066 -0.07073478\n",
      "   6.        ]\n",
      " ...\n",
      " [ 0.5852254   2.         11.         ...  4.532243   -0.40553433\n",
      "   6.        ]\n",
      " [-0.17499517  2.          9.         ...  4.532243    0.7662641\n",
      "   6.        ]\n",
      " [-1.6194142   2.          1.         ... -0.21952066 -2.079532\n",
      "   6.        ]] \n",
      " y_shadow trian\n",
      " [1 0 0 ... 1 1 0] \n",
      " x_shadow test\n",
      " [[-0.17499517  5.         11.         ... -0.21952066 -0.07073478\n",
      "   6.        ]\n",
      " [-0.8591937   2.          8.         ... -0.21952066 -0.4892342\n",
      "   6.        ]\n",
      " [-0.02295106  4.         11.         ... -0.21952066 -0.07073478\n",
      "   6.        ]\n",
      " ...\n",
      " [ 0.35715923  3.         14.         ...  4.7588773   0.7662641\n",
      "   6.        ]\n",
      " [ 1.421468    2.         15.         ... -0.21952066 -0.07073478\n",
      "   6.        ]\n",
      " [ 0.5092033   2.          9.         ... -0.21952066  0.7662641\n",
      "   6.        ]] \n",
      " y_shadow test\n",
      " [0 0 0 ... 1 0 1]\n",
      "Shadow Train acc :  94.43333148956299 Shadow Test acc :  87.69999742507935\n",
      "94/94 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_322375/3475468244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#train SM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0msm_train_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shadow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msm_train_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_shadow_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/r4-base/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[0;32m-> 1195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/r4-base/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "full_sm_train_pred=[]\n",
    "full_sm_train_class=[]\n",
    "\n",
    "full_sm_test_pred=[]\n",
    "full_sm_test_class=[]\n",
    "\n",
    "full_clz_train=[]\n",
    "full_clz_test=[]\n",
    "\n",
    "members=[]\n",
    "nonmembers=[]\n",
    "\n",
    "\n",
    "for j in range(n_shadow):\n",
    "\n",
    "    print(\"Shadow Model \", j)\n",
    "\n",
    "    print('Training shadow model {}'.format(j))\n",
    "    data = read_data('shadow{}_data.npz'.format(j))\n",
    "    x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "\n",
    "    print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "    model,_ = build_simple_mlp (n_class,dim,channel)\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "\n",
    "    # evaluate model\n",
    "    _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "    _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "    print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "\n",
    "    #train SM\n",
    "    sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "    sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "\n",
    "\n",
    "    #test SM\n",
    "    sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "    sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "\n",
    "\n",
    "    full_sm_train_pred.append(sm_train_pred)        \n",
    "    full_sm_train_class.append(sm_train_class)\n",
    "    members.append(np.ones(len(sm_train_pred)))\n",
    "\n",
    "    full_sm_test_pred.append(sm_test_pred)        \n",
    "    full_sm_test_class.append(sm_test_class) \n",
    "    nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "print(\"\\n train predic\", full_sm_train_pred)\n",
    "print(\"\\n trian class\", full_sm_train_class)\n",
    "print(\"\\n members\", members)\n",
    "print(\"\\n nonmembers\", nonmembers)\n",
    "\n",
    "print(\"\\n train class type \", type(full_sm_train_class))\n",
    "\n",
    "\n",
    "full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "members = [item for sublist in members for item in sublist]\n",
    "\n",
    "full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "\n",
    "nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "###atack data preparation\n",
    "attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "#attack_x = np.vstack(attack_x)\n",
    "\n",
    "attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "#attack_y = np.concatenate(attack_y)\n",
    "#attack_y = attack_y.astype('int32')\n",
    "\n",
    "\n",
    "classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "#classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "attack_dataset = (attack_x,attack_y,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6d032a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0479312e-04, 9.9969518e-01],\n",
       "       [9.9995667e-01, 4.3250599e-05],\n",
       "       [9.9862522e-01, 1.3747002e-03],\n",
       "       ...,\n",
       "       [1.1925322e-07, 9.9999982e-01],\n",
       "       [1.2142958e-07, 9.9999982e-01],\n",
       "       [9.9999994e-01, 4.5283450e-08]], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_shadow_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
