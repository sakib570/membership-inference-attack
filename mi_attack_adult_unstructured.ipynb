{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1027973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 10:58:53.272982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-17 10:58:53.273512: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with specific index\n",
    "# data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "# target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "# shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "    \n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "            print(x.iloc[:,j])\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "630d4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, is_synthetic):\n",
    "    \n",
    "    if(is_synthetic == False):\n",
    "        for col in [1,3,5,6,7,8,9,13,14]:\n",
    "            le = LabelEncoder()\n",
    "            dataset[col] = le.fit_transform(dataset[col].astype('str'))\n",
    "\n",
    "        # normalize the values\n",
    "        x_range = [i for i in range(14)]\n",
    "        dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "        x = dataset[x_range].values\n",
    "        y = dataset[14].values\n",
    "    else:\n",
    "        for col in [1,2,3,4,5,6,7,11,12]:\n",
    "            le = LabelEncoder()\n",
    "            dataset[col] = le.fit_transform(dataset[col].astype('str'))\n",
    "\n",
    "        # normalize the values\n",
    "        x_range = [i for i in range(12)]\n",
    "        dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "        x = dataset[x_range].values\n",
    "        y = dataset[12].values\n",
    "        \n",
    "    \n",
    "    dim = x.shape[1]\n",
    "    \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, trian_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:trian_size,]\n",
    "    testX = x[7000:,]\n",
    "    trainY = y[0:trian_size,]\n",
    "    testY = y[7000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0c519d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn(n_class,dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    #model.add(Dense(1024, kernel_regularizer=l2(0.00003)))\n",
    "    #model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio, is_synthetic):\n",
    "    x, y, _ = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_adult{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_adult{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        #model, act_layer = build_simple_mlp(n_class,dim, channel)\n",
    "        model, act_layer = build_dnn(n_class,dim)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7909a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5b5974c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_train_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f855c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers, is_synthetic):\n",
    "    memberX, memberY, _ = transform_data(members, is_synthetic)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers, is_synthetic)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(pred_y)\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01432ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a933f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, train_size, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, train_size, test_ratio, is_synthetic)\n",
    "    #target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "    target_model,_ = build_dnn(n_class,dim)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ef35632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic):\n",
    "    members = []\n",
    "    nonmembers = []\n",
    "\n",
    "    memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers, is_synthetic)\n",
    "\n",
    "    # member\n",
    "    target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "    target_model_member_class = np.argmax(memberY, axis=1)\n",
    "    target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "    #target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "    members.append(np.ones(len(target_model_member_pred)))\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "    # nonmember\n",
    "    target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "    target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "    target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "    #target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "    nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "    full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "    full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "    print('\\n pred', full_attack_test_pred_val)\n",
    "    print('\\n class', full_attack_test_class_status)\n",
    "    print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "    attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)\n",
    "    \n",
    "    return attack_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dde3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64303a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "train_size = 500\n",
    "attack_test_size = 250\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:train_size,:].sample(n = attack_test_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 16:54:15.839590: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-09 16:54:15.839645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (msnkhan-desktop): /proc/driver/nvidia/version does not exist\n",
      "2022-09-09 16:54:15.840312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  94.40000057220459 Target Test acc :  80.0000011920929\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "5a961b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  80.4444432258606\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  95.99999785423279 Shadow Test acc :  74.6666669845581\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  93.9047634601593 Shadow Test acc :  80.88889122009277\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  95.04761695861816 Shadow Test acc :  82.22222328186035\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  97.33333587646484 Shadow Test acc :  80.0000011920929\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  83.99999737739563\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  97.33333587646484 Shadow Test acc :  81.77777528762817\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  91.04762077331543 Shadow Test acc :  80.0000011920929\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  97.7142870426178 Shadow Test acc :  83.99999737739563\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  96.38095498085022 Shadow Test acc :  79.55555319786072\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  96.1904764175415 Shadow Test acc :  83.99999737739563\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  95.4285740852356 Shadow Test acc :  76.88888907432556\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  95.61904668807983 Shadow Test acc :  81.33333325386047\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  95.80952525138855 Shadow Test acc :  81.77777528762817\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  96.38095498085022 Shadow Test acc :  80.4444432258606\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  95.23809552192688 Shadow Test acc :  79.11111116409302\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  97.14285731315613 Shadow Test acc :  75.55555701255798\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  97.7142870426178 Shadow Test acc :  82.66666531562805\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  96.38095498085022 Shadow Test acc :  77.77777910232544\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  97.52380847930908 Shadow Test acc :  79.11111116409302\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 750\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "9074b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "\n",
      " pred (array([[9.93186951e-01, 6.81309216e-03],\n",
      "       [9.99996603e-01, 3.34540414e-06],\n",
      "       [5.33304572e-01, 4.66695338e-01],\n",
      "       [8.33065331e-01, 1.66934624e-01],\n",
      "       [9.99999821e-01, 6.89283510e-08],\n",
      "       [9.99379456e-01, 6.20536448e-04],\n",
      "       [9.98037875e-01, 1.96207990e-03],\n",
      "       [9.99924123e-01, 7.57550661e-05],\n",
      "       [9.98999298e-01, 1.00067887e-03],\n",
      "       [9.99740839e-01, 2.59266293e-04],\n",
      "       [9.27459240e-01, 7.25407079e-02],\n",
      "       [9.97939765e-01, 2.06026668e-03],\n",
      "       [1.42221001e-03, 9.98577833e-01],\n",
      "       [7.65948653e-01, 2.34051391e-01],\n",
      "       [9.99999940e-01, 2.36470328e-08],\n",
      "       [9.83341634e-02, 9.01665688e-01],\n",
      "       [8.42344575e-03, 9.91576552e-01],\n",
      "       [9.86712217e-01, 1.32877463e-02],\n",
      "       [8.72559845e-01, 1.27440065e-01],\n",
      "       [9.91667211e-01, 8.33283830e-03],\n",
      "       [9.98672605e-01, 1.32740464e-03],\n",
      "       [9.99459386e-01, 5.40558773e-04],\n",
      "       [9.99971330e-01, 2.85528786e-05],\n",
      "       [9.99597609e-01, 4.02427337e-04],\n",
      "       [9.99939382e-01, 6.05231908e-05],\n",
      "       [9.99997199e-01, 2.73091473e-06],\n",
      "       [7.74071634e-01, 2.25928351e-01],\n",
      "       [6.91059470e-01, 3.08940500e-01],\n",
      "       [9.99964535e-01, 3.54135482e-05],\n",
      "       [1.58027560e-03, 9.98419762e-01],\n",
      "       [2.47603714e-01, 7.52396226e-01],\n",
      "       [6.29070075e-03, 9.93709266e-01],\n",
      "       [9.97685194e-01, 2.31481134e-03],\n",
      "       [9.78291750e-01, 2.17082873e-02],\n",
      "       [9.79601741e-01, 2.03982126e-02],\n",
      "       [9.99999940e-01, 2.85438362e-09],\n",
      "       [9.13061202e-01, 8.69387761e-02],\n",
      "       [9.99953568e-01, 4.63315519e-05],\n",
      "       [9.99999702e-01, 2.76709329e-07],\n",
      "       [8.45030725e-01, 1.54969260e-01],\n",
      "       [6.69019163e-01, 3.30980778e-01],\n",
      "       [4.05302525e-01, 5.94697475e-01],\n",
      "       [1.27528585e-10, 9.99999940e-01],\n",
      "       [8.28780711e-01, 1.71219260e-01],\n",
      "       [2.77141032e-10, 9.99999940e-01],\n",
      "       [9.99996603e-01, 3.32131413e-06],\n",
      "       [8.31931770e-01, 1.68068141e-01],\n",
      "       [9.99755383e-01, 2.44721188e-04],\n",
      "       [9.69244599e-01, 3.07553448e-02],\n",
      "       [9.38516259e-01, 6.14837073e-02],\n",
      "       [9.99909818e-01, 9.00578598e-05],\n",
      "       [9.98534024e-01, 1.46592362e-03],\n",
      "       [9.99979913e-01, 1.99718434e-05],\n",
      "       [4.34942216e-01, 5.65057814e-01],\n",
      "       [9.99999940e-01, 5.55131408e-08],\n",
      "       [9.98165011e-01, 1.83495320e-03],\n",
      "       [5.23599148e-01, 4.76400912e-01],\n",
      "       [9.99910653e-01, 8.92854514e-05],\n",
      "       [9.99912202e-01, 8.77182028e-05],\n",
      "       [9.99991477e-01, 8.43253292e-06],\n",
      "       [8.22431266e-01, 1.77568614e-01],\n",
      "       [9.99967635e-01, 3.23386121e-05],\n",
      "       [1.94509342e-01, 8.05490613e-01],\n",
      "       [9.99956191e-01, 4.37099370e-05],\n",
      "       [4.12894040e-02, 9.58710492e-01],\n",
      "       [6.43545389e-01, 3.56454551e-01],\n",
      "       [4.86774892e-01, 5.13225079e-01],\n",
      "       [9.99999702e-01, 2.51526586e-07],\n",
      "       [9.98549640e-01, 1.45034143e-03],\n",
      "       [9.99978840e-01, 2.10712878e-05],\n",
      "       [9.99946773e-01, 5.32173908e-05],\n",
      "       [9.99986470e-01, 1.34991333e-05],\n",
      "       [9.99970496e-01, 2.94732999e-05],\n",
      "       [9.74345088e-01, 2.56548002e-02],\n",
      "       [9.94530439e-01, 5.46957552e-03],\n",
      "       [9.99999821e-01, 8.25201951e-08],\n",
      "       [4.77446861e-07, 9.99999464e-01],\n",
      "       [7.57066488e-01, 2.42933542e-01],\n",
      "       [9.71543074e-01, 2.84567513e-02],\n",
      "       [9.93430257e-01, 6.56977436e-03],\n",
      "       [9.54856098e-01, 4.51438949e-02],\n",
      "       [9.28967834e-01, 7.10321590e-02],\n",
      "       [9.99540389e-01, 4.59525065e-04],\n",
      "       [9.99999940e-01, 1.26340938e-08],\n",
      "       [8.60225618e-01, 1.39774412e-01],\n",
      "       [9.90984201e-01, 9.01584886e-03],\n",
      "       [2.31844634e-01, 7.68155336e-01],\n",
      "       [9.98466194e-01, 1.53382809e-03],\n",
      "       [9.99691844e-01, 3.08156450e-04],\n",
      "       [9.98290777e-01, 1.70928356e-03],\n",
      "       [5.13461351e-01, 4.86538678e-01],\n",
      "       [9.99874830e-01, 1.25101331e-04],\n",
      "       [9.99499500e-01, 5.00408350e-04],\n",
      "       [7.67129779e-01, 2.32870221e-01],\n",
      "       [3.93591791e-01, 6.06408238e-01],\n",
      "       [9.99993503e-01, 6.47562320e-06],\n",
      "       [9.31254029e-01, 6.87460080e-02],\n",
      "       [9.99998152e-01, 1.81326982e-06],\n",
      "       [7.37882078e-01, 2.62117893e-01],\n",
      "       [3.13147684e-05, 9.99968588e-01],\n",
      "       [9.99016106e-01, 9.83834034e-04],\n",
      "       [1.67854175e-01, 8.32145929e-01],\n",
      "       [9.99971211e-01, 2.86809263e-05],\n",
      "       [9.10271227e-01, 8.97287130e-02],\n",
      "       [9.99998152e-01, 1.75144453e-06],\n",
      "       [9.99974191e-01, 2.58017244e-05],\n",
      "       [9.99999940e-01, 5.12188052e-08],\n",
      "       [9.99763489e-01, 2.36494292e-04],\n",
      "       [1.92203268e-01, 8.07796717e-01],\n",
      "       [2.38900498e-01, 7.61099458e-01],\n",
      "       [9.99875784e-01, 1.24177037e-04],\n",
      "       [7.27962136e-01, 2.72037894e-01],\n",
      "       [5.73486328e-01, 4.26513702e-01],\n",
      "       [4.00048852e-01, 5.99951208e-01],\n",
      "       [9.99996841e-01, 3.11897111e-06],\n",
      "       [9.99936879e-01, 6.30215727e-05],\n",
      "       [5.97960055e-01, 4.02039886e-01],\n",
      "       [9.99999940e-01, 6.86593316e-09],\n",
      "       [9.99999464e-01, 5.08799701e-07],\n",
      "       [9.12316978e-01, 8.76829401e-02],\n",
      "       [1.78300187e-01, 8.21699739e-01],\n",
      "       [6.69168234e-02, 9.33083117e-01],\n",
      "       [9.92917895e-01, 7.08213029e-03],\n",
      "       [9.99992788e-01, 7.13612690e-06],\n",
      "       [9.99998152e-01, 1.83192185e-06],\n",
      "       [9.99988854e-01, 1.10725141e-05],\n",
      "       [2.25633740e-01, 7.74366319e-01],\n",
      "       [6.19678557e-01, 3.80321324e-01],\n",
      "       [9.88646984e-01, 1.13530131e-02],\n",
      "       [4.84155007e-02, 9.51584458e-01],\n",
      "       [7.01436043e-01, 2.98563927e-01],\n",
      "       [9.99989808e-01, 1.00815805e-05],\n",
      "       [9.99844551e-01, 1.55550166e-04],\n",
      "       [9.99868631e-01, 1.31411318e-04],\n",
      "       [8.56282592e-01, 1.43717349e-01],\n",
      "       [9.99999821e-01, 9.05027093e-08],\n",
      "       [9.99998987e-01, 9.63869184e-07],\n",
      "       [9.97854829e-01, 2.14525429e-03],\n",
      "       [3.39574628e-02, 9.66042519e-01],\n",
      "       [9.95406151e-01, 4.59373230e-03],\n",
      "       [9.99836683e-01, 1.63340228e-04],\n",
      "       [9.99999583e-01, 3.30174515e-07],\n",
      "       [9.99965489e-01, 3.43912907e-05],\n",
      "       [9.99979198e-01, 2.07263220e-05],\n",
      "       [9.99541819e-01, 4.58101480e-04],\n",
      "       [4.42838609e-01, 5.57161391e-01],\n",
      "       [9.99997437e-01, 2.51955180e-06],\n",
      "       [9.99996126e-01, 3.77295555e-06],\n",
      "       [9.99975026e-01, 2.49611367e-05],\n",
      "       [9.99218643e-01, 7.81439536e-04],\n",
      "       [9.99996841e-01, 3.08441599e-06],\n",
      "       [9.91545796e-01, 8.45409557e-03],\n",
      "       [9.99997199e-01, 2.77523827e-06],\n",
      "       [7.95805991e-01, 2.04193950e-01],\n",
      "       [9.99999940e-01, 4.38038334e-08],\n",
      "       [9.87771213e-01, 1.22288167e-02],\n",
      "       [2.60271400e-01, 7.39728570e-01],\n",
      "       [9.99574125e-01, 4.25824663e-04],\n",
      "       [9.31176662e-01, 6.88233450e-02],\n",
      "       [2.03949109e-01, 7.96050787e-01],\n",
      "       [1.91824958e-02, 9.80817378e-01],\n",
      "       [9.06607012e-10, 9.99999940e-01],\n",
      "       [9.99999583e-01, 4.05940739e-07],\n",
      "       [9.99352396e-01, 6.47549750e-04],\n",
      "       [9.98804986e-01, 1.19491597e-03],\n",
      "       [9.99711871e-01, 2.88210518e-04],\n",
      "       [9.98210311e-01, 1.78968557e-03],\n",
      "       [1.40137635e-02, 9.85986292e-01],\n",
      "       [9.93587375e-01, 6.41255919e-03],\n",
      "       [1.27729515e-06, 9.99998629e-01],\n",
      "       [5.38898669e-02, 9.46110129e-01],\n",
      "       [9.99578893e-01, 4.21130680e-04],\n",
      "       [9.98684406e-01, 1.31554750e-03],\n",
      "       [9.99963820e-01, 3.60722006e-05],\n",
      "       [2.79626608e-01, 7.20373333e-01],\n",
      "       [9.89834964e-01, 1.01649882e-02],\n",
      "       [9.91768956e-01, 8.23090971e-03],\n",
      "       [9.99953091e-01, 4.67937898e-05],\n",
      "       [9.99999821e-01, 1.39900749e-07],\n",
      "       [9.98581171e-01, 1.41879835e-03],\n",
      "       [9.99372423e-01, 6.27627305e-04],\n",
      "       [9.69057083e-01, 3.09429411e-02],\n",
      "       [9.25191585e-03, 9.90748227e-01],\n",
      "       [8.57198715e-01, 1.42801344e-01],\n",
      "       [9.99999225e-01, 7.71669306e-07],\n",
      "       [8.36718678e-01, 1.63281232e-01],\n",
      "       [9.97468293e-01, 2.53160577e-03],\n",
      "       [9.99994576e-01, 5.38138829e-06],\n",
      "       [9.99875784e-01, 1.24351121e-04],\n",
      "       [9.83928610e-03, 9.90160704e-01],\n",
      "       [9.99991000e-01, 8.89091007e-06],\n",
      "       [9.96688664e-01, 3.31122754e-03],\n",
      "       [9.99989450e-01, 1.04987494e-05],\n",
      "       [9.99905646e-01, 9.43427076e-05],\n",
      "       [6.91162527e-01, 3.08837414e-01],\n",
      "       [2.12931693e-01, 7.87068367e-01],\n",
      "       [8.02721500e-01, 1.97278559e-01],\n",
      "       [9.99999344e-01, 6.01000806e-07],\n",
      "       [8.29449892e-01, 1.70550123e-01],\n",
      "       [9.81225312e-01, 1.87746491e-02],\n",
      "       [2.68575042e-01, 7.31424868e-01],\n",
      "       [9.99999940e-01, 1.00438280e-08],\n",
      "       [9.99780655e-01, 2.19282039e-04],\n",
      "       [7.99957991e-01, 2.00041994e-01],\n",
      "       [9.16508615e-01, 8.34914446e-02],\n",
      "       [9.99109387e-01, 8.90509167e-04],\n",
      "       [9.99994338e-01, 5.59261980e-06],\n",
      "       [9.46649849e-01, 5.33501841e-02],\n",
      "       [9.98193800e-01, 1.80617964e-03],\n",
      "       [9.99963343e-01, 3.66051027e-05],\n",
      "       [9.47862327e-01, 5.21376505e-02],\n",
      "       [9.99999940e-01, 1.66808540e-08],\n",
      "       [4.87750560e-01, 5.12249410e-01],\n",
      "       [9.99040306e-01, 9.59674187e-04],\n",
      "       [5.11402130e-01, 4.88597929e-01],\n",
      "       [8.94745767e-01, 1.05254225e-01],\n",
      "       [9.99944150e-01, 5.57793937e-05],\n",
      "       [9.99162018e-01, 8.37977394e-04],\n",
      "       [9.99996006e-01, 3.91531785e-06],\n",
      "       [9.65288877e-01, 3.47111747e-02],\n",
      "       [9.97110784e-01, 2.88913865e-03],\n",
      "       [9.99563515e-01, 4.36452305e-04],\n",
      "       [6.54480875e-01, 3.45519096e-01],\n",
      "       [8.18365633e-01, 1.81634426e-01],\n",
      "       [9.96019959e-01, 3.98002379e-03],\n",
      "       [1.16797737e-05, 9.99988258e-01],\n",
      "       [9.99982893e-01, 1.70673393e-05],\n",
      "       [9.99998868e-01, 1.08586312e-06],\n",
      "       [4.69332129e-01, 5.30667841e-01],\n",
      "       [4.84983236e-01, 5.15016735e-01],\n",
      "       [1.22914443e-10, 9.99999940e-01],\n",
      "       [6.15833759e-01, 3.84166181e-01],\n",
      "       [1.27825672e-06, 9.99998629e-01],\n",
      "       [9.99994338e-01, 5.54413600e-06],\n",
      "       [9.97683525e-01, 2.31644604e-03],\n",
      "       [1.84136510e-01, 8.15863490e-01],\n",
      "       [9.19301212e-01, 8.06987807e-02],\n",
      "       [9.93703365e-01, 6.29653037e-03],\n",
      "       [9.99660492e-01, 3.39532853e-04],\n",
      "       [6.05940342e-01, 3.94059628e-01],\n",
      "       [9.99607503e-01, 3.92517861e-04],\n",
      "       [9.98050630e-01, 1.94929435e-03],\n",
      "       [2.07396030e-01, 7.92603910e-01],\n",
      "       [9.99969184e-01, 3.07629489e-05],\n",
      "       [9.98238802e-01, 1.76113925e-03],\n",
      "       [9.99663472e-01, 3.36550380e-04],\n",
      "       [7.79045999e-01, 2.20953971e-01],\n",
      "       [9.99688268e-01, 3.11750046e-04],\n",
      "       [9.51762795e-01, 4.82372418e-02],\n",
      "       [5.36812484e-01, 4.63187546e-01]], dtype=float32), array([[1.02130651e-01, 8.97869289e-01],\n",
      "       [9.99999940e-01, 3.06686729e-08],\n",
      "       [2.95653582e-01, 7.04346359e-01],\n",
      "       [7.67636597e-01, 2.32363328e-01],\n",
      "       [1.58087716e-01, 8.41912210e-01],\n",
      "       [9.99995768e-01, 4.17459523e-06],\n",
      "       [6.71707928e-01, 3.28292131e-01],\n",
      "       [9.99985516e-01, 1.44425821e-05],\n",
      "       [1.43708143e-10, 9.99999940e-01],\n",
      "       [4.30454779e-03, 9.95695531e-01],\n",
      "       [9.87894356e-01, 1.21055152e-02],\n",
      "       [1.61809936e-01, 8.38190138e-01],\n",
      "       [4.89429235e-01, 5.10570824e-01],\n",
      "       [9.98416901e-01, 1.58309715e-03],\n",
      "       [9.99997437e-01, 2.50997800e-06],\n",
      "       [3.33207985e-03, 9.96667862e-01],\n",
      "       [9.39770602e-03, 9.90602255e-01],\n",
      "       [9.98308182e-01, 1.69185479e-03],\n",
      "       [9.09339666e-01, 9.06602517e-02],\n",
      "       [9.12420452e-01, 8.75796154e-02],\n",
      "       [8.98846149e-01, 1.01153761e-01],\n",
      "       [9.82422471e-01, 1.75775010e-02],\n",
      "       [8.00377950e-02, 9.19962108e-01],\n",
      "       [7.76977122e-01, 2.23022729e-01],\n",
      "       [9.99976814e-01, 2.31632112e-05],\n",
      "       [2.37325996e-01, 7.62673974e-01],\n",
      "       [8.09538424e-01, 1.90461427e-01],\n",
      "       [9.99207437e-01, 7.92585954e-04],\n",
      "       [9.84140277e-01, 1.58595890e-02],\n",
      "       [9.98577356e-01, 1.42263738e-03],\n",
      "       [2.41177157e-01, 7.58822918e-01],\n",
      "       [1.02573387e-10, 9.99999940e-01],\n",
      "       [9.99999940e-01, 2.22756619e-10],\n",
      "       [9.99782324e-01, 2.17572611e-04],\n",
      "       [9.99990761e-01, 9.20178718e-06],\n",
      "       [9.99931514e-01, 6.84498227e-05],\n",
      "       [9.39975977e-01, 6.00240156e-02],\n",
      "       [7.75762439e-01, 2.24237546e-01],\n",
      "       [9.93129432e-01, 6.87052868e-03],\n",
      "       [9.99982536e-01, 1.74554189e-05],\n",
      "       [2.79729553e-02, 9.72027063e-01],\n",
      "       [5.36395907e-01, 4.63604152e-01],\n",
      "       [9.99999821e-01, 1.61665653e-07],\n",
      "       [3.17053109e-01, 6.82946920e-01],\n",
      "       [1.37902975e-01, 8.62097085e-01],\n",
      "       [9.99991119e-01, 8.77957154e-06],\n",
      "       [9.59529638e-01, 4.04704101e-02],\n",
      "       [9.99956906e-01, 4.29883330e-05],\n",
      "       [8.55298471e-11, 9.99999940e-01],\n",
      "       [9.99999940e-01, 2.42631852e-08],\n",
      "       [9.98160958e-01, 1.83897419e-03],\n",
      "       [4.18269575e-01, 5.81730366e-01],\n",
      "       [9.56033945e-01, 4.39660028e-02],\n",
      "       [7.86574483e-01, 2.13425517e-01],\n",
      "       [9.04717088e-01, 9.52828974e-02],\n",
      "       [7.34517395e-01, 2.65482605e-01],\n",
      "       [9.99999344e-01, 6.06346816e-07],\n",
      "       [3.90146929e-03, 9.96098459e-01],\n",
      "       [2.09801435e-03, 9.97902036e-01],\n",
      "       [7.44432092e-01, 2.55567819e-01],\n",
      "       [4.16408060e-03, 9.95835960e-01],\n",
      "       [6.99787796e-01, 3.00212145e-01],\n",
      "       [9.99960244e-01, 3.97053263e-05],\n",
      "       [1.58285379e-01, 8.41714680e-01],\n",
      "       [9.99990046e-01, 9.95186929e-06],\n",
      "       [9.46570277e-01, 5.34297824e-02],\n",
      "       [5.22647500e-02, 9.47735190e-01],\n",
      "       [2.46015429e-01, 7.53984630e-01],\n",
      "       [4.59546447e-01, 5.40453434e-01],\n",
      "       [9.99905169e-01, 9.47516673e-05],\n",
      "       [9.99832153e-01, 1.67917853e-04],\n",
      "       [9.99984562e-01, 1.53616365e-05],\n",
      "       [9.78398621e-01, 2.16015149e-02],\n",
      "       [2.13157207e-01, 7.86842763e-01],\n",
      "       [6.07573807e-01, 3.92426103e-01],\n",
      "       [9.99998391e-01, 1.53341762e-06],\n",
      "       [9.99999821e-01, 1.37666788e-07],\n",
      "       [9.99998987e-01, 9.05857405e-07],\n",
      "       [9.99947965e-01, 5.19753085e-05],\n",
      "       [9.99976337e-01, 2.36269480e-05],\n",
      "       [9.99311745e-01, 6.88192726e-04],\n",
      "       [5.60131252e-01, 4.39868808e-01],\n",
      "       [9.99999940e-01, 1.38231906e-08],\n",
      "       [7.14083482e-03, 9.92859185e-01],\n",
      "       [9.48803008e-01, 5.11970408e-02],\n",
      "       [1.49088763e-02, 9.85091031e-01],\n",
      "       [9.87769306e-01, 1.22305304e-02],\n",
      "       [9.86418784e-01, 1.35812173e-02],\n",
      "       [9.99997079e-01, 2.90874345e-06],\n",
      "       [9.98409927e-01, 1.59015681e-03],\n",
      "       [9.99998987e-01, 1.00866794e-06],\n",
      "       [9.99617755e-01, 3.82328959e-04],\n",
      "       [5.25004685e-01, 4.74995255e-01],\n",
      "       [9.27618444e-01, 7.23815039e-02],\n",
      "       [9.99475300e-01, 5.24652831e-04],\n",
      "       [9.98754323e-01, 1.24570332e-03],\n",
      "       [6.92627728e-01, 3.07372302e-01],\n",
      "       [9.00576949e-01, 9.94229764e-02],\n",
      "       [9.99035537e-01, 9.64424456e-04],\n",
      "       [9.99999940e-01, 3.51020657e-10],\n",
      "       [9.45830226e-01, 5.41697592e-02],\n",
      "       [9.98823583e-01, 1.17642875e-03],\n",
      "       [9.99952972e-01, 4.69372499e-05],\n",
      "       [9.09996450e-01, 9.00035650e-02],\n",
      "       [7.60261059e-01, 2.39738941e-01],\n",
      "       [9.99376714e-01, 6.23311382e-04],\n",
      "       [9.99995172e-01, 4.78477477e-06],\n",
      "       [9.78619039e-01, 2.13809423e-02],\n",
      "       [9.99982297e-01, 1.76910107e-05],\n",
      "       [1.36199640e-03, 9.98637974e-01],\n",
      "       [9.99264956e-01, 7.35099486e-04],\n",
      "       [9.99996603e-01, 3.29017303e-06],\n",
      "       [9.98938978e-01, 1.06106594e-03],\n",
      "       [9.91943479e-01, 8.05654842e-03],\n",
      "       [9.99306679e-01, 6.93473674e-04],\n",
      "       [9.99999821e-01, 8.99017465e-08],\n",
      "       [9.99938548e-01, 6.13396187e-05],\n",
      "       [9.99998510e-01, 1.37244183e-06],\n",
      "       [9.99999940e-01, 5.85017474e-08],\n",
      "       [9.99950349e-01, 4.95900058e-05],\n",
      "       [8.20242703e-01, 1.79757297e-01],\n",
      "       [9.99996245e-01, 3.71335682e-06],\n",
      "       [8.35149705e-01, 1.64850280e-01],\n",
      "       [4.18836810e-02, 9.58116293e-01],\n",
      "       [9.99630511e-01, 3.69535934e-04],\n",
      "       [9.96851385e-01, 3.14859417e-03],\n",
      "       [8.51762533e-01, 1.48237377e-01],\n",
      "       [4.23025876e-01, 5.76974154e-01],\n",
      "       [9.99999940e-01, 1.22110979e-08],\n",
      "       [3.51345651e-02, 9.64865506e-01],\n",
      "       [4.41811502e-01, 5.58188498e-01],\n",
      "       [9.97481585e-01, 2.51833675e-03],\n",
      "       [9.99916732e-01, 8.31587968e-05],\n",
      "       [9.99995887e-01, 4.09443737e-06],\n",
      "       [9.99522626e-01, 4.77281603e-04],\n",
      "       [9.99096036e-01, 9.03958280e-04],\n",
      "       [9.98295307e-01, 1.70473638e-03],\n",
      "       [9.99970138e-01, 2.98548857e-05],\n",
      "       [2.23865241e-01, 7.76134729e-01],\n",
      "       [7.04290032e-01, 2.95709908e-01],\n",
      "       [9.03968751e-01, 9.60312188e-02],\n",
      "       [9.99992430e-01, 7.56157669e-06],\n",
      "       [9.99998987e-01, 9.77129162e-07],\n",
      "       [1.32057980e-01, 8.67941976e-01],\n",
      "       [9.99981940e-01, 1.80351817e-05],\n",
      "       [3.40907485e-03, 9.96590853e-01],\n",
      "       [8.80296350e-01, 1.19703628e-01],\n",
      "       [5.46750844e-01, 4.53249186e-01],\n",
      "       [9.99997079e-01, 2.91972947e-06],\n",
      "       [9.99916613e-01, 8.33117520e-05],\n",
      "       [9.99905407e-01, 9.45451684e-05],\n",
      "       [9.99989212e-01, 1.07173291e-05],\n",
      "       [9.67719674e-01, 3.22803371e-02],\n",
      "       [5.26903033e-01, 4.73097026e-01],\n",
      "       [5.98548763e-02, 9.40145075e-01],\n",
      "       [3.66589606e-01, 6.33410454e-01],\n",
      "       [9.99702573e-01, 2.97501218e-04],\n",
      "       [9.22046900e-01, 7.79530182e-02],\n",
      "       [9.99992788e-01, 7.18362980e-06],\n",
      "       [9.99962509e-01, 3.74279916e-05],\n",
      "       [9.99984682e-01, 1.52444745e-05],\n",
      "       [1.04834614e-02, 9.89516556e-01],\n",
      "       [8.60081315e-01, 1.39918700e-01],\n",
      "       [9.99995410e-01, 4.54984365e-06],\n",
      "       [9.99976695e-01, 2.32999719e-05],\n",
      "       [3.75063807e-01, 6.24936163e-01],\n",
      "       [9.98169720e-01, 1.83023955e-03],\n",
      "       [9.99079823e-01, 9.20150953e-04],\n",
      "       [9.99992907e-01, 7.04111380e-06],\n",
      "       [9.99998987e-01, 9.22112235e-07],\n",
      "       [1.15057081e-02, 9.88494277e-01],\n",
      "       [9.01869059e-01, 9.81309041e-02],\n",
      "       [1.02593191e-01, 8.97406757e-01],\n",
      "       [9.93260860e-01, 6.73907530e-03],\n",
      "       [9.99984324e-01, 1.55878952e-05],\n",
      "       [7.09027588e-01, 2.90972412e-01],\n",
      "       [9.99673128e-01, 3.26883601e-04],\n",
      "       [9.90035117e-01, 9.96495318e-03],\n",
      "       [9.99995172e-01, 4.72639749e-06],\n",
      "       [2.38576923e-02, 9.76142228e-01],\n",
      "       [9.87472415e-01, 1.25276018e-02],\n",
      "       [1.96791068e-01, 8.03208947e-01],\n",
      "       [9.99999583e-01, 3.08011948e-07],\n",
      "       [1.59128085e-02, 9.84087050e-01],\n",
      "       [9.99945104e-01, 5.48294738e-05],\n",
      "       [8.41265321e-01, 1.58734694e-01],\n",
      "       [9.99997199e-01, 2.72665216e-06],\n",
      "       [9.99906719e-01, 9.32109688e-05],\n",
      "       [9.99999464e-01, 4.93181290e-07],\n",
      "       [4.62699026e-01, 5.37301064e-01],\n",
      "       [9.99942243e-01, 5.77160681e-05],\n",
      "       [9.99999821e-01, 1.10311177e-07],\n",
      "       [9.99818325e-01, 1.81611584e-04],\n",
      "       [5.48617065e-01, 4.51382905e-01],\n",
      "       [5.80465257e-01, 4.19534653e-01],\n",
      "       [1.56772661e-03, 9.98432159e-01],\n",
      "       [9.99982417e-01, 1.75817549e-05],\n",
      "       [9.99996603e-01, 3.36167022e-06],\n",
      "       [3.27147275e-01, 6.72852695e-01],\n",
      "       [7.12553203e-01, 2.87446797e-01],\n",
      "       [9.99958813e-01, 4.11654983e-05],\n",
      "       [7.67669082e-02, 9.23233032e-01],\n",
      "       [9.99999821e-01, 6.95587232e-08],\n",
      "       [9.87210989e-01, 1.27890687e-02],\n",
      "       [9.99999821e-01, 9.52059764e-08],\n",
      "       [6.99395180e-01, 3.00604701e-01],\n",
      "       [9.99993384e-01, 6.58908812e-06],\n",
      "       [9.99620855e-01, 3.79136181e-04],\n",
      "       [9.99984324e-01, 1.55960151e-05],\n",
      "       [9.99563038e-01, 4.36996459e-04],\n",
      "       [9.99931395e-01, 6.85837003e-05],\n",
      "       [9.06749547e-01, 9.32503864e-02],\n",
      "       [9.99975860e-01, 2.40884547e-05],\n",
      "       [3.56897563e-02, 9.64310229e-01],\n",
      "       [2.33396307e-01, 7.66603768e-01],\n",
      "       [2.39915505e-01, 7.60084391e-01],\n",
      "       [8.59787166e-01, 1.40212774e-01],\n",
      "       [9.99968231e-01, 3.17079757e-05],\n",
      "       [9.99673605e-01, 3.26395617e-04],\n",
      "       [7.02213585e-01, 2.97786504e-01],\n",
      "       [9.99984324e-01, 1.56658516e-05],\n",
      "       [1.21958189e-01, 8.78041804e-01],\n",
      "       [6.84322596e-01, 3.15677404e-01],\n",
      "       [8.53990838e-02, 9.14600909e-01],\n",
      "       [8.96179497e-01, 1.03820398e-01],\n",
      "       [9.99704599e-01, 2.95426871e-04],\n",
      "       [9.99993384e-01, 6.59553234e-06],\n",
      "       [1.33010345e-02, 9.86699045e-01],\n",
      "       [1.51377723e-01, 8.48622322e-01],\n",
      "       [9.99852419e-01, 1.47628030e-04],\n",
      "       [8.78570437e-01, 1.21429563e-01],\n",
      "       [9.99866247e-01, 1.33905123e-04],\n",
      "       [1.84980422e-01, 8.15019548e-01],\n",
      "       [2.53648788e-04, 9.99746442e-01],\n",
      "       [9.25578058e-01, 7.44218454e-02],\n",
      "       [9.63377416e-01, 3.66225429e-02],\n",
      "       [9.99104500e-01, 8.95558565e-04],\n",
      "       [9.99900520e-01, 9.94191505e-05],\n",
      "       [7.25057542e-01, 2.74942487e-01],\n",
      "       [9.99476731e-01, 5.23156719e-04],\n",
      "       [8.13103080e-01, 1.86896831e-01],\n",
      "       [9.97724950e-01, 2.27503362e-03],\n",
      "       [9.99998629e-01, 1.36556559e-06],\n",
      "       [9.82832611e-01, 1.71674155e-02],\n",
      "       [9.99981463e-01, 1.85004574e-05],\n",
      "       [4.43766750e-02, 9.55623388e-01],\n",
      "       [9.99898970e-01, 1.00928773e-04],\n",
      "       [9.99201119e-01, 7.98954978e-04],\n",
      "       [1.78984180e-01, 8.21015775e-01],\n",
      "       [9.99980450e-01, 1.95802986e-05]], dtype=float32))\n",
      "\n",
      " class (array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 1]), array([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "1\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TP: 228     FP: 208     FN: 22     TN: 42\n",
      "PPV: 0.5229\n",
      "Advantage: 0.0800\n",
      "Accuracy:  0.54 Precision:  0.5229357798165137\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00283ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a3c22a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset\n",
    "train_size = 500\n",
    "attack_test_size = 250\n",
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_30K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_nonmembers = attack_test_nonmembers.sample(n=attack_test_size, replace=False)\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_5K.csv', na_values=[\"?\"], header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d85d391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7000\n",
    "target_dataset = pd.read_csv('data/adult_sds_cac.csv', na_values=[\"?\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0487e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  88.42856884002686 Target Test acc :  85.10000109672546\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "is_synthetic = True\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e4bf13de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  90.28571248054504 Shadow Test acc :  74.2222249507904\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  95.99999785423279 Shadow Test acc :  82.22222328186035\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  91.6190505027771 Shadow Test acc :  78.66666913032532\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  93.52381229400635 Shadow Test acc :  83.11111330986023\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  93.71428489685059 Shadow Test acc :  79.11111116409302\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  90.28571248054504 Shadow Test acc :  80.88889122009277\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  94.28571462631226 Shadow Test acc :  72.00000286102295\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  93.9047634601593 Shadow Test acc :  79.55555319786072\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  92.19047427177429 Shadow Test acc :  83.55555534362793\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  92.76190400123596 Shadow Test acc :  74.6666669845581\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  94.28571462631226 Shadow Test acc :  74.2222249507904\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  93.52381229400635 Shadow Test acc :  80.4444432258606\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  93.9047634601593 Shadow Test acc :  73.33333492279053\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  93.14285516738892 Shadow Test acc :  73.77777695655823\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  91.80952310562134 Shadow Test acc :  82.66666531562805\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  93.52381229400635 Shadow Test acc :  77.33333110809326\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  97.14285731315613 Shadow Test acc :  77.77777910232544\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  93.9047634601593 Shadow Test acc :  81.77777528762817\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  94.85714435577393 Shadow Test acc :  79.11111116409302\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  95.23809552192688 Shadow Test acc :  76.44444704055786\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 750\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "be986b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "\n",
      " pred (array([[9.99557793e-01, 4.42208780e-04],\n",
      "       [3.47070545e-01, 6.52929485e-01],\n",
      "       [9.99999821e-01, 6.52376428e-08],\n",
      "       [9.99990165e-01, 9.73688657e-06],\n",
      "       [9.80585933e-01, 1.94141194e-02],\n",
      "       [9.99998987e-01, 9.07824017e-07],\n",
      "       [9.99995291e-01, 4.70001305e-06],\n",
      "       [9.99981701e-01, 1.82892691e-05],\n",
      "       [9.99839067e-01, 1.60868527e-04],\n",
      "       [7.04952061e-01, 2.95047909e-01],\n",
      "       [9.99254346e-01, 7.45724828e-04],\n",
      "       [9.99211967e-01, 7.88065838e-04],\n",
      "       [9.96637583e-01, 3.36239929e-03],\n",
      "       [9.99999940e-01, 3.40392603e-08],\n",
      "       [9.99998987e-01, 9.28207101e-07],\n",
      "       [9.95667636e-01, 4.33224207e-03],\n",
      "       [1.13499640e-02, 9.88650084e-01],\n",
      "       [1.79487653e-03, 9.98205066e-01],\n",
      "       [5.18777315e-03, 9.94812191e-01],\n",
      "       [9.99991238e-01, 8.64630329e-06],\n",
      "       [1.40724529e-03, 9.98592734e-01],\n",
      "       [9.99790907e-01, 2.09024132e-04],\n",
      "       [4.72671054e-02, 9.52732921e-01],\n",
      "       [4.22324806e-01, 5.77675223e-01],\n",
      "       [1.64369009e-02, 9.83563006e-01],\n",
      "       [9.99074578e-01, 9.25423694e-04],\n",
      "       [9.97956157e-01, 2.04370078e-03],\n",
      "       [9.58808780e-01, 4.11911085e-02],\n",
      "       [9.99286413e-01, 7.13593734e-04],\n",
      "       [4.66498882e-01, 5.33501089e-01],\n",
      "       [9.99990761e-01, 9.12791438e-06],\n",
      "       [7.69968338e-08, 9.99999821e-01],\n",
      "       [9.99991477e-01, 8.40506618e-06],\n",
      "       [4.00240183e-01, 5.99759698e-01],\n",
      "       [2.30880714e-11, 9.99999940e-01],\n",
      "       [9.83288586e-01, 1.67114660e-02],\n",
      "       [4.51307325e-03, 9.95486856e-01],\n",
      "       [9.99235630e-01, 7.64403143e-04],\n",
      "       [1.35234818e-02, 9.86476481e-01],\n",
      "       [9.99979436e-01, 2.05100550e-05],\n",
      "       [9.98106539e-01, 1.89336622e-03],\n",
      "       [9.99971449e-01, 2.85434635e-05],\n",
      "       [9.99996722e-01, 3.25364726e-06],\n",
      "       [9.99947488e-01, 5.24451607e-05],\n",
      "       [9.91006494e-01, 8.99340585e-03],\n",
      "       [9.98894572e-01, 1.10547931e-03],\n",
      "       [9.99962389e-01, 3.74914343e-05],\n",
      "       [6.45424565e-03, 9.93545711e-01],\n",
      "       [9.85846400e-01, 1.41536724e-02],\n",
      "       [2.37152926e-04, 9.99762774e-01],\n",
      "       [9.96880829e-01, 3.11918254e-03],\n",
      "       [9.95927036e-01, 4.07291390e-03],\n",
      "       [9.99319375e-01, 6.80555939e-04],\n",
      "       [9.99678254e-01, 3.21758795e-04],\n",
      "       [6.56015242e-11, 9.99999940e-01],\n",
      "       [9.99759197e-01, 2.40888752e-04],\n",
      "       [4.94605005e-02, 9.50539529e-01],\n",
      "       [9.99307871e-01, 6.92142523e-04],\n",
      "       [9.94580805e-01, 5.41916071e-03],\n",
      "       [9.98462856e-01, 1.53714558e-03],\n",
      "       [9.99999821e-01, 1.74060830e-07],\n",
      "       [9.99415278e-01, 5.84561785e-04],\n",
      "       [1.44151971e-01, 8.55847955e-01],\n",
      "       [7.94684947e-01, 2.05315039e-01],\n",
      "       [9.66044009e-01, 3.39559354e-02],\n",
      "       [8.59798372e-01, 1.40201643e-01],\n",
      "       [9.99696493e-01, 3.03485664e-04],\n",
      "       [9.55165744e-01, 4.48341779e-02],\n",
      "       [3.64789099e-01, 6.35210872e-01],\n",
      "       [6.58425212e-01, 3.41574818e-01],\n",
      "       [2.13211268e-01, 7.86788702e-01],\n",
      "       [9.99999464e-01, 4.58214771e-07],\n",
      "       [9.85883236e-01, 1.41167520e-02],\n",
      "       [9.99978840e-01, 2.11224306e-05],\n",
      "       [5.21788359e-01, 4.78211552e-01],\n",
      "       [1.30060554e-01, 8.69939387e-01],\n",
      "       [9.99702692e-01, 2.97298451e-04],\n",
      "       [6.00723565e-01, 3.99276435e-01],\n",
      "       [6.69849664e-02, 9.33014989e-01],\n",
      "       [5.69601536e-01, 4.30398434e-01],\n",
      "       [3.73765409e-01, 6.26234591e-01],\n",
      "       [9.99847412e-01, 1.52542416e-04],\n",
      "       [9.99320328e-01, 6.79569435e-04],\n",
      "       [9.99991953e-01, 8.02709110e-06],\n",
      "       [9.99641418e-01, 3.58550111e-04],\n",
      "       [9.98667955e-01, 1.33201247e-03],\n",
      "       [2.72581559e-02, 9.72741842e-01],\n",
      "       [9.99956071e-01, 4.38349962e-05],\n",
      "       [9.99999821e-01, 1.51850841e-07],\n",
      "       [2.81744421e-01, 7.18255579e-01],\n",
      "       [9.99978721e-01, 2.12401537e-05],\n",
      "       [9.99561846e-01, 4.38153133e-04],\n",
      "       [8.07313442e-01, 1.92686528e-01],\n",
      "       [1.32687546e-12, 9.99999940e-01],\n",
      "       [1.38725103e-22, 9.99999940e-01],\n",
      "       [9.99994934e-01, 4.99576981e-06],\n",
      "       [9.99988377e-01, 1.15434041e-05],\n",
      "       [9.99904692e-01, 9.52840783e-05],\n",
      "       [9.99831915e-01, 1.68230370e-04],\n",
      "       [9.99424100e-01, 5.75922488e-04],\n",
      "       [9.97449756e-01, 2.55030137e-03],\n",
      "       [9.97813225e-01, 2.18669837e-03],\n",
      "       [9.99960363e-01, 3.95930292e-05],\n",
      "       [9.06250417e-01, 9.37496051e-02],\n",
      "       [9.98646080e-01, 1.35398004e-03],\n",
      "       [8.64075869e-02, 9.13592398e-01],\n",
      "       [9.35111403e-01, 6.48885965e-02],\n",
      "       [9.98024940e-01, 1.97511236e-03],\n",
      "       [5.88971972e-01, 4.11028057e-01],\n",
      "       [9.99897778e-01, 1.02161619e-04],\n",
      "       [3.18871677e-01, 6.81128383e-01],\n",
      "       [9.52839971e-01, 4.71599922e-02],\n",
      "       [9.93091226e-01, 6.90869428e-03],\n",
      "       [9.99336064e-01, 6.63958665e-04],\n",
      "       [9.12855923e-01, 8.71439725e-02],\n",
      "       [9.99352872e-01, 6.47173438e-04],\n",
      "       [6.60677910e-01, 3.39322031e-01],\n",
      "       [9.99966204e-01, 3.37486781e-05],\n",
      "       [9.91974592e-01, 8.02532956e-03],\n",
      "       [9.99900043e-01, 9.98652467e-05],\n",
      "       [9.99776840e-01, 2.23208568e-04],\n",
      "       [9.97331321e-01, 2.66861753e-03],\n",
      "       [9.99255300e-01, 7.44714926e-04],\n",
      "       [9.08217669e-01, 9.17822272e-02],\n",
      "       [9.99999821e-01, 8.86581546e-08],\n",
      "       [9.99991953e-01, 7.94954576e-06],\n",
      "       [1.54438734e-01, 8.45561266e-01],\n",
      "       [9.08999801e-01, 9.10001621e-02],\n",
      "       [9.99976933e-01, 2.29598227e-05],\n",
      "       [9.99695301e-01, 3.04764952e-04],\n",
      "       [9.99290705e-01, 7.09267741e-04],\n",
      "       [9.97382343e-01, 2.61768233e-03],\n",
      "       [9.98494744e-01, 1.50521309e-03],\n",
      "       [6.56740442e-02, 9.34325874e-01],\n",
      "       [9.99715686e-01, 2.84343580e-04],\n",
      "       [9.99632895e-01, 3.67172470e-04],\n",
      "       [2.46141339e-04, 9.99753952e-01],\n",
      "       [9.99960721e-01, 3.91713838e-05],\n",
      "       [9.98073936e-01, 1.92603609e-03],\n",
      "       [4.52187005e-03, 9.95478213e-01],\n",
      "       [6.31200612e-01, 3.68799359e-01],\n",
      "       [9.08042967e-01, 9.19569731e-02],\n",
      "       [9.91213143e-01, 8.78671650e-03],\n",
      "       [9.34737265e-01, 6.52627349e-02],\n",
      "       [8.43088746e-01, 1.56911179e-01],\n",
      "       [1.28506153e-05, 9.99987066e-01],\n",
      "       [5.72275460e-01, 4.27724510e-01],\n",
      "       [9.99986470e-01, 1.35283635e-05],\n",
      "       [9.99974668e-01, 2.52374011e-05],\n",
      "       [9.99843597e-01, 1.56461130e-04],\n",
      "       [9.99975622e-01, 2.43703034e-05],\n",
      "       [9.89426672e-01, 1.05732409e-02],\n",
      "       [7.26778030e-01, 2.73221940e-01],\n",
      "       [9.99978125e-01, 2.18355181e-05],\n",
      "       [9.99639034e-01, 3.60987673e-04],\n",
      "       [2.82451034e-01, 7.17548907e-01],\n",
      "       [9.98280525e-01, 1.71945163e-03],\n",
      "       [6.64124127e-06, 9.99993265e-01],\n",
      "       [9.99999702e-01, 2.11243403e-07],\n",
      "       [9.99883473e-01, 1.16481002e-04],\n",
      "       [4.57509518e-01, 5.42490542e-01],\n",
      "       [1.17039688e-01, 8.82960379e-01],\n",
      "       [8.18235993e-01, 1.81764007e-01],\n",
      "       [9.99852657e-01, 1.47294049e-04],\n",
      "       [9.99551952e-01, 4.47980012e-04],\n",
      "       [9.99824286e-01, 1.75778434e-04],\n",
      "       [9.99990880e-01, 9.10263680e-06],\n",
      "       [9.27877903e-01, 7.21219927e-02],\n",
      "       [9.99831200e-01, 1.68735904e-04],\n",
      "       [1.09709270e-01, 8.90290737e-01],\n",
      "       [1.05370142e-01, 8.94629896e-01],\n",
      "       [6.05262585e-13, 9.99999940e-01],\n",
      "       [9.99934614e-01, 6.53700044e-05],\n",
      "       [6.93515321e-05, 9.99930561e-01],\n",
      "       [9.97528195e-01, 2.47178832e-03],\n",
      "       [8.06130469e-03, 9.91938651e-01],\n",
      "       [4.59253713e-02, 9.54074740e-01],\n",
      "       [9.99989331e-01, 1.05499557e-05],\n",
      "       [9.99841690e-01, 1.58375973e-04],\n",
      "       [1.50133893e-01, 8.49866033e-01],\n",
      "       [5.73647678e-01, 4.26352441e-01],\n",
      "       [9.55747092e-13, 9.99999940e-01],\n",
      "       [5.47690988e-02, 9.45230901e-01],\n",
      "       [9.22806919e-01, 7.71930218e-02],\n",
      "       [9.99951184e-01, 4.87245234e-05],\n",
      "       [4.94520426e-01, 5.05479693e-01],\n",
      "       [9.99973714e-01, 2.61671466e-05],\n",
      "       [6.40753686e-01, 3.59246254e-01],\n",
      "       [2.47323096e-01, 7.52676845e-01],\n",
      "       [9.99989092e-01, 1.08302456e-05],\n",
      "       [7.22555891e-02, 9.27744567e-01],\n",
      "       [1.19281411e-01, 8.80718529e-01],\n",
      "       [9.92518723e-01, 7.48128910e-03],\n",
      "       [9.61527288e-01, 3.84726115e-02],\n",
      "       [3.43923494e-02, 9.65607524e-01],\n",
      "       [9.99882519e-01, 1.17361669e-04],\n",
      "       [9.89256144e-01, 1.07438713e-02],\n",
      "       [9.99999821e-01, 6.30947241e-08],\n",
      "       [9.99996364e-01, 3.52815005e-06],\n",
      "       [9.99916852e-01, 8.30224380e-05],\n",
      "       [9.98778462e-01, 1.22162129e-03],\n",
      "       [9.96146560e-01, 3.85340443e-03],\n",
      "       [6.42002583e-01, 3.57997298e-01],\n",
      "       [9.99967277e-01, 3.26528389e-05],\n",
      "       [9.99996603e-01, 3.35057030e-06],\n",
      "       [9.99549329e-01, 4.50613152e-04],\n",
      "       [9.99940693e-01, 5.92241231e-05],\n",
      "       [9.94497597e-01, 5.50244423e-03],\n",
      "       [9.99617994e-01, 3.82006489e-04],\n",
      "       [9.99968231e-01, 3.17301492e-05],\n",
      "       [9.99436021e-01, 5.64047601e-04],\n",
      "       [9.98657465e-01, 1.34249544e-03],\n",
      "       [9.99791861e-01, 2.08084966e-04],\n",
      "       [6.80121556e-02, 9.31987822e-01],\n",
      "       [9.98436213e-01, 1.56383635e-03],\n",
      "       [2.64955275e-02, 9.73504424e-01],\n",
      "       [3.92542773e-07, 9.99999583e-01],\n",
      "       [1.28328785e-01, 8.71671140e-01],\n",
      "       [9.99718547e-01, 2.81485001e-04],\n",
      "       [9.71617937e-01, 2.83820853e-02],\n",
      "       [2.88528632e-02, 9.71147060e-01],\n",
      "       [1.09039582e-01, 8.90960395e-01],\n",
      "       [5.69594886e-05, 9.99942958e-01],\n",
      "       [3.77533823e-01, 6.22466207e-01],\n",
      "       [3.12969297e-01, 6.87030733e-01],\n",
      "       [9.99997556e-01, 2.34605409e-06],\n",
      "       [8.46410543e-02, 9.15358901e-01],\n",
      "       [9.99966681e-01, 3.32849995e-05],\n",
      "       [8.96614730e-01, 1.03385255e-01],\n",
      "       [9.99981940e-01, 1.80053976e-05],\n",
      "       [9.99999821e-01, 8.12310788e-08],\n",
      "       [3.92373383e-01, 6.07626557e-01],\n",
      "       [9.97922659e-01, 2.07747729e-03],\n",
      "       [9.99999940e-01, 5.84303770e-08],\n",
      "       [9.99463916e-01, 5.36056876e-04],\n",
      "       [9.99952376e-01, 4.75057714e-05],\n",
      "       [9.99641418e-01, 3.58550111e-04],\n",
      "       [9.99110222e-01, 8.89749266e-04],\n",
      "       [9.99939382e-01, 6.05668465e-05],\n",
      "       [9.63246275e-04, 9.99036729e-01],\n",
      "       [9.99721050e-01, 2.78969062e-04],\n",
      "       [9.98801231e-01, 1.19885686e-03],\n",
      "       [2.02123430e-02, 9.79787648e-01],\n",
      "       [1.48040414e-22, 9.99999940e-01],\n",
      "       [9.99228358e-01, 7.71627412e-04],\n",
      "       [2.17625318e-04, 9.99782324e-01],\n",
      "       [1.70761570e-02, 9.82923746e-01],\n",
      "       [1.71625495e-01, 8.28374445e-01],\n",
      "       [1.31371170e-01, 8.68628800e-01],\n",
      "       [9.99368966e-01, 6.31082279e-04]], dtype=float32), array([[7.80084252e-01, 2.19915792e-01],\n",
      "       [9.92757976e-01, 7.24192103e-03],\n",
      "       [4.60726172e-01, 5.39273858e-01],\n",
      "       [1.06805541e-01, 8.93194497e-01],\n",
      "       [4.39955682e-01, 5.60044229e-01],\n",
      "       [9.99999821e-01, 6.25738679e-08],\n",
      "       [7.73670614e-01, 2.26329446e-01],\n",
      "       [9.98064220e-01, 1.93576957e-03],\n",
      "       [1.04895353e-01, 8.95104647e-01],\n",
      "       [9.99654770e-01, 3.45189677e-04],\n",
      "       [9.99935687e-01, 6.42268642e-05],\n",
      "       [9.99725223e-01, 2.74785096e-04],\n",
      "       [9.99999821e-01, 6.15465581e-08],\n",
      "       [2.76439241e-04, 9.99723554e-01],\n",
      "       [9.99792099e-01, 2.08005658e-04],\n",
      "       [9.99999464e-01, 4.48230338e-07],\n",
      "       [9.99397397e-01, 6.02443295e-04],\n",
      "       [9.99938309e-01, 6.16571269e-05],\n",
      "       [9.98489738e-01, 1.51021499e-03],\n",
      "       [6.33478388e-02, 9.36652184e-01],\n",
      "       [9.99942124e-01, 5.78319850e-05],\n",
      "       [7.11260438e-02, 9.28874016e-01],\n",
      "       [9.99886930e-01, 1.12956237e-04],\n",
      "       [9.23064232e-01, 7.69357756e-02],\n",
      "       [9.99996483e-01, 3.40415772e-06],\n",
      "       [9.99978840e-01, 2.10610415e-05],\n",
      "       [9.99698281e-01, 3.01694177e-04],\n",
      "       [5.17833412e-01, 4.82166648e-01],\n",
      "       [9.99802351e-01, 1.97695030e-04],\n",
      "       [3.00075322e-01, 6.99924707e-01],\n",
      "       [9.99999940e-01, 2.69524492e-08],\n",
      "       [9.59528029e-01, 4.04720418e-02],\n",
      "       [9.99789953e-01, 2.10145430e-04],\n",
      "       [8.78310204e-01, 1.21689774e-01],\n",
      "       [9.79788005e-01, 2.02118568e-02],\n",
      "       [9.99975264e-01, 2.46771360e-05],\n",
      "       [4.62283999e-01, 5.37716031e-01],\n",
      "       [9.99967515e-01, 3.24715584e-05],\n",
      "       [9.99940693e-01, 5.92521465e-05],\n",
      "       [9.99670744e-01, 3.29274189e-04],\n",
      "       [1.91053867e-01, 8.08946192e-01],\n",
      "       [1.80730969e-02, 9.81926858e-01],\n",
      "       [9.95189011e-01, 4.81087295e-03],\n",
      "       [1.18602365e-01, 8.81397545e-01],\n",
      "       [5.65180600e-01, 4.34819371e-01],\n",
      "       [1.36450678e-01, 8.63549352e-01],\n",
      "       [9.69866276e-01, 3.01337168e-02],\n",
      "       [9.99621451e-01, 3.78572964e-04],\n",
      "       [9.93886530e-01, 6.11350033e-03],\n",
      "       [9.99881923e-01, 1.18056014e-04],\n",
      "       [9.99980390e-01, 1.95549164e-05],\n",
      "       [9.99422669e-01, 5.77345083e-04],\n",
      "       [9.99992430e-01, 7.53484164e-06],\n",
      "       [9.99255896e-01, 7.44132150e-04],\n",
      "       [9.99658704e-01, 3.41328589e-04],\n",
      "       [9.43504989e-01, 5.64949922e-02],\n",
      "       [1.55155972e-01, 8.44843984e-01],\n",
      "       [9.78508651e-01, 2.14912295e-02],\n",
      "       [9.99998748e-01, 1.24921166e-06],\n",
      "       [9.94821429e-01, 5.17853815e-03],\n",
      "       [9.99999940e-01, 7.40060146e-09],\n",
      "       [9.99431968e-01, 5.67932962e-04],\n",
      "       [9.99797106e-01, 2.02823096e-04],\n",
      "       [9.99410272e-01, 5.89786156e-04],\n",
      "       [9.99972045e-01, 2.78834395e-05],\n",
      "       [9.99400496e-01, 5.99551306e-04],\n",
      "       [3.09659000e-02, 9.69034135e-01],\n",
      "       [7.65445158e-02, 9.23455477e-01],\n",
      "       [9.99999225e-01, 6.97185726e-07],\n",
      "       [9.44155753e-01, 5.58442287e-02],\n",
      "       [9.01222885e-01, 9.87770855e-02],\n",
      "       [9.99997795e-01, 2.11580209e-06],\n",
      "       [9.99900281e-01, 9.96719391e-05],\n",
      "       [9.99873161e-01, 1.26938423e-04],\n",
      "       [9.99768734e-01, 2.31364145e-04],\n",
      "       [9.99669552e-01, 3.30480863e-04],\n",
      "       [9.99977529e-01, 2.23801981e-05],\n",
      "       [8.50614190e-01, 1.49385706e-01],\n",
      "       [9.99977887e-01, 2.21071932e-05],\n",
      "       [9.99386370e-01, 6.13631273e-04],\n",
      "       [9.99999106e-01, 8.93577464e-07],\n",
      "       [9.99999583e-01, 3.97604623e-07],\n",
      "       [9.03488398e-01, 9.65116173e-02],\n",
      "       [6.35777831e-01, 3.64222199e-01],\n",
      "       [1.47390768e-01, 8.52609158e-01],\n",
      "       [7.92165041e-01, 2.07834974e-01],\n",
      "       [9.99113321e-01, 8.86634924e-04],\n",
      "       [9.36074793e-01, 6.39251322e-02],\n",
      "       [9.99964535e-01, 3.53456599e-05],\n",
      "       [1.12431264e-08, 9.99999940e-01],\n",
      "       [9.99917686e-01, 8.22508155e-05],\n",
      "       [9.99083638e-01, 9.16379213e-04],\n",
      "       [9.99824047e-01, 1.76100206e-04],\n",
      "       [9.92704213e-01, 7.29576033e-03],\n",
      "       [9.99797344e-01, 2.02676572e-04],\n",
      "       [2.16244176e-01, 7.83755779e-01],\n",
      "       [9.99847174e-01, 1.52797613e-04],\n",
      "       [9.43356276e-01, 5.66437207e-02],\n",
      "       [9.05041873e-01, 9.49581265e-02],\n",
      "       [3.32378950e-05, 9.99966681e-01],\n",
      "       [1.44807044e-02, 9.85519290e-01],\n",
      "       [3.04358322e-02, 9.69564140e-01],\n",
      "       [9.99999940e-01, 2.15791758e-08],\n",
      "       [9.99999702e-01, 2.71813661e-07],\n",
      "       [9.88067389e-01, 1.19326571e-02],\n",
      "       [9.99744773e-01, 2.55339750e-04],\n",
      "       [9.49544430e-01, 5.04555032e-02],\n",
      "       [9.99957383e-01, 4.25482685e-05],\n",
      "       [9.99999940e-01, 3.27364873e-08],\n",
      "       [9.99999940e-01, 5.54516575e-08],\n",
      "       [9.93671954e-01, 6.32800767e-03],\n",
      "       [9.99688029e-01, 3.11973912e-04],\n",
      "       [4.87886161e-01, 5.12113810e-01],\n",
      "       [9.99838352e-01, 1.61787233e-04],\n",
      "       [9.99709606e-01, 2.90447060e-04],\n",
      "       [8.45352948e-01, 1.54647037e-01],\n",
      "       [3.88064757e-02, 9.61193442e-01],\n",
      "       [5.42444643e-04, 9.99457479e-01],\n",
      "       [9.99599159e-01, 4.00901656e-04],\n",
      "       [3.75344008e-02, 9.62465644e-01],\n",
      "       [9.98868346e-01, 1.13161176e-03],\n",
      "       [9.99993622e-01, 6.34557955e-06],\n",
      "       [1.29094139e-01, 8.70905876e-01],\n",
      "       [9.99662280e-01, 3.37722886e-04],\n",
      "       [9.99840736e-01, 1.59262927e-04],\n",
      "       [9.99826431e-01, 1.73626919e-04],\n",
      "       [8.70437741e-01, 1.29562259e-01],\n",
      "       [9.99484718e-01, 5.15173771e-04],\n",
      "       [2.77492609e-06, 9.99997199e-01],\n",
      "       [3.13584097e-02, 9.68641639e-01],\n",
      "       [9.96643782e-01, 3.35623370e-03],\n",
      "       [3.83005477e-02, 9.61699486e-01],\n",
      "       [3.97662789e-01, 6.02337241e-01],\n",
      "       [9.99668241e-01, 3.31711926e-04],\n",
      "       [8.43815433e-05, 9.99915540e-01],\n",
      "       [9.90694582e-01, 9.30530299e-03],\n",
      "       [9.41625416e-01, 5.83746023e-02],\n",
      "       [4.34970409e-02, 9.56502914e-01],\n",
      "       [9.90085423e-01, 9.91469622e-03],\n",
      "       [5.55884719e-01, 4.44115371e-01],\n",
      "       [9.99998629e-01, 1.27072451e-06],\n",
      "       [9.99996603e-01, 3.32250534e-06],\n",
      "       [9.99351323e-01, 6.48646150e-04],\n",
      "       [3.84033888e-10, 9.99999940e-01],\n",
      "       [9.99249458e-01, 7.50538136e-04],\n",
      "       [9.92129028e-01, 7.87099265e-03],\n",
      "       [9.99727964e-01, 2.72115460e-04],\n",
      "       [9.98050869e-01, 1.94905407e-03],\n",
      "       [9.99595106e-01, 4.04966122e-04],\n",
      "       [9.99937117e-01, 6.27867848e-05],\n",
      "       [9.99079704e-01, 9.20286402e-04],\n",
      "       [9.81778443e-01, 1.82215516e-02],\n",
      "       [9.99997675e-01, 2.22195604e-06],\n",
      "       [9.96081471e-01, 3.91843589e-03],\n",
      "       [9.99982297e-01, 1.76521989e-05],\n",
      "       [9.63903904e-01, 3.60960923e-02],\n",
      "       [9.99211729e-01, 7.88357982e-04],\n",
      "       [5.74113488e-01, 4.25886542e-01],\n",
      "       [2.78410077e-01, 7.21589983e-01],\n",
      "       [2.98750162e-01, 7.01249778e-01],\n",
      "       [9.98508096e-01, 1.49189297e-03],\n",
      "       [9.98538673e-01, 1.46122812e-03],\n",
      "       [9.99801874e-01, 1.98040259e-04],\n",
      "       [9.67730939e-01, 3.22691202e-02],\n",
      "       [9.99999940e-01, 1.17801513e-09],\n",
      "       [9.70975399e-01, 2.90246494e-02],\n",
      "       [9.99988616e-01, 1.13195110e-05],\n",
      "       [9.99999821e-01, 8.24168538e-08],\n",
      "       [9.67018485e-01, 3.29814442e-02],\n",
      "       [8.97090077e-01, 1.02909841e-01],\n",
      "       [9.99982178e-01, 1.77465699e-05],\n",
      "       [2.58529471e-04, 9.99741554e-01],\n",
      "       [9.99924481e-01, 7.54791909e-05],\n",
      "       [1.08506486e-01, 8.91493440e-01],\n",
      "       [5.49000144e-01, 4.50999826e-01],\n",
      "       [9.92141008e-01, 7.85897486e-03],\n",
      "       [8.31035078e-01, 1.68964952e-01],\n",
      "       [9.99948800e-01, 5.10788595e-05],\n",
      "       [2.52328015e-23, 9.99999940e-01],\n",
      "       [4.48717624e-01, 5.51282287e-01],\n",
      "       [1.03123387e-11, 9.99999940e-01],\n",
      "       [9.52448547e-01, 4.75514270e-02],\n",
      "       [9.99579608e-01, 4.20345750e-04],\n",
      "       [9.99950945e-01, 4.89443773e-05],\n",
      "       [9.91923392e-01, 8.07659421e-03],\n",
      "       [9.98553336e-01, 1.44659565e-03],\n",
      "       [1.56445135e-10, 9.99999940e-01],\n",
      "       [2.59066970e-21, 9.99999940e-01],\n",
      "       [3.94740641e-01, 6.05259299e-01],\n",
      "       [1.23543575e-01, 8.76456380e-01],\n",
      "       [6.74009264e-01, 3.25990617e-01],\n",
      "       [9.99985993e-01, 1.38950654e-05],\n",
      "       [8.69776487e-01, 1.30223542e-01],\n",
      "       [2.85475496e-02, 9.71452415e-01],\n",
      "       [9.96166408e-01, 3.83355026e-03],\n",
      "       [9.99920309e-01, 7.96315362e-05],\n",
      "       [3.05501908e-01, 6.94498122e-01],\n",
      "       [9.99944746e-01, 5.52428355e-05],\n",
      "       [9.71595764e-01, 2.84041669e-02],\n",
      "       [9.40669239e-01, 5.93308099e-02],\n",
      "       [4.07315105e-01, 5.92684984e-01],\n",
      "       [9.77387667e-01, 2.26124506e-02],\n",
      "       [9.99995291e-01, 4.68273493e-06],\n",
      "       [9.71887469e-01, 2.81124394e-02],\n",
      "       [9.99390960e-01, 6.09031529e-04],\n",
      "       [9.74050581e-01, 2.59493943e-02],\n",
      "       [9.99980390e-01, 1.95727171e-05],\n",
      "       [8.08370829e-01, 1.91629142e-01],\n",
      "       [9.99976218e-01, 2.37017339e-05],\n",
      "       [9.98741806e-01, 1.25826255e-03],\n",
      "       [9.99944150e-01, 5.57816820e-05],\n",
      "       [9.99887764e-01, 1.12192152e-04],\n",
      "       [9.99992430e-01, 7.45665875e-06],\n",
      "       [9.96221006e-01, 3.77897685e-03],\n",
      "       [8.27850495e-03, 9.91721451e-01],\n",
      "       [9.99982417e-01, 1.75508794e-05],\n",
      "       [5.57660043e-01, 4.42339897e-01],\n",
      "       [1.69242071e-25, 9.99999940e-01],\n",
      "       [7.18111843e-02, 9.28188920e-01],\n",
      "       [9.97810364e-01, 2.18968466e-03],\n",
      "       [9.99937952e-01, 6.19476778e-05],\n",
      "       [9.99535859e-01, 4.64147102e-04],\n",
      "       [5.57978153e-01, 4.42021906e-01],\n",
      "       [7.73769557e-01, 2.26230338e-01],\n",
      "       [2.71347514e-03, 9.97286499e-01],\n",
      "       [4.64851474e-24, 9.99999940e-01],\n",
      "       [9.99999344e-01, 5.40452447e-07],\n",
      "       [9.96975422e-01, 3.02463560e-03],\n",
      "       [9.99998629e-01, 1.36128381e-06],\n",
      "       [9.99989212e-01, 1.07471442e-05],\n",
      "       [3.06544453e-01, 6.93455517e-01],\n",
      "       [9.99973714e-01, 2.62422454e-05],\n",
      "       [6.96828806e-07, 9.99999225e-01],\n",
      "       [6.52836621e-01, 3.47163349e-01],\n",
      "       [6.49854362e-01, 3.50145638e-01],\n",
      "       [9.99711156e-01, 2.88889743e-04],\n",
      "       [8.03531468e-01, 1.96468517e-01],\n",
      "       [9.99978483e-01, 2.14899883e-05],\n",
      "       [9.86942053e-01, 1.30579602e-02],\n",
      "       [2.46024966e-01, 7.53975093e-01],\n",
      "       [2.50906944e-01, 7.49092937e-01],\n",
      "       [9.99743819e-01, 2.56218394e-04],\n",
      "       [9.62223113e-03, 9.90377724e-01],\n",
      "       [9.99847651e-01, 1.52471912e-04],\n",
      "       [9.78104591e-01, 2.18952969e-02],\n",
      "       [1.37673244e-01, 8.62326741e-01],\n",
      "       [9.99063790e-01, 9.36169119e-04],\n",
      "       [9.99962866e-01, 3.70969501e-05],\n",
      "       [8.92259657e-01, 1.07740358e-01],\n",
      "       [9.68835711e-01, 3.11642662e-02]], dtype=float32))\n",
      "\n",
      " class (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 0, 0]), array([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "1\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "TP: 206     FP: 195     FN: 44     TN: 55\n",
      "PPV: 0.5137\n",
      "Advantage: 0.0440\n",
      "Accuracy:  0.522 Precision:  0.513715710723192\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bfee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abae907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "0c837158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 5000, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:7000,:].sample(n = 5000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b0648bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, training_data_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:training_data_size,]\n",
    "    testX = x[5000:,]\n",
    "    trainY = y[0:training_data_size,]\n",
    "    testY = y[5000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "6dcc78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Data Size:  2 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  63.599997758865356\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  37.43999898433685\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  75.95999836921692\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  24.220000207424164\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  55.86000084877014\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  77.48000025749207\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  40.939998626708984\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  42.739999294281006\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  41.31999909877777\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  76.03999972343445\n",
      "\n",
      " Training Data Size:  5 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  29.600000381469727\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  62.81999945640564\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  55.09999990463257\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  69.26000118255615\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  56.09999895095825\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  73.25999736785889\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  76.39999985694885\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  75.0\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  74.58000183105469\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  72.29999899864197\n",
      "\n",
      " Training Data Size:  10 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  67.739999294281\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  72.9200005531311\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  71.39999866485596\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  72.71999716758728\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  63.739997148513794\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  72.64000177383423\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  74.5199978351593\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  57.05999732017517\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  66.64000153541565\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  72.7400004863739\n",
      "\n",
      " Training Data Size:  15 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  57.440000772476196\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  75.76000094413757\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  70.67999839782715\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  74.01999831199646\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  77.34000086784363\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  71.21999859809875\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  71.84000015258789\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  71.82000279426575\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  73.7600028514862\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  73.90000224113464\n",
      "\n",
      " Training Data Size:  20 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  77.42000222206116\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  75.22000074386597\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  61.640000343322754\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  69.55999732017517\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  69.31999921798706\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  74.72000122070312\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  72.87999987602234\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  56.36000037193298\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  73.07999730110168\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  75.59999823570251\n",
      "\n",
      " Training Data Size:  25 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  73.46000075340271\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  70.89999914169312\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  71.57999873161316\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  79.36000227928162\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  72.64000177383423\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  65.28000235557556\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  71.21999859809875\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  79.22000288963318\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  79.65999841690063\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  78.79999876022339\n",
      "\n",
      " Training Data Size:  50 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  81.27999901771545\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  74.76000189781189\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  71.96000218391418\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  71.56000137329102\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  75.72000026702881\n",
      "Iteration  5 Target Train acc :  98.00000190734863 Target Test acc :  72.8600025177002\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  77.16000080108643\n",
      "Iteration  7 Target Train acc :  95.99999785423279 Target Test acc :  78.53999733924866\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  74.80000257492065\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  77.920001745224\n",
      "\n",
      " Training Data Size:  100 \n",
      "\n",
      "Iteration  0 Target Train acc :  98.00000190734863 Target Test acc :  79.37999963760376\n",
      "Iteration  1 Target Train acc :  99.00000095367432 Target Test acc :  80.86000084877014\n",
      "Iteration  2 Target Train acc :  99.00000095367432 Target Test acc :  79.24000024795532\n",
      "Iteration  3 Target Train acc :  93.00000071525574 Target Test acc :  79.46000099182129\n",
      "Iteration  4 Target Train acc :  93.00000071525574 Target Test acc :  72.35999703407288\n",
      "Iteration  5 Target Train acc :  88.99999856948853 Target Test acc :  79.42000031471252\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  82.09999799728394\n",
      "Iteration  7 Target Train acc :  99.00000095367432 Target Test acc :  75.77999830245972\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  78.47999930381775\n",
      "Iteration  9 Target Train acc :  98.00000190734863 Target Test acc :  80.94000220298767\n",
      "\n",
      " Training Data Size:  200 \n",
      "\n",
      "Iteration  0 Target Train acc :  98.50000143051147 Target Test acc :  80.55999875068665\n",
      "Iteration  1 Target Train acc :  98.00000190734863 Target Test acc :  76.85999870300293\n",
      "Iteration  2 Target Train acc :  91.50000214576721 Target Test acc :  80.65999746322632\n",
      "Iteration  3 Target Train acc :  94.9999988079071 Target Test acc :  77.67999768257141\n",
      "Iteration  4 Target Train acc :  95.49999833106995 Target Test acc :  80.09999990463257\n",
      "Iteration  5 Target Train acc :  94.9999988079071 Target Test acc :  80.98000288009644\n",
      "Iteration  6 Target Train acc :  99.00000095367432 Target Test acc :  81.05999827384949\n",
      "Iteration  7 Target Train acc :  93.50000023841858 Target Test acc :  80.1800012588501\n",
      "Iteration  8 Target Train acc :  98.50000143051147 Target Test acc :  76.8999993801117\n",
      "Iteration  9 Target Train acc :  99.50000047683716 Target Test acc :  80.19999861717224\n",
      "\n",
      " Training Data Size:  500 \n",
      "\n",
      "Iteration  0 Target Train acc :  97.39999771118164 Target Test acc :  79.42000031471252\n",
      "Iteration  1 Target Train acc :  92.79999732971191 Target Test acc :  75.0\n",
      "Iteration  2 Target Train acc :  97.39999771118164 Target Test acc :  79.28000092506409\n",
      "Iteration  3 Target Train acc :  96.39999866485596 Target Test acc :  81.44000172615051\n",
      "Iteration  4 Target Train acc :  95.99999785423279 Target Test acc :  80.51999807357788\n",
      "Iteration  5 Target Train acc :  92.00000166893005 Target Test acc :  80.55999875068665\n",
      "Iteration  6 Target Train acc :  97.39999771118164 Target Test acc :  79.97999787330627\n",
      "Iteration  7 Target Train acc :  94.40000057220459 Target Test acc :  80.09999990463257\n",
      "Iteration  8 Target Train acc :  97.2000002861023 Target Test acc :  80.3600013256073\n",
      "Iteration  9 Target Train acc :  96.60000205039978 Target Test acc :  79.68000173568726\n",
      "\n",
      " Training Data Size:  1000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 Target Train acc :  93.59999895095825 Target Test acc :  81.73999786376953\n",
      "Iteration  1 Target Train acc :  93.09999942779541 Target Test acc :  82.09999799728394\n",
      "Iteration  2 Target Train acc :  91.60000085830688 Target Test acc :  80.64000010490417\n",
      "Iteration  3 Target Train acc :  90.89999794960022 Target Test acc :  81.90000057220459\n",
      "Iteration  4 Target Train acc :  92.10000038146973 Target Test acc :  82.95999765396118\n",
      "Iteration  5 Target Train acc :  93.4000015258789 Target Test acc :  80.50000071525574\n",
      "Iteration  6 Target Train acc :  93.19999814033508 Target Test acc :  82.34000205993652\n",
      "Iteration  7 Target Train acc :  94.70000267028809 Target Test acc :  81.13999962806702\n",
      "Iteration  8 Target Train acc :  94.70000267028809 Target Test acc :  81.98000192642212\n",
      "Iteration  9 Target Train acc :  96.10000252723694 Target Test acc :  80.68000078201294\n",
      "\n",
      " Training Data Size:  2000 \n",
      "\n",
      "Iteration  0 Target Train acc :  91.20000004768372 Target Test acc :  82.03999996185303\n",
      "Iteration  1 Target Train acc :  91.14999771118164 Target Test acc :  80.7200014591217\n",
      "Iteration  2 Target Train acc :  90.49999713897705 Target Test acc :  82.22000002861023\n",
      "Iteration  3 Target Train acc :  89.0999972820282 Target Test acc :  83.49999785423279\n",
      "Iteration  4 Target Train acc :  91.64999723434448 Target Test acc :  81.99999928474426\n",
      "Iteration  5 Target Train acc :  88.89999985694885 Target Test acc :  82.34000205993652\n",
      "Iteration  6 Target Train acc :  93.00000071525574 Target Test acc :  81.22000098228455\n",
      "Iteration  7 Target Train acc :  90.70000052452087 Target Test acc :  81.66000247001648\n",
      "Iteration  8 Target Train acc :  92.10000038146973 Target Test acc :  83.93999934196472\n",
      "Iteration  9 Target Train acc :  91.29999876022339 Target Test acc :  82.27999806404114\n",
      "\n",
      " Training Data Size:  5000 \n",
      "\n",
      "Iteration  0 Target Train acc :  88.40000033378601 Target Test acc :  83.38000178337097\n",
      "Iteration  1 Target Train acc :  88.48000168800354 Target Test acc :  84.29999947547913\n",
      "Iteration  2 Target Train acc :  88.49999904632568 Target Test acc :  83.70000123977661\n",
      "Iteration  3 Target Train acc :  87.73999810218811 Target Test acc :  84.71999764442444\n",
      "Iteration  4 Target Train acc :  88.09999823570251 Target Test acc :  84.42000150680542\n",
      "Iteration  5 Target Train acc :  88.5200023651123 Target Test acc :  83.63999724388123\n",
      "Iteration  6 Target Train acc :  88.58000040054321 Target Test acc :  84.8800003528595\n",
      "Iteration  7 Target Train acc :  88.7399971485138 Target Test acc :  83.25999975204468\n",
      "Iteration  8 Target Train acc :  88.81999850273132 Target Test acc :  82.77999758720398\n",
      "Iteration  9 Target Train acc :  88.02000284194946 Target Test acc :  83.57999920845032\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=2\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "accuracy_df = pd.DataFrame()\n",
    "accuracy_df['training data size'] = np.nan\n",
    "accuracy_df['training accuracy'] = np.nan\n",
    "accuracy_df['test accuracy'] = np.nan\n",
    "accuracy_df['error'] = np.nan\n",
    "\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "for j in training_data_size:\n",
    "    print('\\n Training Data Size: ', j, '\\n')\n",
    "    for i in range(10):\n",
    "        target_dataset = data.sample(n = 10000, replace = False)\n",
    "        (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, j, test_ratio, is_synthetic)\n",
    "        target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "        #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "        history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "        score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "        _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        print('Iteration ', i, \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "        accuracy_df = accuracy_df.append({'training data size':j, 'training accuracy' : (train_acc * 100.0), 'test accuracy': (test_acc * 100.0), 'error': ((train_acc * 100.0)-(test_acc * 100.0))}, ignore_index=True)\n",
    "        #print('\\n', 'Model test accuracy:', score[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "089eeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_df =pd.read_csv('data/adult_overfitting_test_trainsize')\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "\n",
    "avg_error_ci95_df = pd.DataFrame()\n",
    "avg_error_ci95_df['training data size'] = np.nan\n",
    "avg_error_ci95_df['average training accuracy'] = np.nan\n",
    "avg_error_ci95_df['average test accuracy'] = np.nan\n",
    "avg_error_ci95_df['average error'] = np.nan\n",
    "avg_error_ci95_df['ci95 low'] = np.nan\n",
    "avg_error_ci95_df['ci95 high'] = np.nan\n",
    "\n",
    "for i in training_data_size:\n",
    "    error = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'error'])\n",
    "    training_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'training accuracy'])\n",
    "    test_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'test accuracy'])\n",
    "    ci95 = st.t.interval(alpha=0.95, df=len(error)-1, loc=np.mean(error), scale=st.sem(error))\n",
    "    row = pd.DataFrame({'training data size': [i], 'average training accuracy': \\\n",
    "            [np.mean(training_accuracy)], 'average test accuracy': [np.mean(test_accuracy)], 'average error': [np.mean(error)],\\\n",
    "                                                  'ci95 low': [ci95[0]], 'ci95 high': [ci95[1]]})\n",
    "    avg_error_ci95_df = pd.concat([avg_error_ci95_df, row], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c3205e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training data size</th>\n",
       "      <th>average training accuracy</th>\n",
       "      <th>average test accuracy</th>\n",
       "      <th>average error</th>\n",
       "      <th>ci95 low</th>\n",
       "      <th>ci95 high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>53.559999</td>\n",
       "      <td>46.440001</td>\n",
       "      <td>32.883379</td>\n",
       "      <td>59.996623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.442000</td>\n",
       "      <td>35.558000</td>\n",
       "      <td>25.182118</td>\n",
       "      <td>45.933883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.211999</td>\n",
       "      <td>30.788001</td>\n",
       "      <td>26.872650</td>\n",
       "      <td>34.703351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>71.778001</td>\n",
       "      <td>28.221999</td>\n",
       "      <td>24.323098</td>\n",
       "      <td>32.120901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70.580000</td>\n",
       "      <td>29.420000</td>\n",
       "      <td>24.609671</td>\n",
       "      <td>34.230330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>74.212000</td>\n",
       "      <td>25.788000</td>\n",
       "      <td>22.316257</td>\n",
       "      <td>29.259742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>75.656001</td>\n",
       "      <td>23.743999</td>\n",
       "      <td>21.182247</td>\n",
       "      <td>26.305751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.800001</td>\n",
       "      <td>78.802000</td>\n",
       "      <td>17.998001</td>\n",
       "      <td>15.158599</td>\n",
       "      <td>20.837403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200.0</td>\n",
       "      <td>96.400000</td>\n",
       "      <td>79.517999</td>\n",
       "      <td>16.882001</td>\n",
       "      <td>14.401084</td>\n",
       "      <td>19.362918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>95.759999</td>\n",
       "      <td>79.634000</td>\n",
       "      <td>16.125999</td>\n",
       "      <td>14.616011</td>\n",
       "      <td>17.635988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>93.340001</td>\n",
       "      <td>81.598000</td>\n",
       "      <td>11.742001</td>\n",
       "      <td>10.323797</td>\n",
       "      <td>13.160204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>90.959999</td>\n",
       "      <td>82.192000</td>\n",
       "      <td>8.767999</td>\n",
       "      <td>7.496738</td>\n",
       "      <td>10.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>88.390000</td>\n",
       "      <td>83.866000</td>\n",
       "      <td>4.524000</td>\n",
       "      <td>3.873596</td>\n",
       "      <td>5.174404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training data size  average training accuracy  average test accuracy  \\\n",
       "0                  2.0                 100.000000              53.559999   \n",
       "1                  5.0                 100.000000              64.442000   \n",
       "2                 10.0                 100.000000              69.211999   \n",
       "3                 15.0                 100.000000              71.778001   \n",
       "4                 20.0                 100.000000              70.580000   \n",
       "5                 25.0                 100.000000              74.212000   \n",
       "6                 50.0                  99.400000              75.656001   \n",
       "7                100.0                  96.800001              78.802000   \n",
       "8                200.0                  96.400000              79.517999   \n",
       "9                500.0                  95.759999              79.634000   \n",
       "10              1000.0                  93.340001              81.598000   \n",
       "11              2000.0                  90.959999              82.192000   \n",
       "12              5000.0                  88.390000              83.866000   \n",
       "\n",
       "    average error   ci95 low  ci95 high  \n",
       "0       46.440001  32.883379  59.996623  \n",
       "1       35.558000  25.182118  45.933883  \n",
       "2       30.788001  26.872650  34.703351  \n",
       "3       28.221999  24.323098  32.120901  \n",
       "4       29.420000  24.609671  34.230330  \n",
       "5       25.788000  22.316257  29.259742  \n",
       "6       23.743999  21.182247  26.305751  \n",
       "7       17.998001  15.158599  20.837403  \n",
       "8       16.882001  14.401084  19.362918  \n",
       "9       16.125999  14.616011  17.635988  \n",
       "10      11.742001  10.323797  13.160204  \n",
       "11       8.767999   7.496738  10.039260  \n",
       "12       4.524000   3.873596   5.174404  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_error_ci95_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------- DNN Experiment --------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36d681ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, train_size, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, train_size, test_ratio, is_synthetic)\n",
    "    target_model,_ = build_dnn(n_class,dim)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdb50f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_adult{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_dnn(n_class,dim)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "017dfcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7000\n",
    "attack_test_size = 5000\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:train_size,:].sample(n = attack_test_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb4559e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  85.62856912612915 Target Test acc :  83.63333344459534\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=6\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e8ebf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  85.61428785324097 Shadow Test acc :  83.86666774749756\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  86.04285717010498 Shadow Test acc :  84.50000286102295\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  84.41428542137146 Shadow Test acc :  83.43333601951599\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  85.10000109672546 Shadow Test acc :  84.46666598320007\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  85.62856912612915 Shadow Test acc :  83.83333086967468\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  84.07142758369446 Shadow Test acc :  82.53333568572998\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  84.84285473823547 Shadow Test acc :  83.26666951179504\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 5ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  83.97142887115479 Shadow Test acc :  81.03333115577698\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 5ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  84.97142791748047 Shadow Test acc :  83.83333086967468\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  84.64285731315613 Shadow Test acc :  82.89999961853027\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  84.98571515083313 Shadow Test acc :  83.83333086967468\n",
      "219/219 [==============================] - 1s 5ms/step\n",
      "94/94 [==============================] - 0s 5ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  85.4285717010498 Shadow Test acc :  84.0333342552185\n",
      "219/219 [==============================] - 1s 6ms/step\n",
      "94/94 [==============================] - 1s 6ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  84.7000002861023 Shadow Test acc :  84.56666469573975\n",
      "219/219 [==============================] - 1s 5ms/step\n",
      "94/94 [==============================] - 1s 6ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  84.41428542137146 Shadow Test acc :  84.10000205039978\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  84.95714068412781 Shadow Test acc :  83.86666774749756\n",
      "219/219 [==============================] - 1s 5ms/step\n",
      "94/94 [==============================] - 0s 5ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  85.35714149475098 Shadow Test acc :  84.7333312034607\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  83.82856845855713 Shadow Test acc :  84.3999981880188\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  84.08571481704712 Shadow Test acc :  81.13333582878113\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  85.69999933242798 Shadow Test acc :  84.86666679382324\n",
      "219/219 [==============================] - 1s 5ms/step\n",
      "94/94 [==============================] - 1s 5ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  84.38571691513062 Shadow Test acc :  84.43333506584167\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 10000\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90290621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "\n",
      " pred (array([[0.994057  , 0.00594292],\n",
      "       [0.08962913, 0.9103709 ],\n",
      "       [0.96087474, 0.03912532],\n",
      "       ...,\n",
      "       [0.86039567, 0.13960423],\n",
      "       [0.9942621 , 0.00573787],\n",
      "       [0.99465257, 0.00534731]], dtype=float32), array([[0.99454147, 0.00545851],\n",
      "       [0.69537467, 0.30462536],\n",
      "       [0.728546  , 0.27145386],\n",
      "       ...,\n",
      "       [0.84629935, 0.15370063],\n",
      "       [0.7286267 , 0.27137324],\n",
      "       [0.97372544, 0.02627459]], dtype=float32))\n",
      "\n",
      " class (array([0, 1, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n",
      "0\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "120/120 [==============================] - 0s 2ms/step\n",
      "1\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "TP: 5000     FP: 4999     FN: 0     TN: 1\n",
      "PPV: 0.5001\n",
      "Advantage: 0.0002\n",
      "Accuracy:  0.5001 Precision:  0.5000500050005\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4bf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
