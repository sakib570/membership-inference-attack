{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f73df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_data = np.load(DATA_PATH+'purchase100.npz')\n",
    "features = pur_data['features']\n",
    "labels = pur_data['labels']\n",
    "data = pd.DataFrame(features[:,:])\n",
    "labels = np.argmax(labels, axis=1)\n",
    "data['600'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64fcd326",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.DataFrame(data.iloc[1:20001,].values)\n",
    "shadow_dataset = pd.DataFrame(data.iloc[15001:50001,].values)\n",
    "attack_test_nonmembers = pd.DataFrame(data.iloc[75001:85001,].values)\n",
    "attack_test_members = pd.DataFrame(data.iloc[5001:15001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"])\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"])\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_28K.csv', na_values=[\"?\"])\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_3K.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1378c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_puchase_data(dataset): \n",
    "    df_tot = dataset\n",
    "    df_tot.dropna(inplace=True)\n",
    "\n",
    "    trainX = df_tot.iloc[:,0:dataset.shape[1]-1]\n",
    "    trainY = df_tot.iloc[:,-1]\n",
    "\n",
    "    dim=trainX.shape[1]\n",
    "\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=100\n",
    "\n",
    "    trainX=np.array(trainX)\n",
    "    trainY=np.array(trainY)\n",
    "    \n",
    "    trainY = to_categorical(trainY)\n",
    "\n",
    "\n",
    "    return trainX, trainY, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio):\n",
    "    x, y, dim = transform_puchase_data(dataset)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:14000,]\n",
    "    testX = x[14000:,]\n",
    "    trainY = y[0:14000,]\n",
    "    testY = y[14000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6975c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_purchase_dnn(n_class,dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    #model.add(Dense(1024), kernel_regularizer=l2(0.001))\n",
    "    #model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio):\n",
    "    x, y, _ = transform_puchase_data(dataset)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_purchase{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_purchase{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_purchase_dnn(n_class,dim)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9025164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "715aa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c3ab0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers):\n",
    "    memberX, memberY, _ = transform_puchase_data(members)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_puchase_data(nonmembers)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "#         over_sampler = SMOTE(k_neighbors=2)\n",
    "#         full_cx_data, full_cy_data = over_sampler.fit_resample(full_cx_data, full_cy_data)\n",
    "#         full_cy_data = to_categorical(full_cy_data)\n",
    "              \n",
    "        \n",
    "#         classifier = define_attack_model(2)\n",
    "#         history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5f3f8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model test accuracy: 0.7296666502952576\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=50\n",
    "act_layer=6\n",
    "n_class = 100\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "(target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio)\n",
    "target_model,_ = build_purchase_dnn(n_class,dim)\n",
    "#get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "95cd4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "\n",
      " pred (array([[2.98413169e-11, 3.17552042e-14, 2.61176128e-12, ...,\n",
      "        1.19767781e-12, 5.54956092e-13, 2.99500080e-05],\n",
      "       [1.54623638e-08, 1.35977216e-10, 1.17508484e-04, ...,\n",
      "        2.67538422e-12, 1.07921831e-12, 8.04744726e-14],\n",
      "       [3.56247523e-14, 2.98693125e-15, 9.08623360e-16, ...,\n",
      "        9.36399985e-11, 9.79389920e-12, 1.40032539e-12],\n",
      "       ...,\n",
      "       [1.11653964e-09, 2.61938756e-14, 1.55246312e-06, ...,\n",
      "        5.48449036e-13, 5.51795378e-16, 1.55160027e-08],\n",
      "       [1.43374635e-11, 4.26041608e-13, 2.16723991e-12, ...,\n",
      "        2.17559894e-11, 4.04710727e-12, 9.94139233e-12],\n",
      "       [8.68660806e-08, 5.35840563e-08, 2.98836268e-03, ...,\n",
      "        6.18522432e-13, 2.02693261e-11, 3.59012441e-14]], dtype=float32), array([[5.25158042e-12, 1.55048997e-06, 3.08961767e-09, ...,\n",
      "        1.01382125e-09, 5.55571700e-10, 6.76230209e-12],\n",
      "       [1.04933728e-10, 6.67927280e-15, 3.17102056e-09, ...,\n",
      "        4.20191659e-11, 5.14797623e-13, 3.64414193e-11],\n",
      "       [6.72846501e-11, 3.14269661e-13, 3.15355720e-14, ...,\n",
      "        1.03362936e-05, 6.08685014e-08, 5.66407232e-09],\n",
      "       ...,\n",
      "       [4.14872636e-10, 9.96349037e-01, 8.60271632e-10, ...,\n",
      "        9.69347824e-10, 2.56667846e-07, 3.72465114e-10],\n",
      "       [1.85061994e-14, 5.94807398e-11, 3.76214427e-15, ...,\n",
      "        1.35404921e-09, 3.13017473e-10, 4.58532387e-12],\n",
      "       [2.78164557e-11, 5.15263906e-15, 1.07264586e-13, ...,\n",
      "        1.45407485e-05, 1.78289516e-09, 3.22603341e-07]], dtype=float32))\n",
      "\n",
      " class (array([59,  4, 73, ..., 17, 39, 16]), array([ 7, 52, 87, ...,  1, 55, 86]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# prepare attack test data\n",
    "\n",
    "members = []\n",
    "nonmembers = []\n",
    "\n",
    "memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers)\n",
    "\n",
    "# member\n",
    "target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "target_model_member_class = np.argmax(memberY, axis=1)\n",
    "target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "#target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "members.append(np.ones(len(target_model_member_pred)))\n",
    "members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "# nonmember\n",
    "target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "#target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "print('\\n pred', full_attack_test_pred_val)\n",
    "print('\\n class', full_attack_test_class_status)\n",
    "print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6ad68c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save attack test dataset to csv\n",
    "df = pd.DataFrame()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,0])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,0])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "len(total)\n",
    "df['prob_class_0'] = total\n",
    "df = df.reset_index()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,1])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,1])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['prob_class 1'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_mem_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_mem_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['mem_status'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_class_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_class_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['class_status'] = total\n",
    "\n",
    "df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv('attack_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f2d70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n",
      "shadow_i_trainX =  7000 shadow_i_trainY =  7000 shadow_i_testX =  3000 shadow_i_testY =  3000\n"
     ]
    }
   ],
   "source": [
    "#prepare shadow dataset\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 10000\n",
    "test_ratio = 0.3\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68d46665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  71.29999995231628\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  74.40000176429749\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  99.97143149375916 Shadow Test acc :  72.2000002861023\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  97.98571467399597 Shadow Test acc :  66.26666784286499\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  73.1333315372467\n",
      "219/219 [==============================] - 1s 5ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  80.45714497566223 Shadow Test acc :  55.50000071525574\n",
      "219/219 [==============================] - 2s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  93.45714449882507 Shadow Test acc :  63.599997758865356\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  98.2714295387268 Shadow Test acc :  67.5000011920929\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  72.73333072662354\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  71.10000252723694\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  71.96666598320007\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  71.33333086967468\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  73.4333336353302\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 1s 6ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  73.60000014305115\n",
      "219/219 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  71.03333473205566\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  72.2000002861023\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  72.06666469573975\n",
      "219/219 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  72.89999723434448\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  99.9571442604065 Shadow Test acc :  71.03333473205566\n",
      "219/219 [==============================] - 1s 4ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  96.81428670883179 Shadow Test acc :  65.06666541099548\n",
      "219/219 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=50\n",
    "act_layer=6\n",
    "n_class = 100\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c0ef94cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>y</th>\n",
       "      <th>membership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.541544e-09</td>\n",
       "      <td>1.174988e-04</td>\n",
       "      <td>4.346246e-08</td>\n",
       "      <td>3.301803e-04</td>\n",
       "      <td>3.626944e-09</td>\n",
       "      <td>2.409745e-07</td>\n",
       "      <td>1.580226e-07</td>\n",
       "      <td>8.283080e-06</td>\n",
       "      <td>2.442902e-06</td>\n",
       "      <td>4.205181e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054758e-09</td>\n",
       "      <td>6.547305e-07</td>\n",
       "      <td>9.407898e-04</td>\n",
       "      <td>9.973258e-01</td>\n",
       "      <td>3.270771e-07</td>\n",
       "      <td>1.051507e-04</td>\n",
       "      <td>1.226892e-05</td>\n",
       "      <td>6.049490e-07</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.547408e-10</td>\n",
       "      <td>4.827722e-10</td>\n",
       "      <td>4.904956e-09</td>\n",
       "      <td>1.147579e-10</td>\n",
       "      <td>8.457438e-12</td>\n",
       "      <td>6.471433e-12</td>\n",
       "      <td>5.096669e-10</td>\n",
       "      <td>1.361659e-10</td>\n",
       "      <td>9.337573e-10</td>\n",
       "      <td>9.030466e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.905618e-08</td>\n",
       "      <td>1.324696e-10</td>\n",
       "      <td>3.149643e-09</td>\n",
       "      <td>8.320056e-10</td>\n",
       "      <td>3.835443e-07</td>\n",
       "      <td>4.170861e-07</td>\n",
       "      <td>1.625577e-05</td>\n",
       "      <td>1.751215e-06</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733920e-09</td>\n",
       "      <td>2.809540e-08</td>\n",
       "      <td>9.842902e-10</td>\n",
       "      <td>7.071368e-11</td>\n",
       "      <td>9.491693e-11</td>\n",
       "      <td>3.591490e-12</td>\n",
       "      <td>1.035509e-09</td>\n",
       "      <td>1.391404e-08</td>\n",
       "      <td>7.793460e-11</td>\n",
       "      <td>6.907168e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955270e-10</td>\n",
       "      <td>6.344954e-10</td>\n",
       "      <td>1.612994e-10</td>\n",
       "      <td>6.682086e-08</td>\n",
       "      <td>1.080540e-10</td>\n",
       "      <td>7.624012e-07</td>\n",
       "      <td>2.918887e-04</td>\n",
       "      <td>2.421112e-11</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.699854e-07</td>\n",
       "      <td>5.283324e-11</td>\n",
       "      <td>1.340632e-07</td>\n",
       "      <td>1.915408e-10</td>\n",
       "      <td>1.822124e-04</td>\n",
       "      <td>6.592505e-12</td>\n",
       "      <td>3.998793e-08</td>\n",
       "      <td>1.597922e-09</td>\n",
       "      <td>1.688016e-09</td>\n",
       "      <td>8.662173e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062382e-11</td>\n",
       "      <td>4.718090e-11</td>\n",
       "      <td>3.240416e-12</td>\n",
       "      <td>2.931615e-10</td>\n",
       "      <td>1.450711e-12</td>\n",
       "      <td>1.605902e-10</td>\n",
       "      <td>3.955463e-12</td>\n",
       "      <td>3.835939e-12</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.272562e-08</td>\n",
       "      <td>1.262606e-12</td>\n",
       "      <td>2.823182e-09</td>\n",
       "      <td>1.278845e-11</td>\n",
       "      <td>7.455685e-11</td>\n",
       "      <td>1.315029e-13</td>\n",
       "      <td>9.146635e-10</td>\n",
       "      <td>3.338455e-15</td>\n",
       "      <td>9.232563e-12</td>\n",
       "      <td>2.473779e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.266597e-08</td>\n",
       "      <td>2.475584e-10</td>\n",
       "      <td>2.046895e-12</td>\n",
       "      <td>5.940438e-15</td>\n",
       "      <td>3.333726e-08</td>\n",
       "      <td>1.257963e-10</td>\n",
       "      <td>1.152253e-11</td>\n",
       "      <td>2.189039e-09</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>4.942136e-08</td>\n",
       "      <td>5.101435e-09</td>\n",
       "      <td>3.858816e-09</td>\n",
       "      <td>9.396201e-11</td>\n",
       "      <td>2.810468e-10</td>\n",
       "      <td>4.035811e-14</td>\n",
       "      <td>1.103672e-08</td>\n",
       "      <td>2.481958e-13</td>\n",
       "      <td>1.289252e-09</td>\n",
       "      <td>1.988193e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.084100e-08</td>\n",
       "      <td>2.099107e-09</td>\n",
       "      <td>4.235858e-09</td>\n",
       "      <td>9.735515e-14</td>\n",
       "      <td>1.215275e-06</td>\n",
       "      <td>6.657518e-11</td>\n",
       "      <td>1.044590e-09</td>\n",
       "      <td>2.800449e-06</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>9.314193e-06</td>\n",
       "      <td>3.875714e-10</td>\n",
       "      <td>1.353274e-06</td>\n",
       "      <td>4.515317e-08</td>\n",
       "      <td>2.462291e-06</td>\n",
       "      <td>4.300380e-10</td>\n",
       "      <td>1.096163e-06</td>\n",
       "      <td>8.803803e-10</td>\n",
       "      <td>2.240690e-07</td>\n",
       "      <td>2.465790e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.656181e-09</td>\n",
       "      <td>2.386638e-10</td>\n",
       "      <td>3.281247e-08</td>\n",
       "      <td>3.871282e-10</td>\n",
       "      <td>3.373403e-08</td>\n",
       "      <td>4.706728e-11</td>\n",
       "      <td>3.933095e-13</td>\n",
       "      <td>5.396639e-06</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1.097093e-08</td>\n",
       "      <td>8.175606e-09</td>\n",
       "      <td>3.953086e-10</td>\n",
       "      <td>1.845675e-09</td>\n",
       "      <td>7.099168e-11</td>\n",
       "      <td>2.389507e-12</td>\n",
       "      <td>1.184922e-08</td>\n",
       "      <td>5.211804e-11</td>\n",
       "      <td>1.348438e-09</td>\n",
       "      <td>7.405021e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.253727e-06</td>\n",
       "      <td>3.544342e-06</td>\n",
       "      <td>6.817405e-07</td>\n",
       "      <td>1.336299e-10</td>\n",
       "      <td>1.131832e-04</td>\n",
       "      <td>2.960044e-08</td>\n",
       "      <td>8.514759e-06</td>\n",
       "      <td>2.727389e-06</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1.457679e-08</td>\n",
       "      <td>3.030750e-07</td>\n",
       "      <td>4.313308e-08</td>\n",
       "      <td>5.811122e-09</td>\n",
       "      <td>1.122036e-10</td>\n",
       "      <td>1.343821e-09</td>\n",
       "      <td>2.893942e-11</td>\n",
       "      <td>1.479642e-09</td>\n",
       "      <td>1.665378e-09</td>\n",
       "      <td>2.320726e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111406e-08</td>\n",
       "      <td>1.396644e-09</td>\n",
       "      <td>7.990046e-08</td>\n",
       "      <td>9.735260e-11</td>\n",
       "      <td>2.420566e-05</td>\n",
       "      <td>1.249579e-10</td>\n",
       "      <td>5.746050e-09</td>\n",
       "      <td>5.447636e-08</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2.470142e-08</td>\n",
       "      <td>1.802479e-08</td>\n",
       "      <td>4.327459e-09</td>\n",
       "      <td>2.503999e-11</td>\n",
       "      <td>1.732434e-09</td>\n",
       "      <td>1.512624e-10</td>\n",
       "      <td>3.091513e-07</td>\n",
       "      <td>5.949206e-09</td>\n",
       "      <td>2.686581e-09</td>\n",
       "      <td>1.637639e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.159518e-10</td>\n",
       "      <td>2.546044e-10</td>\n",
       "      <td>6.429053e-10</td>\n",
       "      <td>1.860053e-09</td>\n",
       "      <td>2.766816e-10</td>\n",
       "      <td>9.450836e-08</td>\n",
       "      <td>1.542193e-04</td>\n",
       "      <td>2.694064e-11</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0             1             2             3             4  \\\n",
       "0       6.541544e-09  1.174988e-04  4.346246e-08  3.301803e-04  3.626944e-09   \n",
       "1       5.547408e-10  4.827722e-10  4.904956e-09  1.147579e-10  8.457438e-12   \n",
       "2       1.733920e-09  2.809540e-08  9.842902e-10  7.071368e-11  9.491693e-11   \n",
       "3       5.699854e-07  5.283324e-11  1.340632e-07  1.915408e-10  1.822124e-04   \n",
       "4       2.272562e-08  1.262606e-12  2.823182e-09  1.278845e-11  7.455685e-11   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "199995  4.942136e-08  5.101435e-09  3.858816e-09  9.396201e-11  2.810468e-10   \n",
       "199996  9.314193e-06  3.875714e-10  1.353274e-06  4.515317e-08  2.462291e-06   \n",
       "199997  1.097093e-08  8.175606e-09  3.953086e-10  1.845675e-09  7.099168e-11   \n",
       "199998  1.457679e-08  3.030750e-07  4.313308e-08  5.811122e-09  1.122036e-10   \n",
       "199999  2.470142e-08  1.802479e-08  4.327459e-09  2.503999e-11  1.732434e-09   \n",
       "\n",
       "                   5             6             7             8             9  \\\n",
       "0       2.409745e-07  1.580226e-07  8.283080e-06  2.442902e-06  4.205181e-08   \n",
       "1       6.471433e-12  5.096669e-10  1.361659e-10  9.337573e-10  9.030466e-08   \n",
       "2       3.591490e-12  1.035509e-09  1.391404e-08  7.793460e-11  6.907168e-10   \n",
       "3       6.592505e-12  3.998793e-08  1.597922e-09  1.688016e-09  8.662173e-10   \n",
       "4       1.315029e-13  9.146635e-10  3.338455e-15  9.232563e-12  2.473779e-08   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "199995  4.035811e-14  1.103672e-08  2.481958e-13  1.289252e-09  1.988193e-07   \n",
       "199996  4.300380e-10  1.096163e-06  8.803803e-10  2.240690e-07  2.465790e-06   \n",
       "199997  2.389507e-12  1.184922e-08  5.211804e-11  1.348438e-09  7.405021e-08   \n",
       "199998  1.343821e-09  2.893942e-11  1.479642e-09  1.665378e-09  2.320726e-04   \n",
       "199999  1.512624e-10  3.091513e-07  5.949206e-09  2.686581e-09  1.637639e-08   \n",
       "\n",
       "        ...            92            93            94            95  \\\n",
       "0       ...  1.054758e-09  6.547305e-07  9.407898e-04  9.973258e-01   \n",
       "1       ...  8.905618e-08  1.324696e-10  3.149643e-09  8.320056e-10   \n",
       "2       ...  1.955270e-10  6.344954e-10  1.612994e-10  6.682086e-08   \n",
       "3       ...  1.062382e-11  4.718090e-11  3.240416e-12  2.931615e-10   \n",
       "4       ...  3.266597e-08  2.475584e-10  2.046895e-12  5.940438e-15   \n",
       "...     ...           ...           ...           ...           ...   \n",
       "199995  ...  8.084100e-08  2.099107e-09  4.235858e-09  9.735515e-14   \n",
       "199996  ...  3.656181e-09  2.386638e-10  3.281247e-08  3.871282e-10   \n",
       "199997  ...  3.253727e-06  3.544342e-06  6.817405e-07  1.336299e-10   \n",
       "199998  ...  1.111406e-08  1.396644e-09  7.990046e-08  9.735260e-11   \n",
       "199999  ...  5.159518e-10  2.546044e-10  6.429053e-10  1.860053e-09   \n",
       "\n",
       "                  96            97            98            99   y  membership  \n",
       "0       3.270771e-07  1.051507e-04  1.226892e-05  6.049490e-07  95           1  \n",
       "1       3.835443e-07  4.170861e-07  1.625577e-05  1.751215e-06  85           1  \n",
       "2       1.080540e-10  7.624012e-07  2.918887e-04  2.421112e-11  60           1  \n",
       "3       1.450711e-12  1.605902e-10  3.955463e-12  3.835939e-12  20           1  \n",
       "4       3.333726e-08  1.257963e-10  1.152253e-11  2.189039e-09  48           1  \n",
       "...              ...           ...           ...           ...  ..         ...  \n",
       "199995  1.215275e-06  6.657518e-11  1.044590e-09  2.800449e-06  48           0  \n",
       "199996  3.373403e-08  4.706728e-11  3.933095e-13  5.396639e-06  14           0  \n",
       "199997  1.131832e-04  2.960044e-08  8.514759e-06  2.727389e-06  79           0  \n",
       "199998  2.420566e-05  1.249579e-10  5.746050e-09  5.447636e-08  43           0  \n",
       "199999  2.766816e-10  9.450836e-08  1.542193e-04  2.694064e-11  62           0  \n",
       "\n",
       "[200000 rows x 102 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_df = prep_attack_data(n_attack_data)\n",
    "attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62d614f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.251580e-12</td>\n",
       "      <td>1.550490e-06</td>\n",
       "      <td>3.089618e-09</td>\n",
       "      <td>2.265308e-08</td>\n",
       "      <td>3.170026e-08</td>\n",
       "      <td>1.031084e-02</td>\n",
       "      <td>4.649702e-10</td>\n",
       "      <td>9.896552e-01</td>\n",
       "      <td>1.313169e-09</td>\n",
       "      <td>4.429032e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004185e-16</td>\n",
       "      <td>3.399599e-12</td>\n",
       "      <td>1.564845e-11</td>\n",
       "      <td>2.459371e-09</td>\n",
       "      <td>1.639833e-06</td>\n",
       "      <td>3.243553e-13</td>\n",
       "      <td>1.013821e-09</td>\n",
       "      <td>5.555717e-10</td>\n",
       "      <td>6.762302e-12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.049337e-10</td>\n",
       "      <td>6.679273e-15</td>\n",
       "      <td>3.171021e-09</td>\n",
       "      <td>6.189256e-14</td>\n",
       "      <td>4.556443e-07</td>\n",
       "      <td>6.804904e-12</td>\n",
       "      <td>3.055240e-09</td>\n",
       "      <td>2.365298e-12</td>\n",
       "      <td>3.223258e-11</td>\n",
       "      <td>5.143663e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>5.241238e-09</td>\n",
       "      <td>4.407018e-10</td>\n",
       "      <td>3.363424e-10</td>\n",
       "      <td>5.079025e-12</td>\n",
       "      <td>7.379908e-12</td>\n",
       "      <td>1.064263e-10</td>\n",
       "      <td>4.201917e-11</td>\n",
       "      <td>5.147976e-13</td>\n",
       "      <td>3.644142e-11</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.728465e-11</td>\n",
       "      <td>3.142697e-13</td>\n",
       "      <td>3.153557e-14</td>\n",
       "      <td>1.791235e-13</td>\n",
       "      <td>1.008317e-12</td>\n",
       "      <td>3.015234e-15</td>\n",
       "      <td>1.291146e-09</td>\n",
       "      <td>3.509069e-13</td>\n",
       "      <td>1.904931e-14</td>\n",
       "      <td>1.118292e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.609530e-09</td>\n",
       "      <td>2.808245e-08</td>\n",
       "      <td>4.857492e-11</td>\n",
       "      <td>2.417192e-14</td>\n",
       "      <td>3.680575e-09</td>\n",
       "      <td>1.260370e-14</td>\n",
       "      <td>1.033629e-05</td>\n",
       "      <td>6.086850e-08</td>\n",
       "      <td>5.664072e-09</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.500934e-09</td>\n",
       "      <td>4.689499e-09</td>\n",
       "      <td>3.941263e-03</td>\n",
       "      <td>6.813244e-09</td>\n",
       "      <td>3.803758e-03</td>\n",
       "      <td>4.176817e-09</td>\n",
       "      <td>7.135264e-04</td>\n",
       "      <td>2.966714e-06</td>\n",
       "      <td>3.088951e-04</td>\n",
       "      <td>1.749461e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370450e-07</td>\n",
       "      <td>6.212899e-12</td>\n",
       "      <td>3.594317e-12</td>\n",
       "      <td>2.134109e-07</td>\n",
       "      <td>4.222499e-07</td>\n",
       "      <td>6.900437e-09</td>\n",
       "      <td>1.821299e-07</td>\n",
       "      <td>7.015982e-06</td>\n",
       "      <td>4.398880e-08</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.112169e-12</td>\n",
       "      <td>1.624837e-17</td>\n",
       "      <td>4.551090e-09</td>\n",
       "      <td>1.882862e-16</td>\n",
       "      <td>1.254222e-13</td>\n",
       "      <td>5.018241e-14</td>\n",
       "      <td>8.860589e-12</td>\n",
       "      <td>8.627319e-15</td>\n",
       "      <td>4.184961e-11</td>\n",
       "      <td>1.877186e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>9.764923e-08</td>\n",
       "      <td>1.521807e-12</td>\n",
       "      <td>4.531417e-17</td>\n",
       "      <td>1.124038e-16</td>\n",
       "      <td>5.622948e-15</td>\n",
       "      <td>3.318514e-13</td>\n",
       "      <td>3.633342e-12</td>\n",
       "      <td>2.549423e-15</td>\n",
       "      <td>3.960865e-12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3.781913e-10</td>\n",
       "      <td>6.541376e-11</td>\n",
       "      <td>5.897551e-10</td>\n",
       "      <td>1.679216e-10</td>\n",
       "      <td>1.178417e-05</td>\n",
       "      <td>1.305457e-09</td>\n",
       "      <td>2.700733e-07</td>\n",
       "      <td>2.045521e-08</td>\n",
       "      <td>2.512732e-10</td>\n",
       "      <td>4.840353e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038200e-10</td>\n",
       "      <td>7.603360e-10</td>\n",
       "      <td>1.126960e-07</td>\n",
       "      <td>1.228799e-08</td>\n",
       "      <td>1.344115e-07</td>\n",
       "      <td>3.768711e-11</td>\n",
       "      <td>1.835935e-06</td>\n",
       "      <td>4.451512e-07</td>\n",
       "      <td>1.260990e-08</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2.853237e-13</td>\n",
       "      <td>1.802704e-11</td>\n",
       "      <td>9.280368e-10</td>\n",
       "      <td>2.182457e-08</td>\n",
       "      <td>8.240011e-12</td>\n",
       "      <td>3.565267e-06</td>\n",
       "      <td>2.769353e-13</td>\n",
       "      <td>7.186834e-08</td>\n",
       "      <td>3.672361e-07</td>\n",
       "      <td>1.271133e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.104006e-13</td>\n",
       "      <td>4.924649e-14</td>\n",
       "      <td>5.201058e-11</td>\n",
       "      <td>8.223761e-08</td>\n",
       "      <td>1.766298e-09</td>\n",
       "      <td>4.974094e-11</td>\n",
       "      <td>1.639730e-09</td>\n",
       "      <td>1.038645e-11</td>\n",
       "      <td>8.270240e-09</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4.148726e-10</td>\n",
       "      <td>9.963490e-01</td>\n",
       "      <td>8.602716e-10</td>\n",
       "      <td>9.938403e-04</td>\n",
       "      <td>1.822380e-09</td>\n",
       "      <td>5.324255e-05</td>\n",
       "      <td>8.899958e-09</td>\n",
       "      <td>2.590750e-03</td>\n",
       "      <td>5.592521e-08</td>\n",
       "      <td>3.592270e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.304211e-13</td>\n",
       "      <td>1.840470e-10</td>\n",
       "      <td>2.606808e-08</td>\n",
       "      <td>1.315705e-06</td>\n",
       "      <td>4.582496e-06</td>\n",
       "      <td>2.061073e-09</td>\n",
       "      <td>9.693478e-10</td>\n",
       "      <td>2.566678e-07</td>\n",
       "      <td>3.724651e-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.850620e-14</td>\n",
       "      <td>5.948074e-11</td>\n",
       "      <td>3.762144e-15</td>\n",
       "      <td>1.400853e-12</td>\n",
       "      <td>3.296175e-10</td>\n",
       "      <td>3.390383e-12</td>\n",
       "      <td>1.583681e-13</td>\n",
       "      <td>5.351064e-11</td>\n",
       "      <td>6.276414e-16</td>\n",
       "      <td>3.422593e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.260824e-15</td>\n",
       "      <td>4.525114e-12</td>\n",
       "      <td>6.602087e-08</td>\n",
       "      <td>9.743842e-12</td>\n",
       "      <td>1.214545e-09</td>\n",
       "      <td>2.332410e-12</td>\n",
       "      <td>1.354049e-09</td>\n",
       "      <td>3.130175e-10</td>\n",
       "      <td>4.585324e-12</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.781646e-11</td>\n",
       "      <td>5.152639e-15</td>\n",
       "      <td>1.072646e-13</td>\n",
       "      <td>6.220304e-13</td>\n",
       "      <td>1.102023e-13</td>\n",
       "      <td>1.930425e-14</td>\n",
       "      <td>7.302888e-11</td>\n",
       "      <td>6.029843e-14</td>\n",
       "      <td>1.303829e-13</td>\n",
       "      <td>6.690381e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259406e-06</td>\n",
       "      <td>2.333076e-06</td>\n",
       "      <td>3.746637e-10</td>\n",
       "      <td>4.681826e-14</td>\n",
       "      <td>2.611602e-09</td>\n",
       "      <td>8.215071e-11</td>\n",
       "      <td>1.454075e-05</td>\n",
       "      <td>1.782895e-09</td>\n",
       "      <td>3.226033e-07</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4  \\\n",
       "0     5.251580e-12  1.550490e-06  3.089618e-09  2.265308e-08  3.170026e-08   \n",
       "1     1.049337e-10  6.679273e-15  3.171021e-09  6.189256e-14  4.556443e-07   \n",
       "2     6.728465e-11  3.142697e-13  3.153557e-14  1.791235e-13  1.008317e-12   \n",
       "3     6.500934e-09  4.689499e-09  3.941263e-03  6.813244e-09  3.803758e-03   \n",
       "4     5.112169e-12  1.624837e-17  4.551090e-09  1.882862e-16  1.254222e-13   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  3.781913e-10  6.541376e-11  5.897551e-10  1.679216e-10  1.178417e-05   \n",
       "9996  2.853237e-13  1.802704e-11  9.280368e-10  2.182457e-08  8.240011e-12   \n",
       "9997  4.148726e-10  9.963490e-01  8.602716e-10  9.938403e-04  1.822380e-09   \n",
       "9998  1.850620e-14  5.948074e-11  3.762144e-15  1.400853e-12  3.296175e-10   \n",
       "9999  2.781646e-11  5.152639e-15  1.072646e-13  6.220304e-13  1.102023e-13   \n",
       "\n",
       "                 5             6             7             8             9  \\\n",
       "0     1.031084e-02  4.649702e-10  9.896552e-01  1.313169e-09  4.429032e-10   \n",
       "1     6.804904e-12  3.055240e-09  2.365298e-12  3.223258e-11  5.143663e-11   \n",
       "2     3.015234e-15  1.291146e-09  3.509069e-13  1.904931e-14  1.118292e-16   \n",
       "3     4.176817e-09  7.135264e-04  2.966714e-06  3.088951e-04  1.749461e-07   \n",
       "4     5.018241e-14  8.860589e-12  8.627319e-15  4.184961e-11  1.877186e-11   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  1.305457e-09  2.700733e-07  2.045521e-08  2.512732e-10  4.840353e-13   \n",
       "9996  3.565267e-06  2.769353e-13  7.186834e-08  3.672361e-07  1.271133e-07   \n",
       "9997  5.324255e-05  8.899958e-09  2.590750e-03  5.592521e-08  3.592270e-08   \n",
       "9998  3.390383e-12  1.583681e-13  5.351064e-11  6.276414e-16  3.422593e-14   \n",
       "9999  1.930425e-14  7.302888e-11  6.029843e-14  1.303829e-13  6.690381e-15   \n",
       "\n",
       "      ...            91            92            93            94  \\\n",
       "0     ...  1.004185e-16  3.399599e-12  1.564845e-11  2.459371e-09   \n",
       "1     ...  5.241238e-09  4.407018e-10  3.363424e-10  5.079025e-12   \n",
       "2     ...  2.609530e-09  2.808245e-08  4.857492e-11  2.417192e-14   \n",
       "3     ...  1.370450e-07  6.212899e-12  3.594317e-12  2.134109e-07   \n",
       "4     ...  9.764923e-08  1.521807e-12  4.531417e-17  1.124038e-16   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "9995  ...  1.038200e-10  7.603360e-10  1.126960e-07  1.228799e-08   \n",
       "9996  ...  5.104006e-13  4.924649e-14  5.201058e-11  8.223761e-08   \n",
       "9997  ...  3.304211e-13  1.840470e-10  2.606808e-08  1.315705e-06   \n",
       "9998  ...  3.260824e-15  4.525114e-12  6.602087e-08  9.743842e-12   \n",
       "9999  ...  4.259406e-06  2.333076e-06  3.746637e-10  4.681826e-14   \n",
       "\n",
       "                95            96            97            98            99   y  \n",
       "0     1.639833e-06  3.243553e-13  1.013821e-09  5.555717e-10  6.762302e-12   7  \n",
       "1     7.379908e-12  1.064263e-10  4.201917e-11  5.147976e-13  3.644142e-11  52  \n",
       "2     3.680575e-09  1.260370e-14  1.033629e-05  6.086850e-08  5.664072e-09  87  \n",
       "3     4.222499e-07  6.900437e-09  1.821299e-07  7.015982e-06  4.398880e-08  24  \n",
       "4     5.622948e-15  3.318514e-13  3.633342e-12  2.549423e-15  3.960865e-12  35  \n",
       "...            ...           ...           ...           ...           ...  ..  \n",
       "9995  1.344115e-07  3.768711e-11  1.835935e-06  4.451512e-07  1.260990e-08  54  \n",
       "9996  1.766298e-09  4.974094e-11  1.639730e-09  1.038645e-11  8.270240e-09  45  \n",
       "9997  4.582496e-06  2.061073e-09  9.693478e-10  2.566678e-07  3.724651e-10   1  \n",
       "9998  1.214545e-09  2.332410e-12  1.354049e-09  3.130175e-10  4.585324e-12  55  \n",
       "9999  2.611602e-09  8.215071e-11  1.454075e-05  1.782895e-09  3.226033e-07  86  \n",
       "\n",
       "[10000 rows x 101 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "nmem_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c177be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "3\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "4\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "6\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "7\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "8\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "9\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "10\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "11\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "12\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "13\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "14\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "15\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "16\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "17\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "18\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "19\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "20\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "21\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "22\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "23\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "24\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "25\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "26\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "27\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "28\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "29\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "30\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "31\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "32\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "33\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "34\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "35\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "36\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "37\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "38\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "39\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "40\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "41\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "42\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "43\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "44\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "45\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "46\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "47\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "48\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "49\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "50\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "51\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "52\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "53\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "54\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "55\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "56\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "57\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "58\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "59\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "60\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "61\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "62\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "63\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "64\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "65\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "66\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "67\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "68\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "69\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "70\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "71\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "72\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "73\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "74\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "75\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "76\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "77\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "79\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "80\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "81\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "82\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "83\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "84\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "85\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "86\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "87\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "88\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "89\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "90\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "91\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "92\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "93\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "94\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "95\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "96\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "97\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "98\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "99\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_df, mem_validation, nmem_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af3617c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 9385     FP: 6653     FN: 615     TN: 3347\n",
      "PPV: 0.5852\n",
      "Advantage: 0.2732\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c5f921fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a9382bc7-fd48-42a6-8436-af2bd2196281/assets\n"
     ]
    }
   ],
   "source": [
    "#save the prepared attack data on disk\n",
    "np.savez(DATA_PATH + 'attack_purchase_data.npz', n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef36e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stored attack model training data \n",
    "data_name = 'attack_adult_data.npz'\n",
    "with np.load(DATA_PATH + data_name, allow_pickle=True) as f:\n",
    "        n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = [f['arr_%d' % i] for i in range(len(f.files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e06462e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  1\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  2\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Class :  3\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  4\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Class :  5\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  6\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  7\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  8\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  9\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  10\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  11\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  12\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  13\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  14\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  15\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Class :  16\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  17\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  18\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Class :  19\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  20\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  21\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  22\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  23\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  24\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  25\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Class :  26\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "Class :  27\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  28\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  29\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Class :  30\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  31\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Class :  32\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  33\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  34\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  35\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  36\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  37\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  38\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  39\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  40\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  41\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  42\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  43\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  44\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Class :  45\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  46\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Class :  47\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  48\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  49\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "Class :  50\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  51\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  52\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  53\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  54\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  55\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  56\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  57\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  58\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  59\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  60\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  61\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  62\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  63\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  64\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  65\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Class :  66\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  67\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  68\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  69\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  70\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  71\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  72\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  73\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  74\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  75\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  76\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  77\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  78\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  79\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  80\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  81\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  82\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  83\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  84\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  85\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  86\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  87\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  88\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  89\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  90\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  91\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  92\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  93\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  94\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  95\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  96\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f970d439dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  97\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f976aafe050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  98\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  99\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "TP: 9244     FP: 6395     FN: 756     TN: 3605\n",
      "PPV: 0.5911\n",
      "Advantage: 0.2849\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tn, precision, advj, acc, recall = train_attack_model(n_attack_data, attack_test_data)\n",
    "#target_membership, predicted_membership = train_attack_model(n_attack_data, attack_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9ad2f872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5193872315473136"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18687f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84deb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab86d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_data = n_attack_data\n",
    "check_membership = attack_test_data\n",
    "n_hidden=50\n",
    "learning_rate=0.01\n",
    "batch_size=200\n",
    "epochs=50\n",
    "model='nn'\n",
    "l2_ratio=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19720640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,  classes = attack_data\n",
    "\n",
    "train_x = x[0]\n",
    "train_y = y[0]\n",
    "test_x = x[1]\n",
    "test_y = y[1]\n",
    "train_classes = classes[0]\n",
    "test_classes = classes[1]\n",
    "\n",
    "#print(tra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e47fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "\n",
    "checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "\n",
    "train_indices = np.arange(len(train_x))\n",
    "test_indices = np.arange(len(test_x))\n",
    "unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "predicted_membership, target_membership = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in unique_classes:\n",
    "    print(\"Class : \", c)\n",
    "    c_train_indices = train_indices[train_classes == c]\n",
    "    c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "    c_test_indices = test_indices[test_classes == c]\n",
    "    c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "    c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "\n",
    "    full_cx_data=(c_train_x,c_test_x)\n",
    "    full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "    full_cy_data=(c_train_y,c_test_y)\n",
    "    full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "    full_cy_data = to_categorical(full_cy_data)\n",
    "\n",
    "    classifier = define_attack_model(2)\n",
    "    history = classifier.fit(full_cx_data, full_cy_data, epochs=200, batch_size=32, verbose=0)\n",
    "    #classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "    #get predictions on real train and test data\n",
    "    c_indices = np.where(checkmem_class_status==c)\n",
    "    predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "    print(predict_y)\n",
    "    c_pred_y = np.argmax(classifier.predict(checkmem_prediction_vals[c_indices]),axis=1)\n",
    "    #c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "    #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "\n",
    "    c_target_y = checkmem_membership_status[c_indices]\n",
    "\n",
    "\n",
    "    target_membership.append(c_target_y)\n",
    "    predicted_membership.append(c_pred_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf72106",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_indices = np.where(checkmem_class_status==c)\n",
    "predict_y = classifier.predict(checkmem_prediction_vals[c_indices], batch_size=32)\n",
    "c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "c_target_y = checkmem_membership_status[c_indices]\n",
    "target_membership.append(c_target_y)\n",
    "predicted_membership.append(c_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee134168",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prety_print_result (target_membership,predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dccc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(predicted_membership).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership.reshape((len(predicted_membership))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafafdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
