{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac6b5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv('data/bangkok', na_values=[\"?\"], header=None)\n",
    "target_dataset = loc_data.sample(n = 1200, replace = False)\n",
    "df_rest = loc_data.loc[~loc_data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 2000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 600, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:840,:].sample(n = 600, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f73df2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_data = np.load(DATA_PATH+'purchase100.npz')\n",
    "features = pur_data['features']\n",
    "labels = pur_data['labels']\n",
    "data = pd.DataFrame(features[:,:])\n",
    "labels = np.argmax(labels, axis=1)\n",
    "data['600'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64fcd326",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.DataFrame(data.iloc[1:20001,].values)\n",
    "shadow_dataset = pd.DataFrame(data.iloc[15001:50001,].values)\n",
    "attack_test_nonmembers = pd.DataFrame(data.iloc[75001:85001,].values)\n",
    "attack_test_members = pd.DataFrame(data.iloc[5001:15001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"])\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"])\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_28K.csv', na_values=[\"?\"])\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_3K.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset):\n",
    "    x = dataset.iloc[:,1:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,0] # label column\n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=30\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1378c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_location_data(dataset): \n",
    "    df_tot = dataset\n",
    "    df_tot.dropna(inplace=True)\n",
    "\n",
    "    trainX = df_tot.iloc[:,1:]\n",
    "    trainY = df_tot.iloc[:,0]\n",
    "    \n",
    "\n",
    "    dim=trainX.shape[1]\n",
    "\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=30\n",
    "\n",
    "    trainX=np.array(trainX)\n",
    "    trainY=np.array(trainY)\n",
    "    \n",
    "    \n",
    "    trainY = to_categorical(trainY)\n",
    "\n",
    "    return trainX, trainY, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio):\n",
    "    x, y, dim = transform_location_data(dataset)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:840,]\n",
    "    testX = x[840:,]\n",
    "    trainY = y[0:840,]\n",
    "    testY = y[840:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6975c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_purchase_dnn(n_class,dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    #model.add(Dense(1024), kernel_regularizer=l2(0.001))\n",
    "    #model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2dcb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_location_dnn(n_class,dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, input_dim=dim, kernel_regularizer=l2(0.0007)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(248, kernel_regularizer=l2(0.0007)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.0007)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64, kernel_regularizer=l2(0.0007)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "       \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio):\n",
    "    x, y, _ = transform_location_data(dataset)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_location{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_location{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_location_dnn(n_class,dim)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9025164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "715aa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3ab0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers):\n",
    "    memberX, memberY, _ = transform_location_data(members)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_location_data(nonmembers)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "#         over_sampler = SMOTE(k_neighbors=2)\n",
    "#         full_cx_data, full_cy_data = over_sampler.fit_resample(full_cx_data, full_cy_data)\n",
    "#         full_cy_data = to_categorical(full_cy_data)\n",
    "              \n",
    "        \n",
    "#         classifier = define_attack_model(2)\n",
    "#         history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f3f8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model test accuracy: 0.5305555462837219\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=40\n",
    "channel=1   \n",
    "EPS=100\n",
    "act_layer=6\n",
    "n_class = 31\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "(target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio)\n",
    "target_model,_ = build_location_dnn(n_class,dim)\n",
    "#get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95cd4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "\n",
      " pred (array([[2.2451704e-05, 2.8579988e-04, 3.1301269e-04, ..., 7.5937379e-08,\n",
      "        5.3171651e-05, 1.3372452e-06],\n",
      "       [9.2460992e-05, 4.7596907e-03, 8.2041064e-05, ..., 4.2755586e-05,\n",
      "        1.2596275e-04, 1.0706383e-05],\n",
      "       [6.7628163e-05, 9.4923557e-04, 9.8687476e-01, ..., 1.6501830e-09,\n",
      "        9.8220815e-05, 5.1238608e-06],\n",
      "       ...,\n",
      "       [1.3854070e-05, 1.7114902e-05, 8.9391642e-06, ..., 7.1200309e-05,\n",
      "        4.5617655e-04, 3.6587691e-04],\n",
      "       [2.7609134e-05, 8.3431747e-04, 1.7158538e-05, ..., 4.8328440e-07,\n",
      "        1.7086437e-04, 2.7603130e-07],\n",
      "       [8.9783662e-06, 3.7671265e-04, 1.0525980e-03, ..., 7.0322119e-07,\n",
      "        4.5053280e-06, 1.4845864e-06]], dtype=float32), array([[3.0896984e-04, 3.0560547e-04, 9.0791506e-01, ..., 1.0290515e-06,\n",
      "        9.4257668e-04, 7.9719713e-03],\n",
      "       [7.3096761e-04, 1.2062288e-05, 1.6828367e-04, ..., 5.4822018e-04,\n",
      "        2.8696761e-01, 9.8327138e-02],\n",
      "       [2.2453058e-04, 6.0438913e-01, 2.9040777e-04, ..., 1.7678567e-04,\n",
      "        1.0034229e-04, 4.1978387e-07],\n",
      "       ...,\n",
      "       [6.9870580e-06, 6.0809281e-04, 2.5902573e-05, ..., 8.6547871e-08,\n",
      "        7.6011129e-06, 2.7532204e-07],\n",
      "       [3.7769321e-04, 9.0352834e-05, 4.1696158e-01, ..., 6.3033687e-05,\n",
      "        5.3240068e-04, 1.5213643e-01],\n",
      "       [5.5021563e-05, 7.3843333e-04, 9.8379123e-01, ..., 4.2971965e-07,\n",
      "        4.7839319e-05, 1.5779329e-05]], dtype=float32))\n",
      "\n",
      " class (array([ 5,  8,  2, 12, 27, 17, 25, 30, 10, 12,  3,  6,  7, 15, 23,  8,  8,\n",
      "        1, 30, 10, 22, 20, 27, 22, 21, 23, 24, 15, 21,  7, 12, 23, 23, 13,\n",
      "       14, 14, 26,  4, 21, 30, 22, 21,  2, 23,  2, 20,  7, 15, 30, 25, 15,\n",
      "       20, 11, 15, 20,  7, 11, 16, 17, 12, 23,  3, 27, 15,  9,  4, 15,  9,\n",
      "       23,  4, 15,  4,  5, 19, 10, 19, 27,  6,  4,  8, 20,  1, 27,  5, 13,\n",
      "       15,  4, 29, 29, 11, 24, 18, 13, 26,  3, 15,  7, 11,  1, 20,  9, 20,\n",
      "       20, 25, 24, 28,  8,  8,  7, 19,  8, 24,  3,  4,  8,  8, 14, 12, 23,\n",
      "        8,  6, 27, 19, 17,  3, 16, 23,  2, 22, 24, 30, 18,  9, 14,  2,  6,\n",
      "        3, 30, 20, 21, 26,  8, 26, 30, 10,  9, 22, 27, 25, 16, 17,  2, 17,\n",
      "       17, 28, 21, 15, 11,  9, 19, 12, 10, 19, 11,  4, 20,  5, 17, 25, 28,\n",
      "        4, 18, 22, 19, 19, 16, 24, 19,  8,  4,  3,  8, 12,  9, 15, 30,  5,\n",
      "        4, 20, 17, 29, 20, 14, 10, 21,  2,  2, 12, 16, 12, 25, 20, 20, 30,\n",
      "       11, 12, 16, 30, 15,  9, 15, 11, 16, 18,  8, 17, 29, 19,  9, 18, 16,\n",
      "        8,  8, 15, 24, 20, 29, 28, 23,  5, 13,  2, 19,  7,  8, 19,  4, 10,\n",
      "       20, 24,  3,  8, 13, 10, 12,  7, 14, 30, 23, 20, 28,  4, 12,  3, 21,\n",
      "       15,  9, 10, 24,  8,  7, 27,  5, 10, 25,  2,  2, 11, 20, 25, 25, 15,\n",
      "       18, 29,  8, 20, 11, 22, 21,  4,  8, 30, 15, 28, 12, 29,  1,  3, 27,\n",
      "       14, 11, 10,  9, 30, 21, 18, 19, 21, 10, 12, 19,  2, 25, 14,  2, 17,\n",
      "       19,  8, 10,  1, 30,  1, 20, 27, 12,  7,  8, 27, 15, 24, 25, 15, 11,\n",
      "       20,  6, 28, 20,  6,  4, 29, 19,  7, 18,  8,  2, 12, 15, 10,  8, 21,\n",
      "       30,  6, 11, 24, 16,  5, 23,  8, 15, 23,  1, 21, 16,  1, 21, 27, 19,\n",
      "        8, 26, 17, 29,  7, 16, 19, 20, 10,  3, 11,  5, 29, 27, 22, 10, 23,\n",
      "       10,  1,  7, 15, 14, 28, 20, 11, 29, 29, 13,  8,  8, 15, 10, 19,  8,\n",
      "       24, 20, 13,  8,  4, 20, 13, 22,  9, 12, 30, 16, 24, 13, 24,  8, 26,\n",
      "       27, 19,  9, 27, 16, 12, 21, 28, 20, 16, 24, 29, 17,  6, 15,  8,  9,\n",
      "        6,  8,  8,  9,  9, 22, 25,  8, 15, 25,  7, 16,  8, 18, 30,  3, 11,\n",
      "       21, 11, 16,  8,  8, 27, 25, 22, 10, 13,  4,  7, 10,  6, 10,  8,  8,\n",
      "       16,  2, 18, 15,  3, 20,  8, 10, 30, 22, 24, 15,  5,  1, 15, 25, 13,\n",
      "        1, 18, 29, 19,  7,  3,  4, 26, 17,  6,  8,  1, 24,  8, 21,  1, 20,\n",
      "       13,  8, 24, 12, 17, 11, 20, 11, 14, 24,  9, 17,  6, 13, 20,  8, 15,\n",
      "       23,  6,  7,  8, 11, 28, 10,  1, 30, 13, 15, 19, 26, 28, 12,  1,  9,\n",
      "       30, 20,  4, 22, 10, 20, 16,  9, 11, 10, 19,  7,  8, 16, 20, 25, 13,\n",
      "       26,  3, 21,  6, 30,  2,  4, 18, 28, 22, 18, 25,  9, 12, 25, 24, 10,\n",
      "       20, 10, 17,  2, 21, 27, 22, 30,  4, 19, 23,  1, 12, 11, 26, 17, 24,\n",
      "       30, 20, 15, 29, 19, 16,  9, 18, 10,  3, 15, 25,  5,  6,  8, 10, 20,\n",
      "       21,  5, 18,  8,  6]), array([ 2, 29,  1, 23,  1, 28, 21,  1, 26,  5, 27, 15, 10,  4,  4,  4, 11,\n",
      "       20, 21, 29, 15, 26, 22,  1, 17, 17, 24, 24, 10, 20, 14,  6, 21, 27,\n",
      "       30,  1,  8,  8, 21, 20, 21,  5,  7, 21, 15, 18, 13, 15, 15, 17,  7,\n",
      "        4, 12, 15,  8,  5, 12,  2, 13, 21, 20,  4,  8, 11,  2,  4,  1, 10,\n",
      "        7, 29, 30, 25, 21, 18, 26, 23, 15, 11, 29,  2, 20, 22, 26,  1, 22,\n",
      "       22, 15, 29, 22, 12, 10, 19, 18, 30,  2, 20, 15, 17,  9, 21, 10, 24,\n",
      "        5, 20,  8, 10, 21,  8, 18,  2, 25, 21,  7, 25, 15, 26, 26, 28,  2,\n",
      "       19,  7, 29,  9,  3, 28, 17, 10, 30, 23,  8,  8, 21, 15,  3, 22,  8,\n",
      "       20, 10, 20,  7, 30, 20,  7,  8, 22,  7,  1,  7, 28, 29, 21, 19, 24,\n",
      "        1, 21, 13, 29, 20, 10, 30, 14, 18, 15, 21,  4,  9,  8, 15, 11, 29,\n",
      "       15,  6, 16, 12,  6,  8, 11, 25, 20, 11, 15, 12, 15,  2,  1, 10, 11,\n",
      "       20, 18,  1, 20,  8, 27, 28, 25, 20, 17, 24, 10, 21, 26,  9, 12, 27,\n",
      "       10,  8, 26, 25,  8, 20, 13, 21, 20, 28, 16, 14, 13, 29,  8, 19, 11,\n",
      "        9,  7, 19, 11, 10, 23, 27,  4, 30,  1, 23, 19, 15,  4, 25, 15, 28,\n",
      "        7,  8,  2,  8, 24, 20,  4, 27, 30,  7, 11,  2,  6, 12,  2,  6, 18,\n",
      "       13, 12, 24,  2,  3, 21, 18,  8, 20, 17, 22, 22,  7,  8,  6, 13,  4,\n",
      "        6,  1, 19, 24,  9, 15,  2, 15, 13,  1, 26, 12, 24,  3, 21,  8, 23,\n",
      "        2, 26, 13,  8,  3,  6,  7,  1,  8, 11, 10,  6, 18,  8, 19,  6, 21,\n",
      "        6,  8, 10, 13, 13, 19,  6, 15, 30, 11,  8, 11, 21, 11, 26, 18, 29,\n",
      "        9, 17,  8, 27, 18,  1,  9, 14, 17,  8, 25, 22, 15,  2, 12, 19, 29,\n",
      "       12, 18,  2,  4,  4, 11, 18, 14, 12,  6, 19,  4, 26, 28, 27, 12,  8,\n",
      "       27, 11,  8,  3, 22,  8, 10,  3, 26, 30,  5, 14, 23,  9, 15, 25, 30,\n",
      "        1,  2, 29, 21,  8, 24, 18, 20, 17, 24,  1, 24,  2,  2, 11,  1, 21,\n",
      "       28, 10, 19,  1, 18, 27, 12,  8, 29, 30, 18,  3,  2, 20, 19, 26, 26,\n",
      "       27, 27,  4,  6, 25,  1, 29, 12, 25, 14,  4, 14,  9, 14, 25,  7,  8,\n",
      "       15,  2,  8, 23, 24, 20,  4, 19,  8, 24,  4,  5, 29, 30,  1, 20,  8,\n",
      "       14, 16,  1,  1, 17, 20, 15,  4,  4, 15, 26,  5, 16, 24,  3,  7, 14,\n",
      "        3, 16, 22, 11, 12, 19, 14,  8,  5, 22, 10, 11,  9, 21, 15, 24, 22,\n",
      "       12, 12,  5,  9,  7, 21, 21, 13, 20, 15, 10, 25,  9, 25, 11,  4, 29,\n",
      "       17, 15,  2, 23,  5, 21, 23, 14, 10,  6,  3, 19, 21, 23,  8, 27,  6,\n",
      "        9, 10, 17,  2, 12,  8, 26, 29,  6,  8,  3, 14, 17, 28, 30, 28, 16,\n",
      "       10, 10,  5,  1, 11, 13, 15,  6, 15, 29,  5, 14,  5, 21,  9,  9,  3,\n",
      "       13, 21, 21, 22, 22,  1,  3, 12, 21, 30, 21,  9, 21,  8, 21,  3,  2,\n",
      "       30, 20,  9,  3, 16,  4, 24, 17,  9, 19, 25, 10,  4, 27, 13, 29, 12,\n",
      "       18, 28,  5,  7,  3, 23,  5, 21, 25, 11,  2, 15, 27,  6,  5, 29, 19,\n",
      "       21, 23,  8,  2,  2]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# prepare attack test data\n",
    "\n",
    "members = []\n",
    "nonmembers = []\n",
    "\n",
    "memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers)\n",
    "\n",
    "# member\n",
    "target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "target_model_member_class = np.argmax(memberY, axis=1)\n",
    "target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "#target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "members.append(np.ones(len(target_model_member_pred)))\n",
    "members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "# nonmember\n",
    "target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "#target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "print('\\n pred', full_attack_test_pred_val)\n",
    "print('\\n class', full_attack_test_class_status)\n",
    "print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6ad68c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save attack test dataset to csv\n",
    "df = pd.DataFrame()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,0])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,0])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "len(total)\n",
    "df['prob_class_0'] = total\n",
    "df = df.reset_index()\n",
    "mem = pd.Series(full_attack_test_pred_val[0][:,1])\n",
    "nonmem = pd.Series(full_attack_test_pred_val[1][:,1])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['prob_class 1'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_mem_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_mem_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['mem_status'] = total\n",
    "\n",
    "mem = pd.Series(full_attack_test_class_status[0][:])\n",
    "nonmem = pd.Series(full_attack_test_class_status[1][:])\n",
    "total = pd.concat([mem, nonmem],axis=0, ignore_index=True)\n",
    "df['class_status'] = total\n",
    "\n",
    "df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv('attack_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f2d70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n",
      "shadow_i_trainX =  840 shadow_i_trainY =  840 shadow_i_testX =  360 shadow_i_testY =  360\n"
     ]
    }
   ],
   "source": [
    "#prepare shadow dataset\n",
    "n_shadow_models = 60\n",
    "shadow_data_size = 1200\n",
    "test_ratio = 0.3\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68d46665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  99.88095164299011 Shadow Test acc :  42.222222685813904\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.22222089767456\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.055556416511536\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.22222089767456\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  79.16666865348816 Shadow Test acc :  34.44444537162781\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  53.05555462837219\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  44.16666626930237\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.94444537162781\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  51.66666507720947\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  89.04761672019958 Shadow Test acc :  42.77777671813965\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.49999940395355\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  50.833332538604736\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.49999940395355\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  50.27777552604675\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  43.61111223697662\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  98.57142567634583 Shadow Test acc :  41.94444417953491\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  50.55555701255798\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  43.33333373069763\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  20\n",
      "Training shadow model 20\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  45.277777314186096\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  21\n",
      "Training shadow model 21\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.22222089767456\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  22\n",
      "Training shadow model 22\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  45.55555582046509\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  23\n",
      "Training shadow model 23\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  50.55555701255798\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  24\n",
      "Training shadow model 24\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  49.44444298744202\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  25\n",
      "Training shadow model 25\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  51.11111402511597\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  26\n",
      "Training shadow model 26\n",
      "Shadow Train acc :  76.1904776096344 Shadow Test acc :  32.499998807907104\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  27\n",
      "Training shadow model 27\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  43.33333373069763\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  28\n",
      "Training shadow model 28\n",
      "Shadow Train acc :  78.09523940086365 Shadow Test acc :  39.722222089767456\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  29\n",
      "Training shadow model 29\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  42.77777671813965\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  30\n",
      "Training shadow model 30\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.33333194255829\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  31\n",
      "Training shadow model 31\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.94444537162781\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  32\n",
      "Training shadow model 32\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  33\n",
      "Training shadow model 33\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.88888895511627\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  34\n",
      "Training shadow model 34\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  44.999998807907104\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  35\n",
      "Training shadow model 35\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.777777910232544\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  36\n",
      "Training shadow model 36\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.88888895511627\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  37\n",
      "Training shadow model 37\n",
      "Shadow Train acc :  95.47619223594666 Shadow Test acc :  43.61111223697662\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  38\n",
      "Training shadow model 38\n",
      "Shadow Train acc :  99.04761910438538 Shadow Test acc :  46.11110985279083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "Shadow Model  39\n",
      "Training shadow model 39\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  51.11111402511597\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  40\n",
      "Training shadow model 40\n",
      "Shadow Train acc :  99.52380657196045 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  41\n",
      "Training shadow model 41\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  51.38888955116272\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  42\n",
      "Training shadow model 42\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.88888895511627\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  43\n",
      "Training shadow model 43\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.49999940395355\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  44\n",
      "Training shadow model 44\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  48.61111044883728\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  45\n",
      "Training shadow model 45\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  46\n",
      "Training shadow model 46\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  47\n",
      "Training shadow model 47\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  48\n",
      "Training shadow model 48\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  51.9444465637207\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  49\n",
      "Training shadow model 49\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  44.16666626930237\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  50\n",
      "Training shadow model 50\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  50.0\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  51\n",
      "Training shadow model 51\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  52\n",
      "Training shadow model 52\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  53\n",
      "Training shadow model 53\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  49.44444298744202\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  54\n",
      "Training shadow model 54\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  47.777777910232544\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  55\n",
      "Training shadow model 55\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  44.999998807907104\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  56\n",
      "Training shadow model 56\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  57\n",
      "Training shadow model 57\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.388888359069824\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Shadow Model  58\n",
      "Training shadow model 58\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  46.11110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "Shadow Model  59\n",
      "Training shadow model 59\n",
      "Shadow Train acc :  78.8095235824585 Shadow Test acc :  33.61110985279083\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "per_class_sample=40\n",
    "channel=1\n",
    "EPS=100\n",
    "act_layer=6\n",
    "n_class = 31\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0ef94cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_df = prep_attack_data(n_attack_data)\n",
    "attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62d614f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.907915</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>1.307487e-06</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>2.756053e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.222034e-03</td>\n",
       "      <td>3.473059e-04</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.056595e-02</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>1.029052e-06</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>7.971971e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.073690e-05</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>2.763821e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.686335e-01</td>\n",
       "      <td>1.639225e-02</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>5.966214e-02</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>5.482202e-04</td>\n",
       "      <td>0.286968</td>\n",
       "      <td>9.832714e-02</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.604389</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>1.814771e-01</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>9.508774e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.024930e-06</td>\n",
       "      <td>1.654286e-04</td>\n",
       "      <td>0.015224</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>5.620118e-06</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>1.767857e-04</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.197839e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.199356e-04</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>6.803751e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.868211e-02</td>\n",
       "      <td>3.358580e-01</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.919092e-04</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1.359883e-01</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>1.293991e-03</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>1.291345e-04</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>3.152572e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.577279e-04</td>\n",
       "      <td>6.375201e-05</td>\n",
       "      <td>0.820674</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>9.395346e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.940748e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.446454e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>3.661131e-03</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>7.559169e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.011770e-03</td>\n",
       "      <td>4.047854e-04</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.072970</td>\n",
       "      <td>6.815073e-03</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>5.415375e-04</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>5.823603e-04</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>3.596262e-03</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>2.172195e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.109001e-03</td>\n",
       "      <td>2.503201e-01</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.208794e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.958360e-01</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>4.241396e-03</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>5.465820e-06</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>4.959995e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.802638e-07</td>\n",
       "      <td>7.759500e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.423435e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>8.654787e-08</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.753220e-07</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.416962</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>6.978997e-07</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>9.965130e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.928544e-03</td>\n",
       "      <td>7.730046e-04</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>1.955544e-04</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>6.303369e-05</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>1.521364e-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.983791</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>4.485458e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.331048e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.485214e-07</td>\n",
       "      <td>2.808699e-07</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.086850e-05</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>4.297196e-07</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1.577933e-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.000309  0.000306  0.907915  0.001118  0.000593  0.014152  0.002854   \n",
       "1    0.000731  0.000012  0.000168  0.001460  0.032700  0.001204  0.000010   \n",
       "2    0.000225  0.604389  0.000290  0.000320  0.000134  0.009279  0.046155   \n",
       "3    0.000340  0.003887  0.000002  0.000014  0.000038  0.000010  0.000049   \n",
       "4    0.000133  0.122700  0.000234  0.000115  0.000145  0.005945  0.005737   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595  0.001992  0.000828  0.006391  0.005343  0.001124  0.004704  0.003768   \n",
       "596  0.000354  0.000607  0.000029  0.000133  0.000117  0.000005  0.000374   \n",
       "597  0.000007  0.000608  0.000026  0.000021  0.000018  0.000629  0.000696   \n",
       "598  0.000378  0.000090  0.416962  0.000428  0.002955  0.064196  0.008082   \n",
       "599  0.000055  0.000738  0.983791  0.004459  0.000030  0.002301  0.002622   \n",
       "\n",
       "                7         8             9  ...            22            23  \\\n",
       "0    1.307487e-06  0.000084  2.756053e-04  ...  4.222034e-03  3.473059e-04   \n",
       "1    6.073690e-05  0.000673  2.763821e-04  ...  4.686335e-01  1.639225e-02   \n",
       "2    1.814771e-01  0.120881  9.508774e-05  ...  3.024930e-06  1.654286e-04   \n",
       "3    3.199356e-04  0.000245  6.803751e-03  ...  3.868211e-02  3.358580e-01   \n",
       "4    1.291345e-04  0.002174  3.152572e-05  ...  7.577279e-04  6.375201e-05   \n",
       "..            ...       ...           ...  ...           ...           ...   \n",
       "595  3.661131e-03  0.028536  7.559169e-02  ...  2.011770e-03  4.047854e-04   \n",
       "596  3.596262e-03  0.000128  2.172195e-02  ...  4.109001e-03  2.503201e-01   \n",
       "597  5.465820e-06  0.997620  4.959995e-07  ...  2.802638e-07  7.759500e-06   \n",
       "598  6.978997e-07  0.000415  9.965130e-05  ...  6.928544e-03  7.730046e-04   \n",
       "599  4.485458e-06  0.000006  1.331048e-07  ...  6.485214e-07  2.808699e-07   \n",
       "\n",
       "           24        25            26        27            28        29  \\\n",
       "0    0.000090  0.000016  1.056595e-02  0.000462  1.029052e-06  0.000943   \n",
       "1    0.004764  0.002624  5.966214e-02  0.016756  5.482202e-04  0.286968   \n",
       "2    0.015224  0.003167  5.620118e-06  0.000180  1.767857e-04  0.000100   \n",
       "3    0.002763  0.000012  4.919092e-04  0.000102  1.359883e-01  0.000312   \n",
       "4    0.820674  0.000081  9.395346e-06  0.000006  4.940748e-05  0.000006   \n",
       "..        ...       ...           ...       ...           ...       ...   \n",
       "595  0.000545  0.072970  6.815073e-03  0.000046  5.415375e-04  0.000228   \n",
       "596  0.000102  0.000307  1.208794e-04  0.000004  5.958360e-01  0.000256   \n",
       "597  0.000032  0.000001  2.423435e-07  0.000012  8.654787e-08  0.000008   \n",
       "598  0.002578  0.000901  1.955544e-04  0.000123  6.303369e-05  0.000532   \n",
       "599  0.000022  0.000023  1.086850e-05  0.001053  4.297196e-07  0.000048   \n",
       "\n",
       "               30   y  \n",
       "0    7.971971e-03   2  \n",
       "1    9.832714e-02  29  \n",
       "2    4.197839e-07   1  \n",
       "3    1.293991e-03  23  \n",
       "4    2.446454e-05   1  \n",
       "..            ...  ..  \n",
       "595  5.823603e-04  21  \n",
       "596  4.241396e-03  23  \n",
       "597  2.753220e-07   8  \n",
       "598  1.521364e-01   2  \n",
       "599  1.577933e-05   2  \n",
       "\n",
       "[600 rows x 32 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "nmem_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c177be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "4\n",
      "WARNING:tensorflow:5 out of the last 46 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fded17ee200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "5\n",
      "WARNING:tensorflow:6 out of the last 48 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdecc9bad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "8\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "10\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "11\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "13\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "14\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "15\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "16\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "17\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "18\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "20\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "21\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "22\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "23\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "24\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "25\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "27\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "28\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "29\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "30\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_df, mem_validation, nmem_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af3617c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 600     FP: 148     FN: 0     TN: 452\n",
      "PPV: 0.8021\n",
      "Advantage: 0.7533\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67ae5aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021390374331551"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c5f921fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msnkhan/anaconda3/envs/r4-base/lib/python3.7/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a9382bc7-fd48-42a6-8436-af2bd2196281/assets\n"
     ]
    }
   ],
   "source": [
    "#save the prepared attack data on disk\n",
    "np.savez(DATA_PATH + 'attack_purchase_data.npz', n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef36e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stored attack model training data \n",
    "data_name = 'attack_adult_data.npz'\n",
    "with np.load(DATA_PATH + data_name, allow_pickle=True) as f:\n",
    "        n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init = [f['arr_%d' % i] for i in range(len(f.files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e06462e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :  0\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  1\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  2\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Class :  3\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  4\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Class :  5\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  6\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  7\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  8\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  9\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  10\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  11\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  12\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  13\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  14\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  15\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Class :  16\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  17\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  18\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Class :  19\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  20\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  21\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  22\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  23\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  24\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  25\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Class :  26\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "Class :  27\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  28\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  29\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Class :  30\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Class :  31\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Class :  32\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  33\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  34\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  35\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  36\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  37\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  38\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  39\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Class :  40\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  41\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  42\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  43\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  44\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Class :  45\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  46\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Class :  47\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  48\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  49\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "Class :  50\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  51\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  52\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  53\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  54\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  55\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  56\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  57\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Class :  58\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  59\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  60\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  61\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  62\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  63\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  64\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  65\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Class :  66\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Class :  67\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  68\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  69\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Class :  70\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  71\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  72\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  73\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  74\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  75\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  76\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  77\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  78\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  79\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  80\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  81\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  82\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  83\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  84\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  85\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  86\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  87\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  88\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  89\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  90\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Class :  91\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Class :  92\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Class :  93\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  94\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  95\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  96\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f970d439dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Class :  97\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f976aafe050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Class :  98\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Class :  99\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "TP: 9244     FP: 6395     FN: 756     TN: 3605\n",
      "PPV: 0.5911\n",
      "Advantage: 0.2849\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tn, precision, advj, acc, recall = train_attack_model(n_attack_data, attack_test_data)\n",
    "#target_membership, predicted_membership = train_attack_model(n_attack_data, attack_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9ad2f872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5193872315473136"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18687f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84deb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab86d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_data = n_attack_data\n",
    "check_membership = attack_test_data\n",
    "n_hidden=50\n",
    "learning_rate=0.01\n",
    "batch_size=200\n",
    "epochs=50\n",
    "model='nn'\n",
    "l2_ratio=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19720640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,  classes = attack_data\n",
    "\n",
    "train_x = x[0]\n",
    "train_y = y[0]\n",
    "test_x = x[1]\n",
    "test_y = y[1]\n",
    "train_classes = classes[0]\n",
    "test_classes = classes[1]\n",
    "\n",
    "#print(tra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e47fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "\n",
    "checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "\n",
    "train_indices = np.arange(len(train_x))\n",
    "test_indices = np.arange(len(test_x))\n",
    "unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "predicted_membership, target_membership = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in unique_classes:\n",
    "    print(\"Class : \", c)\n",
    "    c_train_indices = train_indices[train_classes == c]\n",
    "    c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "    c_test_indices = test_indices[test_classes == c]\n",
    "    c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "    c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)  \n",
    "\n",
    "    full_cx_data=(c_train_x,c_test_x)\n",
    "    full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "    full_cy_data=(c_train_y,c_test_y)\n",
    "    full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "    full_cy_data = to_categorical(full_cy_data)\n",
    "\n",
    "    classifier = define_attack_model(2)\n",
    "    history = classifier.fit(full_cx_data, full_cy_data, epochs=200, batch_size=32, verbose=0)\n",
    "    #classifier.save('model/attack_model_class{}'.format(c))\n",
    "\n",
    "    #get predictions on real train and test data\n",
    "    c_indices = np.where(checkmem_class_status==c)\n",
    "    predict_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "    print(predict_y)\n",
    "    c_pred_y = np.argmax(classifier.predict(checkmem_prediction_vals[c_indices]),axis=1)\n",
    "    #c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "    #c_pred_y = classifier.predict_classes(checkmem_prediction_vals[c_indices])\n",
    "\n",
    "    c_target_y = checkmem_membership_status[c_indices]\n",
    "\n",
    "\n",
    "    target_membership.append(c_target_y)\n",
    "    predicted_membership.append(c_pred_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf72106",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_indices = np.where(checkmem_class_status==c)\n",
    "predict_y = classifier.predict(checkmem_prediction_vals[c_indices], batch_size=32)\n",
    "c_pred_y = np.where(predict_y > 0.5, 1,0)\n",
    "c_target_y = checkmem_membership_status[c_indices]\n",
    "target_membership.append(c_target_y)\n",
    "predicted_membership.append(c_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee134168",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prety_print_result (target_membership,predicted_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dccc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(predicted_membership).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['target'] = pd.Series(target_membership)\n",
    "df['predicted'] = pd.Series(predicted_membership.reshape((len(predicted_membership))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafafdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
