{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with specific index\n",
    "# data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "# target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "# shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "    \n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "            print(x.iloc[:,j])\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "630d4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, is_synthetic):\n",
    "    \n",
    "\n",
    "    le = LabelEncoder()\n",
    "    dataset[10] = le.fit_transform(dataset[10].astype('str'))\n",
    "\n",
    "    # normalize the values\n",
    "    x_range = [i for i in range(10)]\n",
    "    #dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "\n",
    "    x = dataset[x_range].values\n",
    "    y = dataset[10].values\n",
    "        \n",
    "    \n",
    "    dim = x.shape[1]\n",
    "    \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:7000,]\n",
    "    testX = x[7000:,]\n",
    "    trainY = y[0:7000,]\n",
    "    testY = y[7000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba094f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_dnn(n_class,dim, channel=0):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio, is_synthetic):\n",
    "    x, y, _ = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_avila{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_avila{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_simple_mlp(n_class,dim, channel)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7909a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b5974c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_train_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f855c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers, is_synthetic):\n",
    "    memberX, memberY, _ = transform_data(members, is_synthetic)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers, is_synthetic)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(pred_y)\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01432ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a933f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio, is_synthetic)\n",
    "    target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ef35632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic):\n",
    "    members = []\n",
    "    nonmembers = []\n",
    "\n",
    "    memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers, is_synthetic)\n",
    "\n",
    "    # member\n",
    "    target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "    target_model_member_class = np.argmax(memberY, axis=1)\n",
    "    target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "    #target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "    members.append(np.ones(len(target_model_member_pred)))\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "    # nonmember\n",
    "    target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "    target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "    target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "    #target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "    nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "    full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "    full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "    print('\\n pred', full_attack_test_pred_val)\n",
    "    print('\\n class', full_attack_test_class_status)\n",
    "    print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "    attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)\n",
    "    \n",
    "    return attack_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f13a0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "82e68463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/avila-tr.txt', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = pd.read_csv('data/avila-ts.txt', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = df_rest.sample(n = 7000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 3000, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:7000,:].sample(n = 3000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  96.12857103347778 Target Test acc :  90.73333144187927\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 12\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a961b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  95.88571190834045 Shadow Test acc :  84.3999981880188\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 3ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  97.68571257591248 Shadow Test acc :  86.59999966621399\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  94.08571720123291 Shadow Test acc :  84.53333377838135\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  96.74285650253296 Shadow Test acc :  85.33333539962769\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  94.68571543693542 Shadow Test acc :  83.66666436195374\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  94.71428394317627 Shadow Test acc :  84.6666693687439\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  95.22857069969177 Shadow Test acc :  83.39999914169312\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  94.8285698890686 Shadow Test acc :  84.86666679382324\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  97.5428581237793 Shadow Test acc :  85.66666841506958\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  96.62857055664062 Shadow Test acc :  83.53333473205566\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  94.88571286201477 Shadow Test acc :  85.13333201408386\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 6ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  97.22856879234314 Shadow Test acc :  86.73333525657654\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  97.2000002861023 Shadow Test acc :  85.79999804496765\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  84.13333296775818\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  96.31428718566895 Shadow Test acc :  85.66666841506958\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  95.91428637504578 Shadow Test acc :  85.06666421890259\n",
      "110/110 [==============================] - 1s 4ms/step\n",
      "47/47 [==============================] - 0s 3ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  96.8571424484253 Shadow Test acc :  84.60000157356262\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  94.4857120513916 Shadow Test acc :  83.46666693687439\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  94.85714435577393 Shadow Test acc :  82.13333487510681\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  95.68571448326111 Shadow Test acc :  83.79999995231628\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 5000\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9074b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "\n",
      " pred (array([[9.7050071e-01, 2.3709588e-16, 5.3663268e-15, ..., 6.3308222e-16,\n",
      "        2.0681337e-06, 1.8180718e-06],\n",
      "       [8.8731172e-03, 3.8849543e-19, 9.2158836e-15, ..., 7.6288776e-15,\n",
      "        1.0891775e-02, 4.2772226e-09],\n",
      "       [6.6687059e-01, 2.3195396e-07, 2.8747135e-07, ..., 1.9356172e-07,\n",
      "        2.9454189e-12, 4.5688250e-08],\n",
      "       ...,\n",
      "       [9.9968970e-01, 1.1148814e-15, 5.0343784e-05, ..., 2.1332906e-16,\n",
      "        9.8672871e-08, 1.8458871e-14],\n",
      "       [3.1852403e-01, 1.1128450e-11, 5.6032317e-09, ..., 1.0047440e-09,\n",
      "        1.8475058e-06, 1.1344299e-06],\n",
      "       [9.9997610e-01, 1.4525879e-16, 6.8545106e-22, ..., 5.8788912e-09,\n",
      "        2.2700308e-06, 1.6626132e-09]], dtype=float32), array([[8.83870944e-02, 8.96694171e-16, 2.81694416e-12, ...,\n",
      "        4.19103200e-17, 3.17756954e-09, 6.53733014e-06],\n",
      "       [1.88080855e-02, 8.21492009e-18, 1.80693706e-15, ...,\n",
      "        5.31825749e-17, 1.59894609e-09, 1.36780045e-08],\n",
      "       [1.37939742e-06, 1.85555727e-19, 9.21852201e-22, ...,\n",
      "        6.33557537e-14, 3.87311995e-01, 6.12681568e-01],\n",
      "       ...,\n",
      "       [9.12852027e-03, 1.62149617e-11, 3.17298383e-16, ...,\n",
      "        8.44497944e-11, 2.12218012e-07, 2.02936872e-06],\n",
      "       [9.99340594e-01, 4.20923676e-18, 2.39295064e-25, ...,\n",
      "        1.31163794e-19, 7.55836227e-10, 3.97221492e-12],\n",
      "       [9.99765396e-01, 5.50314297e-13, 6.17705594e-13, ...,\n",
      "        7.17527166e-14, 1.51959356e-09, 8.31058475e-13]], dtype=float32))\n",
      "\n",
      " class (array([5, 3, 0, ..., 0, 4, 0]), array([ 0,  5, 10, ...,  6,  0,  0]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n",
      "0\n",
      "39/39 [==============================] - 0s 924us/step\n",
      "39/39 [==============================] - 0s 895us/step\n",
      "1\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "3\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "5\n",
      "18/18 [==============================] - 0s 974us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "6\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "7\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "8\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "10\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "11\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "TP: 2946     FP: 2842     FN: 54     TN: 158\n",
      "PPV: 0.5090\n",
      "Advantage: 0.0347\n",
      "Accuracy:  0.5173333333333333 Precision:  0.5089841050449205\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ae477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3d6ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset\n",
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_30K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_5K.csv', na_values=[\"?\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e8d406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  85.14285683631897 Target Test acc :  82.73333311080933\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "is_synthetic = True\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c83ba152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  89.28571343421936 Shadow Test acc :  80.53333163261414\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  84.85714197158813 Shadow Test acc :  80.80000281333923\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  86.77142858505249 Shadow Test acc :  83.66666436195374\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  88.02857398986816 Shadow Test acc :  81.5999984741211\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  86.45714521408081 Shadow Test acc :  82.33333230018616\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  86.8571400642395 Shadow Test acc :  82.40000009536743\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  87.74285912513733 Shadow Test acc :  79.93333339691162\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  85.88571548461914 Shadow Test acc :  79.13333177566528\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  87.22857236862183 Shadow Test acc :  81.5999984741211\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  86.48571372032166 Shadow Test acc :  83.39999914169312\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  87.51428723335266 Shadow Test acc :  80.46666383743286\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  87.4571442604065 Shadow Test acc :  83.26666951179504\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  86.57143115997314 Shadow Test acc :  80.40000200271606\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  87.628573179245 Shadow Test acc :  81.33333325386047\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  86.88571453094482 Shadow Test acc :  82.33333230018616\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  86.51428818702698 Shadow Test acc :  80.13333082199097\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  86.59999966621399 Shadow Test acc :  82.06666707992554\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  87.82857060432434 Shadow Test acc :  83.66666436195374\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  84.77143049240112 Shadow Test acc :  77.26666927337646\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  86.54285669326782 Shadow Test acc :  82.20000267028809\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 5000\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef67324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "\n",
      " pred (array([[9.9985862e-01, 1.4152995e-04],\n",
      "       [9.8442662e-01, 1.5573268e-02],\n",
      "       [9.4646138e-01, 5.3538572e-02],\n",
      "       ...,\n",
      "       [9.9994189e-01, 5.8105015e-05],\n",
      "       [9.8555994e-01, 1.4439992e-02],\n",
      "       [9.9721175e-01, 2.7883006e-03]], dtype=float32), array([[9.9999624e-01, 3.7535829e-06],\n",
      "       [2.1646561e-02, 9.7835344e-01],\n",
      "       [5.6454796e-01, 4.3545207e-01],\n",
      "       ...,\n",
      "       [8.2621348e-01, 1.7378657e-01],\n",
      "       [9.9999923e-01, 7.5641776e-07],\n",
      "       [9.9825138e-01, 1.7485529e-03]], dtype=float32))\n",
      "\n",
      " class (array([0, 0, 0, ..., 0, 0, 0]), array([0, 1, 1, ..., 0, 0, 0]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n",
      "0\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "117/117 [==============================] - 0s 1ms/step\n",
      "1\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "TP: 4811     FP: 4805     FN: 189     TN: 195\n",
      "PPV: 0.5003\n",
      "Advantage: 0.0012\n",
      "Accuracy:  0.5006 Precision:  0.5003119800332779\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "fbe1dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 5000, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:7000,:].sample(n = 5000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9b6a811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:10,]\n",
    "    testX = x[5000:,]\n",
    "    trainY = y[0:10,]\n",
    "    testY = y[5000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "02c4e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_614 (Dense)           (None, 1024)              15360     \n",
      "                                                                 \n",
      " activation_456 (Activation)  (None, 1024)             0         \n",
      "                                                                 \n",
      " dense_615 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_457 (Activation)  (None, 512)              0         \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 541,186\n",
      "Trainable params: 541,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " Target Train acc :  100.0 Target Test acc :  76.39999985694885\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=2\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ad759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
