{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with specific index\n",
    "# data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "# target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "# shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "    \n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "            print(x.iloc[:,j])\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "630d4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, is_synthetic):\n",
    "    \n",
    "\n",
    "    le = LabelEncoder()\n",
    "    dataset[10] = le.fit_transform(dataset[10].astype('str'))\n",
    "\n",
    "    # normalize the values\n",
    "    x_range = [i for i in range(10)]\n",
    "    #dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "\n",
    "    x = dataset[x_range].values\n",
    "    y = dataset[10].values\n",
    "        \n",
    "    \n",
    "    dim = x.shape[1]\n",
    "    \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, train_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:train_size,]\n",
    "    testX = x[7000:,]\n",
    "    trainY = y[0:train_size,]\n",
    "    testY = y[7000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83e6ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_dnn(n_class,dim, channel=0):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(600, input_dim=dim))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    #model.add(Dense(1024, kernel_regularizer=l2(0.00003)))\n",
    "    #model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(128, kernel_regularizer=l2(0.00003)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    #model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=6\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio, is_synthetic):\n",
    "    x, y, _ = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_avila{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_avila{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_simple_mlp(n_class,dim, channel)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7909a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b5974c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_train_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f855c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers, is_synthetic):\n",
    "    memberX, memberY, _ = transform_data(members, is_synthetic)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers, is_synthetic)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(pred_y)\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01432ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a933f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, train_size, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, train_size, test_ratio, is_synthetic)\n",
    "    target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ef35632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic):\n",
    "    members = []\n",
    "    nonmembers = []\n",
    "\n",
    "    memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers, is_synthetic)\n",
    "\n",
    "    # member\n",
    "    target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "    target_model_member_class = np.argmax(memberY, axis=1)\n",
    "    target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "    #target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "    members.append(np.ones(len(target_model_member_pred)))\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "    # nonmember\n",
    "    target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "    target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "    target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "    #target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "    nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "    full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "    full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "    print('\\n pred', full_attack_test_pred_val)\n",
    "    print('\\n class', full_attack_test_class_status)\n",
    "    print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "    attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)\n",
    "    \n",
    "    return attack_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f13a0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e68463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "train_size = 7000\n",
    "attack_test_size = 250\n",
    "data = pd.read_csv('data/avila-tr.txt', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = pd.read_csv('data/avila-ts.txt', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = df_rest.sample(n = 7000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:train_size,:].sample(n = attack_test_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  97.10000157356262 Target Test acc :  92.86666512489319\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 12\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5a961b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  98.28571677207947 Shadow Test acc :  61.33333444595337\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  99.61904883384705 Shadow Test acc :  60.88888645172119\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  99.80952143669128 Shadow Test acc :  60.44444441795349\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  99.80952143669128 Shadow Test acc :  66.22222065925598\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  97.90475964546204 Shadow Test acc :  64.8888885974884\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  97.90475964546204 Shadow Test acc :  68.44444274902344\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  99.61904883384705 Shadow Test acc :  63.999998569488525\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  100.0 Shadow Test acc :  63.555556535720825\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  98.66666793823242 Shadow Test acc :  68.00000071525574\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  59.55555438995361\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  99.42857027053833 Shadow Test acc :  65.3333306312561\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  96.76190614700317 Shadow Test acc :  63.11110854148865\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  93.14285516738892 Shadow Test acc :  62.66666650772095\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  97.7142870426178 Shadow Test acc :  72.44444489479065\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  99.04761910438538 Shadow Test acc :  64.8888885974884\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  62.66666650772095\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  98.85714054107666 Shadow Test acc :  60.44444441795349\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  99.80952143669128 Shadow Test acc :  66.66666865348816\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  99.80952143669128 Shadow Test acc :  65.3333306312561\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  99.42857027053833 Shadow Test acc :  62.22222447395325\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 750\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9074b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "\n",
      " pred (array([[9.8714331e-13, 6.9560365e-29, 0.0000000e+00, ..., 2.6858010e-24,\n",
      "        7.9548124e-28, 9.0669403e-16],\n",
      "       [9.9999827e-01, 1.3162569e-11, 9.4170819e-15, ..., 3.0618432e-07,\n",
      "        1.3237573e-07, 4.1405130e-07],\n",
      "       [8.4214187e-01, 1.1881189e-06, 4.3991413e-06, ..., 6.5386434e-06,\n",
      "        1.2312449e-05, 8.1916196e-06],\n",
      "       ...,\n",
      "       [2.0310460e-01, 5.5409937e-06, 3.1311571e-04, ..., 5.8683008e-04,\n",
      "        7.6346754e-05, 6.0785293e-05],\n",
      "       [4.1725137e-08, 1.8437559e-13, 3.0010899e-10, ..., 6.9823525e-09,\n",
      "        4.5893788e-03, 9.9534422e-01],\n",
      "       [3.5555948e-02, 7.4192535e-08, 6.0806116e-09, ..., 3.6230577e-07,\n",
      "        1.5032805e-06, 1.0204015e-05]], dtype=float32), array([[9.9714029e-01, 1.8152552e-09, 1.3582187e-12, ..., 2.2745754e-08,\n",
      "        2.8992619e-11, 2.2385427e-08],\n",
      "       [9.7578484e-01, 5.7244280e-09, 2.1229867e-02, ..., 5.0547860e-06,\n",
      "        1.4580105e-03, 1.5208459e-03],\n",
      "       [1.3312943e-05, 7.8457033e-12, 1.4787159e-18, ..., 3.9531895e-11,\n",
      "        1.9779311e-05, 1.3654228e-02],\n",
      "       ...,\n",
      "       [9.1326928e-01, 4.0222371e-08, 3.1177612e-09, ..., 9.7958500e-06,\n",
      "        1.2114477e-07, 7.9576944e-07],\n",
      "       [1.6353978e-09, 3.1646759e-19, 8.0512016e-31, ..., 1.5984066e-17,\n",
      "        2.1198939e-08, 4.9687678e-06],\n",
      "       [1.9505781e-01, 8.3256593e-09, 1.4451637e-09, ..., 6.5696433e-08,\n",
      "        2.4014912e-10, 6.8270765e-08]], dtype=float32))\n",
      "\n",
      " class (array([6, 0, 0, 0, 3, 3, 0, 0, 4, 7, 0, 0, 0, 7, 0, 0, 7, 5, 0, 9, 4, 4,\n",
      "       0, 0, 0, 6, 4, 0, 2, 0, 3, 0, 0, 4, 2, 4, 4, 7, 7, 3, 0, 1, 7, 0,\n",
      "       6, 0, 4, 0, 0, 0, 2, 6, 0, 3, 2, 6, 3, 3, 3, 5, 0, 4, 3, 8, 0, 0,\n",
      "       0, 4, 4, 6, 4, 9, 0, 1, 4, 0, 0, 0, 3, 4, 6, 6, 7, 6, 0, 4, 5, 7,\n",
      "       7, 1, 0, 7, 7, 0, 0, 7, 0, 6, 4, 7, 7, 7, 0, 4, 0, 0, 8, 0, 4, 0,\n",
      "       0, 3, 0, 3, 6, 8, 4, 3, 0, 0, 0, 0, 0, 9, 0, 4, 0, 0, 9, 0, 4, 0,\n",
      "       8, 0, 9, 0, 0, 3, 3, 0, 7, 0, 0, 0, 4, 7, 7, 3, 4, 4, 8, 4, 5, 0,\n",
      "       0, 4, 0, 0, 0, 7, 7, 0, 0, 0, 0, 4, 0, 4, 4, 3, 2, 0, 4, 0, 3, 0,\n",
      "       3, 0, 7, 7, 0, 4, 0, 3, 4, 4, 7, 0, 0, 3, 0, 0, 1, 8, 7, 4, 5, 7,\n",
      "       0, 4, 4, 7, 9, 0, 0, 7, 8, 4, 4, 0, 3, 0, 4, 5, 7, 7, 6, 6, 5, 5,\n",
      "       8, 8, 0, 9, 0, 0, 5, 0, 9, 7, 0, 8, 2, 0, 8, 0, 4, 4, 3, 4, 0, 8,\n",
      "       8, 4, 0, 8, 8, 3, 9, 6]), array([ 0,  0,  7,  5,  4,  4,  0,  3,  7,  0,  5,  0,  3,  0,  1,  7,  7,\n",
      "        3,  9,  3,  0,  3,  4,  3,  3,  7,  4,  4, 10,  7,  5,  0,  3,  1,\n",
      "       10,  9,  2,  0,  0,  0,  0,  7,  7,  0,  0,  0,  9,  0,  0,  6,  9,\n",
      "        0,  0,  7,  5,  0,  4,  0,  0,  0,  6,  1,  0,  0,  5,  7,  0,  0,\n",
      "        0,  0,  4,  3,  0,  0,  0,  0,  6,  0,  0,  0,  0,  9,  0,  6,  3,\n",
      "        0,  9,  0,  9,  9,  4,  0,  0,  3,  4,  0,  0,  7,  4,  5,  0,  2,\n",
      "        0,  7,  4,  4,  3,  0,  0,  0,  4,  0,  0,  4,  2,  6,  9,  0,  0,\n",
      "        0,  0,  9,  3,  0,  0,  4,  0,  4,  4,  9,  0,  7,  0,  8,  7,  4,\n",
      "        4,  0,  0,  4,  0,  4,  9,  3,  1,  0,  0,  0,  0,  9,  6,  5,  5,\n",
      "        0,  0,  0,  0,  4,  0,  4,  4,  2,  7,  3,  4,  4,  0,  0,  4,  3,\n",
      "        0,  0,  0,  3, 10,  0,  0,  6,  0,  2,  4,  0,  0,  2,  0,  3,  0,\n",
      "        7,  9,  9,  7,  8,  7,  0,  0,  3,  0,  4,  3,  3,  4,  4,  4,  7,\n",
      "        6,  0,  3,  6,  0,  0,  3,  0,  4,  4,  1,  2,  4,  9,  0,  4, 10,\n",
      "        0,  9,  0,  7,  6,  0,  3,  0,  2,  7,  0,  0,  0,  0,  4,  9,  0,\n",
      "        4,  0,  3,  0,  4,  7,  9,  0,  9,  0,  7,  4]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n",
      "0\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2\n",
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f771fa99dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "3\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f776228fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "4\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "10\n",
      "11\n",
      "TP: 101     FP: 88     FN: 149     TN: 158\n",
      "PPV: 0.5344\n",
      "Advantage: 0.0463\n",
      "Accuracy:  0.5221774193548387 Precision:  0.5343915343915344\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ae477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f3d6ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset\n",
    "train_size = 500\n",
    "attack_test_size = 250\n",
    "target_dataset = pd.read_csv('data/avila_sds.csv', na_values=[\"?\"], header=None)\n",
    "df = pd.read_csv('data/avila-ts.txt', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = df.sample(n = 5000, replace = False)\n",
    "df_rest = df.loc[~df.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = attack_test_size, replace = False)\n",
    "attack_test_members = pd.read_csv('data/avila-tr.txt', na_values=[\"?\"], header=None)\n",
    "attack_test_members = attack_test_members.sample(n=attack_test_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11a1cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7000\n",
    "target_dataset = pd.read_csv('data/avila_sds_sdv_copulagan.csv', na_values=[\"?\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e8d406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  57.3285698890686 Target Test acc :  41.76666736602783\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 12\n",
    "is_synthetic = True\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c83ba152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "shadow_i_trainX =  525 shadow_i_trainY =  525 shadow_i_testX =  225 shadow_i_testY =  225\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  91.80952310562134 Shadow Test acc :  63.11110854148865\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  99.04761910438538 Shadow Test acc :  70.2222228050232\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  99.04761910438538 Shadow Test acc :  66.22222065925598\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  96.57142758369446 Shadow Test acc :  58.222222328186035\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  97.52380847930908 Shadow Test acc :  63.555556535720825\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  99.04761910438538 Shadow Test acc :  61.33333444595337\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  98.85714054107666 Shadow Test acc :  64.4444465637207\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  99.23809766769409 Shadow Test acc :  60.88888645172119\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  96.76190614700317 Shadow Test acc :  65.77777862548828\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  99.61904883384705 Shadow Test acc :  67.11111068725586\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  99.80952143669128 Shadow Test acc :  60.00000238418579\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  97.7142870426178 Shadow Test acc :  63.999998569488525\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  97.52380847930908 Shadow Test acc :  58.666664361953735\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  99.23809766769409 Shadow Test acc :  61.77777647972107\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  99.61904883384705 Shadow Test acc :  60.44444441795349\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  97.33333587646484 Shadow Test acc :  63.11110854148865\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  99.42857027053833 Shadow Test acc :  66.66666865348816\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  99.61904883384705 Shadow Test acc :  65.3333306312561\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  98.4761893749237 Shadow Test acc :  65.3333306312561\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  96.76190614700317 Shadow Test acc :  59.11111235618591\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 750\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ef67324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "\n",
      " pred (array([[8.29200362e-05, 6.31923536e-09, 8.15046860e-06, ...,\n",
      "        1.09960241e-09, 2.21771259e-07, 3.28547202e-07],\n",
      "       [1.63710961e-10, 1.48050272e-19, 1.82836905e-11, ...,\n",
      "        4.57471699e-10, 9.97439981e-01, 1.82544964e-03],\n",
      "       [1.00084848e-03, 1.78367738e-08, 3.51257114e-07, ...,\n",
      "        1.08447065e-08, 1.36180915e-08, 3.47947719e-07],\n",
      "       ...,\n",
      "       [9.67245042e-01, 4.44265025e-09, 1.31724098e-09, ...,\n",
      "        5.87845648e-08, 1.52431720e-10, 1.77634161e-06],\n",
      "       [9.61077929e-01, 1.22125229e-07, 1.76585491e-09, ...,\n",
      "        3.11442790e-07, 7.19873050e-09, 2.58238629e-06],\n",
      "       [4.50925291e-01, 4.31745957e-06, 1.80087522e-06, ...,\n",
      "        1.57275008e-05, 1.20057200e-06, 4.96224791e-04]], dtype=float32), array([[4.3696832e-02, 1.8540393e-07, 2.5460375e-08, ..., 6.5816877e-08,\n",
      "        6.3296968e-10, 7.4345695e-07],\n",
      "       [5.0678100e-03, 1.7937796e-07, 8.4155627e-06, ..., 9.6001156e-07,\n",
      "        2.2927592e-05, 8.2367042e-06],\n",
      "       [9.7652799e-01, 1.8091067e-07, 9.4485983e-09, ..., 2.3256497e-07,\n",
      "        1.0743219e-08, 2.2757001e-06],\n",
      "       ...,\n",
      "       [2.6265090e-02, 3.2523738e-07, 4.9773371e-06, ..., 2.5358952e-07,\n",
      "        1.4816384e-03, 6.4991394e-07],\n",
      "       [1.3641060e-06, 7.7199754e-11, 6.4312073e-04, ..., 2.6584108e-05,\n",
      "        8.6214042e-01, 2.6546488e-02],\n",
      "       [1.7936761e-06, 9.1542746e-11, 4.3956411e-06, ..., 3.2982701e-08,\n",
      "        9.9415475e-01, 4.9895076e-03]], dtype=float32))\n",
      "\n",
      " class (array([ 4,  9,  4,  0,  0,  0,  3,  3,  6, 10,  0,  3,  5,  0,  2,  0,  1,\n",
      "        9,  1,  0,  0,  4,  0,  2,  6,  4,  2,  6,  0,  4,  4,  7,  0,  3,\n",
      "        0,  0,  4,  7,  3,  0,  3,  0,  0,  4,  9,  0,  0,  4,  1,  0,  3,\n",
      "        0,  0,  4,  6,  0,  0,  6,  4,  6,  4,  4,  4,  0,  5,  0,  3,  0,\n",
      "        0,  9,  9,  0,  0,  3,  0,  0,  0,  5,  4,  4,  0,  0,  0,  4,  0,\n",
      "        4,  3,  0,  9,  0,  0, 10,  5,  4,  0,  7,  0,  4,  3,  7,  0,  0,\n",
      "        0,  4,  5,  0,  4,  3, 10,  7, 10,  4,  0,  2,  3,  6,  0,  0,  0,\n",
      "        7,  4,  0, 10,  3,  0,  9,  0,  0,  0,  0,  5,  8,  0,  4,  3,  0,\n",
      "        5,  7,  0,  4,  0,  3,  4,  4, 10, 10,  4,  0, 10,  0,  2, 10, 10,\n",
      "        0,  0,  3,  0,  4,  0,  0,  5,  0,  0,  0,  6,  0,  4,  3,  0,  3,\n",
      "        3,  0,  0,  0,  4,  3,  4,  4,  6,  0,  7,  0,  9,  0,  0,  4,  6,\n",
      "        0,  4,  5,  3,  9,  2,  0,  0,  5,  4, 10,  0,  0,  0,  3,  7,  0,\n",
      "        0,  0,  4,  0,  7,  5,  4,  3,  3,  4,  0,  3,  6,  0,  0, 10,  0,\n",
      "        4,  4,  0,  0,  3,  3,  3,  0,  0,  9,  9,  0,  7,  0,  0,  0,  5,\n",
      "        4,  0,  0,  4,  0,  3,  7,  3,  0,  0,  0,  6]), array([ 4,  8,  0,  4,  0,  3,  0,  9,  4,  3,  0,  4,  0,  4,  0,  0,  0,\n",
      "        0,  3,  0, 10,  0,  1,  3,  0,  4,  9,  7,  7,  3,  4,  0,  0,  6,\n",
      "        0,  6,  4,  4,  0,  3,  0,  4,  6,  4,  0,  4,  7,  5,  0,  7,  5,\n",
      "        3,  6,  0,  0,  0,  0,  0,  4,  3,  5,  4,  9,  7,  3,  0, 10,  0,\n",
      "        0,  0,  4,  4,  0,  4,  3,  0,  4,  3, 10,  0,  7,  4,  0,  4,  0,\n",
      "        4, 10,  0,  3,  4,  3,  0,  9,  4,  7,  6,  0,  7,  4,  4,  4,  0,\n",
      "        0,  4,  0,  0,  0,  5,  0,  4,  0,  3,  0,  5,  7,  0,  0,  0,  2,\n",
      "        7,  9,  0,  6,  0,  0,  0,  0,  3,  7,  7,  0, 10,  4,  0,  3,  0,\n",
      "        3,  7,  3,  0,  0,  0,  5,  0,  0,  4,  7,  0,  3,  0,  0,  4,  1,\n",
      "        0,  0,  0,  0,  3,  0,  6,  0,  4,  9,  0,  0,  0,  4,  4,  5,  0,\n",
      "        0,  0,  3,  3,  4,  4,  0,  0,  4,  5,  5,  0,  0,  4,  7,  4,  0,\n",
      "        7,  3,  4,  3,  3,  0,  3,  6, 10,  0,  0,  0,  9,  0,  2,  4,  4,\n",
      "        0,  4,  3,  6,  0,  3,  0,  7,  2,  0,  7,  0,  7,  9,  0,  4,  5,\n",
      "        0,  7,  9,  0,  5,  4,  9,  0,  0,  0,  6,  0,  0,  3,  0,  9,  0,\n",
      "        7,  0,  3,  7,  4,  3,  9,  2,  4,  3,  3, 10]))\n",
      "\n",
      " mem status (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n",
      "0\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "4\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "10\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "11\n",
      "TP: 76     FP: 70     FN: 174     TN: 180\n",
      "PPV: 0.5205\n",
      "Advantage: 0.0240\n",
      "Accuracy:  0.512 Precision:  0.5205479452054794\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fbe1dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/avila-tr.txt', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = pd.read_csv('data/avila-ts.txt', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = df_rest.sample(n = 7000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 1500, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:3000,:].sample(n = 1500, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9b6a811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, training_data_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:training_data_size,]\n",
    "    testX = x[5000:,]\n",
    "    trainY = y[0:training_data_size,]\n",
    "    testY = y[5000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "02c4e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Data Size:  2 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  16.760000586509705\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  39.05999958515167\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  17.560000717639923\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  7.5599998235702515\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  8.720000088214874\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  32.67999887466431\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  33.25999975204468\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  27.52000093460083\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  39.899998903274536\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  4.899999871850014\n",
      "\n",
      " Training Data Size:  5 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  22.87999987602234\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  34.299999475479126\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  13.600000739097595\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  41.760000586509705\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  33.52000117301941\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  16.06000065803528\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  12.89999932050705\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  19.539999961853027\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  26.480001211166382\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  18.99999976158142\n",
      "\n",
      " Training Data Size:  10 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  35.78000068664551\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  35.64000129699707\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  36.41999959945679\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  38.499999046325684\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  30.959999561309814\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  19.220000505447388\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  31.760001182556152\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  38.31999897956848\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  30.140000581741333\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  37.07999885082245\n",
      "\n",
      " Training Data Size:  15 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  32.1399986743927\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  37.90000081062317\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  35.31999886035919\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  37.34000027179718\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  37.63999938964844\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  33.75999927520752\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  33.88000130653381\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  38.339999318122864\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  34.860000014305115\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  31.139999628067017\n",
      "\n",
      " Training Data Size:  20 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  25.81999897956848\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  35.0600004196167\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  40.83999991416931\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  38.15999925136566\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  36.75999939441681\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  42.660000920295715\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  33.46000015735626\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  39.64000046253204\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  37.97999918460846\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  43.43999922275543\n",
      "\n",
      " Training Data Size:  25 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  38.22000026702881\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  36.959999799728394\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  45.100000500679016\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  33.61999988555908\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  37.65999972820282\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  38.06000053882599\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  42.69999861717224\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  41.040000319480896\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  44.940000772476196\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  35.04000008106232\n",
      "\n",
      " Training Data Size:  50 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  44.920000433921814\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  48.820000886917114\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  45.80000042915344\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  42.21999943256378\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  45.419999957084656\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  46.959999203681946\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  36.399999260902405\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  48.60000014305115\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  47.47999906539917\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  43.6599999666214\n",
      "\n",
      " Training Data Size:  100 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  51.99999809265137\n",
      "Iteration  1 Target Train acc :  91.00000262260437 Target Test acc :  51.980000734329224\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  45.500001311302185\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  49.3800014257431\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  53.21999788284302\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  49.61999952793121\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  49.09999966621399\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  50.4800021648407\n",
      "Iteration  8 Target Train acc :  98.00000190734863 Target Test acc :  53.21999788284302\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  48.48000109195709\n",
      "\n",
      " Training Data Size:  200 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  53.96000146865845\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  56.58000111579895\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  58.34000110626221\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  57.74000287055969\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  55.14000058174133\n",
      "Iteration  5 Target Train acc :  98.00000190734863 Target Test acc :  56.49999976158142\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  58.75999927520752\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  57.020002603530884\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  55.73999881744385\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  57.920002937316895\n",
      "\n",
      " Training Data Size:  500 \n",
      "\n",
      "Iteration  0 Target Train acc :  98.60000014305115 Target Test acc :  64.92000222206116\n",
      "Iteration  1 Target Train acc :  95.20000219345093 Target Test acc :  62.459999322891235\n",
      "Iteration  2 Target Train acc :  99.19999837875366 Target Test acc :  65.31999707221985\n",
      "Iteration  3 Target Train acc :  98.7999975681305 Target Test acc :  65.39999842643738\n",
      "Iteration  4 Target Train acc :  97.79999852180481 Target Test acc :  63.77999782562256\n",
      "Iteration  5 Target Train acc :  99.19999837875366 Target Test acc :  63.440001010894775\n",
      "Iteration  6 Target Train acc :  99.19999837875366 Target Test acc :  62.73999810218811\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  66.01999998092651\n",
      "Iteration  8 Target Train acc :  98.19999933242798 Target Test acc :  62.41999864578247\n",
      "Iteration  9 Target Train acc :  98.7999975681305 Target Test acc :  65.57999849319458\n",
      "\n",
      " Training Data Size:  1000 \n",
      "\n",
      "Iteration  0 Target Train acc :  97.29999899864197 Target Test acc :  72.79999852180481\n",
      "Iteration  1 Target Train acc :  97.79999852180481 Target Test acc :  68.91999840736389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 Target Train acc :  97.39999771118164 Target Test acc :  70.21999955177307\n",
      "Iteration  3 Target Train acc :  96.8999981880188 Target Test acc :  71.17999792098999\n",
      "Iteration  4 Target Train acc :  96.20000123977661 Target Test acc :  69.08000111579895\n",
      "Iteration  5 Target Train acc :  98.1000006198883 Target Test acc :  70.4200029373169\n",
      "Iteration  6 Target Train acc :  96.29999995231628 Target Test acc :  69.88000273704529\n",
      "Iteration  7 Target Train acc :  97.60000109672546 Target Test acc :  72.03999757766724\n",
      "Iteration  8 Target Train acc :  96.39999866485596 Target Test acc :  71.43999934196472\n",
      "Iteration  9 Target Train acc :  96.60000205039978 Target Test acc :  71.29999995231628\n",
      "\n",
      " Training Data Size:  2000 \n",
      "\n",
      "Iteration  0 Target Train acc :  94.30000185966492 Target Test acc :  74.72000122070312\n",
      "Iteration  1 Target Train acc :  96.5499997138977 Target Test acc :  79.37999963760376\n",
      "Iteration  2 Target Train acc :  98.25000166893005 Target Test acc :  78.75999808311462\n",
      "Iteration  3 Target Train acc :  96.8999981880188 Target Test acc :  77.89999842643738\n",
      "Iteration  4 Target Train acc :  95.70000171661377 Target Test acc :  77.53999829292297\n",
      "Iteration  5 Target Train acc :  97.45000004768372 Target Test acc :  79.1599988937378\n",
      "Iteration  6 Target Train acc :  94.70000267028809 Target Test acc :  77.28000283241272\n",
      "Iteration  7 Target Train acc :  97.45000004768372 Target Test acc :  78.47999930381775\n",
      "Iteration  8 Target Train acc :  95.49999833106995 Target Test acc :  79.04000282287598\n",
      "Iteration  9 Target Train acc :  97.39999771118164 Target Test acc :  79.1599988937378\n",
      "\n",
      " Training Data Size:  5000 \n",
      "\n",
      "Iteration  0 Target Train acc :  96.57999873161316 Target Test acc :  88.80000114440918\n",
      "Iteration  1 Target Train acc :  93.33999752998352 Target Test acc :  85.61999797821045\n",
      "Iteration  2 Target Train acc :  90.0600016117096 Target Test acc :  84.43999886512756\n",
      "Iteration  3 Target Train acc :  97.2599983215332 Target Test acc :  89.71999883651733\n",
      "Iteration  4 Target Train acc :  95.81999778747559 Target Test acc :  89.80000019073486\n",
      "Iteration  5 Target Train acc :  95.92000246047974 Target Test acc :  88.09999823570251\n",
      "Iteration  6 Target Train acc :  95.56000232696533 Target Test acc :  88.62000107765198\n",
      "Iteration  7 Target Train acc :  96.46000266075134 Target Test acc :  89.84000086784363\n",
      "Iteration  8 Target Train acc :  96.38000130653381 Target Test acc :  89.20000195503235\n",
      "Iteration  9 Target Train acc :  97.079998254776 Target Test acc :  90.31999707221985\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "per_class_sample=150\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 12\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "accuracy_df = pd.DataFrame()\n",
    "accuracy_df['training data size'] = np.nan\n",
    "accuracy_df['training accuracy'] = np.nan\n",
    "accuracy_df['test accuracy'] = np.nan\n",
    "accuracy_df['error'] = np.nan\n",
    "\n",
    "data = pd.read_csv('data/avila-tr.txt', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "for j in training_data_size:\n",
    "    print('\\n Training Data Size: ', j, '\\n')\n",
    "    for i in range(10):\n",
    "        target_dataset = data.sample(n = 10000, replace = False)\n",
    "        (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, j, test_ratio, is_synthetic)\n",
    "        target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "        #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "        history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "        score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "        _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        print('Iteration ', i, \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "        accuracy_df = accuracy_df.append({'training data size':j, 'training accuracy' : (train_acc * 100.0), 'test accuracy': (test_acc * 100.0), 'error': ((train_acc * 100.0)-(test_acc * 100.0))}, ignore_index=True)\n",
    "        #print('\\n', 'Model test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5a3c04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_df =pd.read_csv('data/adult_overfitting_test_trainsize')\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "\n",
    "avg_error_ci95_df = pd.DataFrame()\n",
    "avg_error_ci95_df['training data size'] = np.nan\n",
    "avg_error_ci95_df['average training accuracy'] = np.nan\n",
    "avg_error_ci95_df['average test accuracy'] = np.nan\n",
    "avg_error_ci95_df['average error'] = np.nan\n",
    "avg_error_ci95_df['ci95 low'] = np.nan\n",
    "avg_error_ci95_df['ci95 high'] = np.nan\n",
    "\n",
    "for i in training_data_size:\n",
    "    error = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'error'])\n",
    "    training_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'training accuracy'])\n",
    "    test_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'test accuracy'])\n",
    "    ci95 = stats.t.interval(alpha=0.95, df=len(error)-1, loc=np.mean(error), scale=stats.sem(error))\n",
    "    row = pd.DataFrame({'training data size': [i], 'average training accuracy': \\\n",
    "            [np.mean(training_accuracy)], 'average test accuracy': [np.mean(test_accuracy)], 'average error': [np.mean(error)],\\\n",
    "                                                  'ci95 low': [ci95[0]], 'ci95 high': [ci95[1]]})\n",
    "    avg_error_ci95_df = pd.concat([avg_error_ci95_df, row], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ecafb45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training data size</th>\n",
       "      <th>average training accuracy</th>\n",
       "      <th>average test accuracy</th>\n",
       "      <th>average error</th>\n",
       "      <th>ci95 low</th>\n",
       "      <th>ci95 high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>22.792000</td>\n",
       "      <td>77.208000</td>\n",
       "      <td>67.667063</td>\n",
       "      <td>86.748937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.004000</td>\n",
       "      <td>75.996000</td>\n",
       "      <td>69.007891</td>\n",
       "      <td>82.984108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33.382000</td>\n",
       "      <td>66.618000</td>\n",
       "      <td>62.461118</td>\n",
       "      <td>70.774882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.232000</td>\n",
       "      <td>64.768000</td>\n",
       "      <td>62.960384</td>\n",
       "      <td>66.575616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.382000</td>\n",
       "      <td>62.618000</td>\n",
       "      <td>58.943850</td>\n",
       "      <td>66.292150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>39.334000</td>\n",
       "      <td>60.666000</td>\n",
       "      <td>57.831477</td>\n",
       "      <td>63.500523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>45.028000</td>\n",
       "      <td>54.972000</td>\n",
       "      <td>52.339900</td>\n",
       "      <td>57.604101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.900000</td>\n",
       "      <td>50.298000</td>\n",
       "      <td>48.602000</td>\n",
       "      <td>45.522708</td>\n",
       "      <td>51.681293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200.0</td>\n",
       "      <td>99.800000</td>\n",
       "      <td>56.770001</td>\n",
       "      <td>43.029999</td>\n",
       "      <td>41.886576</td>\n",
       "      <td>44.173422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>98.499999</td>\n",
       "      <td>64.207999</td>\n",
       "      <td>34.292000</td>\n",
       "      <td>33.395389</td>\n",
       "      <td>35.188611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>97.060000</td>\n",
       "      <td>70.728000</td>\n",
       "      <td>26.332000</td>\n",
       "      <td>25.350823</td>\n",
       "      <td>27.313177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>96.420000</td>\n",
       "      <td>78.142000</td>\n",
       "      <td>18.278000</td>\n",
       "      <td>17.545025</td>\n",
       "      <td>19.010976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>95.446000</td>\n",
       "      <td>88.446000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.456580</td>\n",
       "      <td>7.543420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training data size  average training accuracy  average test accuracy  \\\n",
       "0                  2.0                 100.000000              22.792000   \n",
       "1                  5.0                 100.000000              24.004000   \n",
       "2                 10.0                 100.000000              33.382000   \n",
       "3                 15.0                 100.000000              35.232000   \n",
       "4                 20.0                 100.000000              37.382000   \n",
       "5                 25.0                 100.000000              39.334000   \n",
       "6                 50.0                 100.000000              45.028000   \n",
       "7                100.0                  98.900000              50.298000   \n",
       "8                200.0                  99.800000              56.770001   \n",
       "9                500.0                  98.499999              64.207999   \n",
       "10              1000.0                  97.060000              70.728000   \n",
       "11              2000.0                  96.420000              78.142000   \n",
       "12              5000.0                  95.446000              88.446000   \n",
       "\n",
       "    average error   ci95 low  ci95 high  \n",
       "0       77.208000  67.667063  86.748937  \n",
       "1       75.996000  69.007891  82.984108  \n",
       "2       66.618000  62.461118  70.774882  \n",
       "3       64.768000  62.960384  66.575616  \n",
       "4       62.618000  58.943850  66.292150  \n",
       "5       60.666000  57.831477  63.500523  \n",
       "6       54.972000  52.339900  57.604101  \n",
       "7       48.602000  45.522708  51.681293  \n",
       "8       43.029999  41.886576  44.173422  \n",
       "9       34.292000  33.395389  35.188611  \n",
       "10      26.332000  25.350823  27.313177  \n",
       "11      18.278000  17.545025  19.010976  \n",
       "12       7.000000   6.456580   7.543420  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_error_ci95_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ad759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
