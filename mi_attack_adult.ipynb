{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1027973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score\n",
    "MODEL_PATH = './model/'\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "942cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with specific index\n",
    "# data = pd.read_csv('data/adult.data', na_values=[\"?\"])\n",
    "# target_dataset = pd.DataFrame(data.iloc[1:10001,].values)\n",
    "# shadow_dataset = pd.DataFrame(data.iloc[15001:30001,].values)\n",
    "# attack_test_nonmembers = pd.DataFrame(data.iloc[11001:14001,].values)\n",
    "# attack_test_members = pd.DataFrame(data.iloc[2001:5001,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0793fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_name):\n",
    "    with np.load(DATA_PATH + data_name) as f:\n",
    "        train_x, train_y, test_x, test_y = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f080a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_transform_data(dataset):\n",
    "    x = dataset.iloc[:,0:dataset.shape[1]-1] # seperate the feature column from class label\n",
    "    y = dataset.iloc[:,-1] # label column\n",
    "    \n",
    "\n",
    "    dim=x.shape[1] # number of feature columns\n",
    "\n",
    "    #num of classes\n",
    "    num_classes=2\n",
    "\n",
    "    for j in range(0,dim):\n",
    "        if x.iloc[:,j].dtypes == object:   # transform categorical variables\n",
    "            x.iloc[:,j] = x.iloc[:,j].astype('category') # change datatype to categorical\n",
    "            x.iloc[:,j] = x.iloc[:,j].cat.codes # change from category name to category number\n",
    "        else:  #transform numrical variables to standard scaler form \n",
    "            sc = StandardScaler()  \n",
    "            val=np.array(x.iloc[:,j]).reshape(-1,1)\n",
    "            std_data = sc.fit_transform(val)\n",
    "            std_data = pd.DataFrame(std_data)\n",
    "            x.iloc[:,j]=std_data\n",
    "            print(x.iloc[:,j])\n",
    "\n",
    "    y = y.astype('category') # change label to categorical\n",
    "    y = y.cat.codes # change from category name to number\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "630d4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, is_synthetic):\n",
    "    \n",
    "    if(is_synthetic == False):\n",
    "        for col in [1,3,5,6,7,8,9,13,14]:\n",
    "            le = LabelEncoder()\n",
    "            dataset[col] = le.fit_transform(dataset[col].astype('str'))\n",
    "\n",
    "        # normalize the values\n",
    "        x_range = [i for i in range(14)]\n",
    "        dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "        x = dataset[x_range].values\n",
    "        y = dataset[14].values\n",
    "    else:\n",
    "        for col in [1,2,3,4,5,6,7,11,12]:\n",
    "            le = LabelEncoder()\n",
    "            dataset[col] = le.fit_transform(dataset[col].astype('str'))\n",
    "\n",
    "        # normalize the values\n",
    "        x_range = [i for i in range(12)]\n",
    "        dataset[x_range] = dataset[x_range]/dataset[x_range].max()\n",
    "\n",
    "        x = dataset[x_range].values\n",
    "        y = dataset[12].values\n",
    "        \n",
    "    \n",
    "    dim = x.shape[1]\n",
    "    \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    \n",
    "    y=to_categorical(y)\n",
    "    \n",
    "    return x, y, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3880a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:7000,]\n",
    "    testX = x[7000:,]\n",
    "    trainY = y[0:7000,]\n",
    "    testY = y[7000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a33ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(n_class,pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(248))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=3\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fa65618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shadow_data(dataset, n_shadow, shadow_size, test_ratio, is_synthetic):\n",
    "    x, y, _ = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    shadow_indices = np.arange(len(dataset))\n",
    "    \n",
    "   \n",
    "    for i in range(n_shadow):\n",
    "        shadow_i_indices = np.random.choice(shadow_indices, shadow_size, replace=False)\n",
    "        shadow_i_x, shadow_i_y = x[shadow_i_indices], y[shadow_i_indices]\n",
    "        trainX,testX, trainY, testY = train_test_split(shadow_i_x, shadow_i_y, test_size=test_ratio)\n",
    "        print('shadow_i_trainX = ', len(trainX), 'shadow_i_trainY = ', len(trainY), 'shadow_i_testX = ', len(testX), 'shadow_i_testY = ', len(testY))\n",
    "        \n",
    "        np.savez(DATA_PATH + 'shadow_adult{}_data.npz'.format(i), trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0da144ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_shadow_models(n_shadow, n_class, dim, channel):\n",
    "    full_sm_train_pred=[]\n",
    "    full_sm_train_class=[]\n",
    "    \n",
    "    full_sm_test_pred=[]\n",
    "    full_sm_test_class=[]\n",
    "    \n",
    "    full_clz_train=[]\n",
    "    full_clz_test=[]\n",
    "    \n",
    "    members=[]\n",
    "    nonmembers=[]\n",
    "    \n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "\n",
    "    for j in range(n_shadow):\n",
    "        \n",
    "        print(\"Shadow Model \", j)\n",
    "        \n",
    "        print('Training shadow model {}'.format(j))\n",
    "        data = read_data('shadow_adult{}_data.npz'.format(j))\n",
    "        x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test = data\n",
    "        #print('x_shadow trian\\n', x_shadow_train,'\\n y_shadow trian\\n', y_shadow_train, '\\n x_shadow test\\n', x_shadow_test, '\\n y_shadow test\\n', y_shadow_test)\n",
    "\n",
    "        model, act_layer = build_simple_mlp(n_class,dim, channel)\n",
    "            \n",
    "            \n",
    "        # fit model\n",
    "        history = model.fit(x_shadow_train, y_shadow_train, epochs=EPS, batch_size=32, validation_data=(x_shadow_test, y_shadow_test), verbose=0)\n",
    "    \n",
    "        # evaluate model\n",
    "        _, train_acc = model.evaluate(x_shadow_train, y_shadow_train, verbose=0)\n",
    "        _, test_acc = model.evaluate(x_shadow_test, y_shadow_test, verbose=0)\n",
    "        print(\"Shadow Train acc : \", (train_acc * 100.0),\"Shadow Test acc : \", (test_acc * 100.0))\n",
    "        train_accuracy.append((train_acc * 100.0))\n",
    "        test_accuracy.append((test_acc * 100.0))\n",
    "\n",
    "    \n",
    "        #train SM\n",
    "        sm_train_pred=model.predict(x_shadow_train, batch_size=32)\n",
    "        sm_train_class=np.argmax(y_shadow_train,axis=1)\n",
    "    \n",
    "    \n",
    "        #test SM\n",
    "        sm_test_pred=model.predict(x_shadow_test, batch_size=32)\n",
    "        sm_test_class=np.argmax(y_shadow_test,axis=1)\n",
    "        \n",
    "     \n",
    "        full_sm_train_pred.append(sm_train_pred)        \n",
    "        full_sm_train_class.append(sm_train_class)\n",
    "        members.append(np.ones(len(sm_train_pred)))\n",
    "        \n",
    "        full_sm_test_pred.append(sm_test_pred)        \n",
    "        full_sm_test_class.append(sm_test_class) \n",
    "        nonmembers.append(np.zeros(len(sm_test_pred)))\n",
    "\n",
    "\n",
    "    full_sm_train_pred = np.vstack(full_sm_train_pred)\n",
    "    full_sm_train_class = [item for sublist in full_sm_train_class for item in sublist]\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "    \n",
    "    full_sm_test_pred = np.vstack(full_sm_test_pred)\n",
    "    full_sm_test_class = [item for sublist in full_sm_test_class for item in sublist]\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "    \n",
    "    shadow_train_performance=(full_sm_train_pred, np.array(full_sm_train_class))\n",
    "    shadow_test_performance=(full_sm_test_pred, np.array(full_sm_test_class))\n",
    "\n",
    "\n",
    "    ###atack data preparation\n",
    "    attack_x = (full_sm_train_pred,full_sm_test_pred)\n",
    "    #attack_x = np.vstack(attack_x)\n",
    "    \n",
    "    attack_y = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    #attack_y = np.concatenate(attack_y)\n",
    "    #attack_y = attack_y.astype('int32')\n",
    "    \n",
    "    \n",
    "    classes = (np.array(full_sm_train_class),np.array(full_sm_test_class))\n",
    "    #classes = np.array([item for sublist in classes for item in sublist])\n",
    "\n",
    "\n",
    "    attack_dataset = (attack_x,attack_y,classes)\n",
    "    shadow_accuracy = (train_accuracy, test_accuracy)\n",
    "\n",
    "            \n",
    "    return  shadow_train_performance, shadow_test_performance, attack_dataset, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, model, shadow_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f90bfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack_model(n_class):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7909a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_mlp(pix,d):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=pix))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation(\"tanh\"))\n",
    "#     model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    act_layer=1\n",
    "    \n",
    "    return model, act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b5974c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_attack_train_data(n_attack_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(n_attack_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(n_attack_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(n_attack_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(n_attack_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(n_attack_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(n_attack_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "\n",
    "    memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "    memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "    memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "    memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "    realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "    realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "    attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f855c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_validation_data(attack_test_data):\n",
    "\n",
    "    attack_mem = pd.DataFrame(attack_test_data[0][0])\n",
    "    attack_nmem = pd.DataFrame(attack_test_data[0][1])\n",
    "    \n",
    "    attack_mem_status = pd.DataFrame(attack_test_data[1][0])\n",
    "    attack_mem_status.columns = [\"membership\"]\n",
    "    \n",
    "    attack_nmem_status = pd.DataFrame(attack_test_data[1][1])\n",
    "    attack_nmem_status.columns = [\"membership\"]\n",
    "    \n",
    "    real_class_mem = pd.DataFrame(attack_test_data[2][0])\n",
    "    real_class_mem.columns = [\"y\"]\n",
    "    \n",
    "    real_class_nmem = pd.DataFrame(attack_test_data[2][1])\n",
    "    real_class_nmem.columns = [\"y\"]\n",
    "    \n",
    "    mem_df = pd.concat([attack_mem,real_class_mem],axis=1)\n",
    "    nmem_df = pd.concat([attack_nmem,real_class_nmem],axis=1)\n",
    "\n",
    "#     memdf = pd.concat([attack_mem,attack_nmem],axis=0)\n",
    "#     memdf = memdf.reset_index(drop=True)\n",
    "\n",
    "#     memstatus =  pd.concat([attack_mem_status,attack_nmem_status],axis=0)\n",
    "#     memstatus = memstatus.reset_index(drop=True)\n",
    "\n",
    "#     realclass = pd.concat([real_class_mem,real_class_nmem],axis=0)\n",
    "#     realclass = realclass.reset_index(drop=True)\n",
    "\n",
    "#     attack_df = pd.concat([memdf,realclass,memstatus],axis=1)\n",
    "    \n",
    "    return mem_df, nmem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53d38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_test_data(members, nonmembers, is_synthetic):\n",
    "    memberX, memberY, _ = transform_data(members, is_synthetic)\n",
    "    \n",
    "    nonmemberX, nonmemberY, _ = transform_data(nonmembers, is_synthetic)\n",
    "    \n",
    "    return memberX, memberY, nonmemberX, nonmemberY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a49a59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prety_print_result(mem, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(mem, pred).ravel()\n",
    "    print('TP: %d     FP: %d     FN: %d     TN: %d' % (tp, fp, fn, tn))\n",
    "    if tp == fp == 0:\n",
    "        print('PPV: 0\\nAdvantage: 0')\n",
    "    else:\n",
    "        print('PPV: %.4f\\nAdvantage: %.4f' % (tp / (tp + fp), tp / (tp + fn) - fp / (tn + fp)))\n",
    "\n",
    "    return tp, fp, fn, tn, (tp / (tp + fp)), (tp / (tp + fn) - fp / (tn + fp)), ((tp+tn)/(tp+tn+fp+fn)),  (tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3a729d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(attack_data, check_membership, n_hidden=50, learning_rate=0.01, batch_size=200, epochs=50, model='nn', l2_ratio=1e-7):\n",
    "\n",
    "    x, y,  classes = attack_data\n",
    "\n",
    "    train_x = x[0]\n",
    "    train_y = y[0]\n",
    "    test_x = x[1]\n",
    "    test_y = y[1]\n",
    "    train_classes = classes[0]\n",
    "    test_classes = classes[1]\n",
    "    \n",
    "    \n",
    "    checkmem_prediction_vals, checkmem_membership_status, checkmem_class_status = check_membership\n",
    "    \n",
    "    checkmem_prediction_vals=np.vstack(checkmem_prediction_vals)\n",
    "    checkmem_membership_status=np.array([item for sublist in checkmem_membership_status for item in sublist])\n",
    "    checkmem_class_status=np.array([item for sublist in checkmem_class_status for item in sublist])\n",
    "    \n",
    "    train_indices = np.arange(len(train_x))\n",
    "    test_indices = np.arange(len(test_x))\n",
    "    unique_classes = np.unique(train_classes)\n",
    "\n",
    "\n",
    "    predicted_membership, target_membership = [], []\n",
    "    for c in unique_classes:\n",
    "        print(\"Class : \", c)\n",
    "        c_train_indices = train_indices[train_classes == c]\n",
    "        c_train_x, c_train_y = train_x[c_train_indices], train_y[c_train_indices]\n",
    "        c_test_indices = test_indices[test_classes == c]\n",
    "        c_test_x, c_test_y = test_x[c_test_indices], test_y[c_test_indices]\n",
    "        c_dataset = (c_train_x, c_train_y, c_test_x, c_test_y)        \n",
    "        \n",
    "        full_cx_data=(c_train_x,c_test_x)\n",
    "        full_cx_data = np.vstack(full_cx_data)\n",
    "\n",
    "        full_cy_data=(c_train_y,c_test_y)\n",
    "        full_cy_data = np.array([item for sublist in full_cy_data for item in sublist])\n",
    "        \n",
    "        d=1\n",
    "        pix = full_cx_data.shape[1]\n",
    "        classifier, _ = attack_mlp(pix,d)\n",
    "        history = classifier.fit(full_cx_data, full_cy_data, epochs=EPS, batch_size=32, verbose=0)\n",
    "\n",
    "        #get predictions on real train and test data\n",
    "        c_indices = np.where(checkmem_class_status==c)\n",
    "        pred_y = classifier.predict(checkmem_prediction_vals[c_indices])\n",
    "        print(pred_y)\n",
    "        c_pred_y = np.argmax(pred_y, axis=1)\n",
    "        c_target_y = checkmem_membership_status[c_indices]\n",
    "        \n",
    "       \n",
    "        target_membership.append(c_target_y)\n",
    "        predicted_membership.append(c_pred_y)\n",
    "\n",
    "    target_membership=np.array([item for sublist in target_membership for item in sublist])\n",
    "    predicted_membership=np.array([item for sublist in predicted_membership for item in sublist])\n",
    "\n",
    "\n",
    "    tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (target_membership,predicted_membership)   \n",
    "    return tp, fp, fn, tn, precision, advj, acc, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01432ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shokri_attack(attack_df, mem_validation, nmem_validation):\n",
    "    \n",
    "    predicted_membership, predicted_nmembership, true_membership, TP_idx, TN_idx  = [], [], [], [], []\n",
    "\n",
    "    class_val = np.unique(attack_df['y'])\n",
    "    ncval=attack_df.shape[1]-1\n",
    "    \n",
    "    for c_val in class_val:\n",
    "\n",
    "        print(c_val)\n",
    "        \n",
    "        filter_rec_all = attack_df[(attack_df['y'] == c_val)]\n",
    "        filter_rec_idx = np.array(filter_rec_all.index)\n",
    "        \n",
    "        attack_feat = filter_rec_all.iloc[:, 0:ncval]\n",
    "        attack_class = filter_rec_all['membership']\n",
    "             \n",
    "        d=1\n",
    "        pix = attack_feat.shape[1]\n",
    "        \n",
    "        attack_model, _ = attack_mlp(pix,d)\n",
    "        \n",
    "       \n",
    "        history = attack_model.fit(attack_feat, attack_class, epochs=EPS, batch_size=32, verbose=0)\n",
    "        \n",
    "        mcval=mem_validation.shape[1]-1\n",
    "        \n",
    "        \n",
    "        check_mem_feat = mem_validation[mem_validation['y']==c_val]\n",
    "        check_nmem_feat = nmem_validation[nmem_validation['y']==c_val]\n",
    "        \n",
    "        if (len(check_mem_feat)!=0) and (len(check_nmem_feat)!=0):\n",
    "        \n",
    "            check_mem_feat_idx =  np.array(check_mem_feat.index)\n",
    "\n",
    "\n",
    "            check_nmem_feat_idx =  np.array(check_nmem_feat.index)\n",
    "\n",
    "            #print(check_nmem_feat_idx)\n",
    "            #print(np.argmax(mpred,axis=1)==0)\n",
    "\n",
    "\n",
    "            mpred = attack_model.predict(np.array(check_mem_feat))    \n",
    "            predicted_membership.append(np.argmax(mpred,axis=1) )\n",
    "\n",
    "            nmpred = attack_model.predict(np.array(check_nmem_feat))    \n",
    "            predicted_nmembership.append(np.argmax(nmpred,axis=1) )        \n",
    "\n",
    "\n",
    "\n",
    "            TP_idx.append(check_mem_feat_idx[np.where(np.argmax(mpred,axis=1)==1)[0]])\n",
    "\n",
    "            TN_idx.append(check_nmem_feat_idx[np.where(np.argmax(nmpred,axis=1)==0)[0]])\n",
    "\n",
    "    pred_members = np.array([item for sublist in predicted_membership for item in sublist])\n",
    "    pred_nonmembers = np.array([item for sublist in predicted_nmembership for item in sublist])\n",
    "    \n",
    "    TP_idx_list = np.array([item for sublist in TP_idx for item in sublist])\n",
    "    TN_idx_list = np.array([item for sublist in TN_idx for item in sublist])\n",
    "    \n",
    "    members=np.array(list(pred_members))\n",
    "    nonmembers=np.array(list(pred_nonmembers))\n",
    "    \n",
    "    pred_membership = np.concatenate([members,nonmembers])\n",
    "    ori_membership = np.concatenate([np.ones(len(members)), np.zeros(len(nonmembers))])\n",
    "    \n",
    "    return pred_membership, ori_membership, TP_idx_list, TN_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a933f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_target_model(target_dataset, per_class_sample, epoch, act_layer, n_class, is_synthetic, channel=0, verbose=0, test_ratio=0.3):\n",
    "    \n",
    "    (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, test_ratio, is_synthetic)\n",
    "    target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "    #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "    history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "    score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "    _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "    print('\\n', \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "    #print('\\n', 'Model test accuracy:', score[1])\n",
    "    return target_model, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ef35632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic):\n",
    "    members = []\n",
    "    nonmembers = []\n",
    "\n",
    "    memberX, memberY, nonmemberX, nonmemberY = load_attack_test_data(attack_test_members, attack_test_nonmembers, is_synthetic)\n",
    "\n",
    "    # member\n",
    "    target_model_member_pred = target_model.predict(memberX, batch_size=32)\n",
    "    target_model_member_class = np.argmax(memberY, axis=1)\n",
    "    target_model_member_pred = np.vstack(target_model_member_pred)\n",
    "    #target_model_member_class = [item for sublist in target_model_member_class for item in sublist]\n",
    "    members.append(np.ones(len(target_model_member_pred)))\n",
    "    members = [item for sublist in members for item in sublist]\n",
    "\n",
    "\n",
    "    # nonmember\n",
    "    target_model_nonmember_pred = target_model.predict(nonmemberX, batch_size=32)\n",
    "    target_model_nonmember_class = np.argmax(nonmemberY, axis=1)\n",
    "    target_model_nonmember_pred = np.vstack(target_model_nonmember_pred)\n",
    "    #target_model_nonmember_class = [item for sublist in target_model_nonmember_class for item in sublist]\n",
    "    nonmembers.append(np.zeros(len(target_model_nonmember_pred)))\n",
    "    nonmembers = [item for sublist in nonmembers for item in sublist]\n",
    "\n",
    "    full_attack_test_pred_val = (target_model_member_pred, target_model_nonmember_pred)\n",
    "    full_attack_test_mem_status = (np.array(members).astype('int32'),np.array(nonmembers).astype('int32'))\n",
    "    full_attack_test_class_status = (np.array(target_model_member_class),np.array(target_model_nonmember_class))\n",
    "\n",
    "    print('\\n pred', full_attack_test_pred_val)\n",
    "    print('\\n class', full_attack_test_class_status)\n",
    "    print('\\n mem status', full_attack_test_mem_status)\n",
    "\n",
    "    attack_test_data = (full_attack_test_pred_val, full_attack_test_mem_status,full_attack_test_class_status)\n",
    "    \n",
    "    return attack_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3af88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Original Data--------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "efa33089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 5000, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:7000,:].sample(n = 5000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c3787688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  87.08571195602417 Target Test acc :  83.46666693687439\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5a961b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  89.20000195503235 Shadow Test acc :  83.33333134651184\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  88.82856965065002 Shadow Test acc :  83.46666693687439\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  89.2285704612732 Shadow Test acc :  82.13333487510681\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  89.14285898208618 Shadow Test acc :  81.73333406448364\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  87.82857060432434 Shadow Test acc :  78.86666655540466\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  89.85714316368103 Shadow Test acc :  83.79999995231628\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  89.94285464286804 Shadow Test acc :  82.99999833106995\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  90.20000100135803 Shadow Test acc :  81.53333067893982\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  89.3999993801117 Shadow Test acc :  83.79999995231628\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  89.02857303619385 Shadow Test acc :  82.59999752044678\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  89.05714154243469 Shadow Test acc :  81.80000185966492\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  89.20000195503235 Shadow Test acc :  83.26666951179504\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  90.34285545349121 Shadow Test acc :  81.40000104904175\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  89.31428790092468 Shadow Test acc :  81.40000104904175\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  89.34285640716553 Shadow Test acc :  84.93333458900452\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  89.9142861366272 Shadow Test acc :  82.8000009059906\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  90.48571586608887 Shadow Test acc :  82.13333487510681\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  89.68571424484253 Shadow Test acc :  81.40000104904175\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  89.28571343421936 Shadow Test acc :  84.0666651725769\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  89.48571681976318 Shadow Test acc :  83.53333473205566\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 5000\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9074b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "\n",
      " pred (array([[9.9994665e-01, 5.3302210e-05],\n",
      "       [3.4182948e-01, 6.5817058e-01],\n",
      "       [9.4589436e-01, 5.4105654e-02],\n",
      "       ...,\n",
      "       [4.6259616e-02, 9.5374036e-01],\n",
      "       [9.7471362e-01, 2.5286397e-02],\n",
      "       [2.9062511e-07, 9.9999970e-01]], dtype=float32), array([[0.00103546, 0.99896455],\n",
      "       [0.53800523, 0.46199468],\n",
      "       [0.98857766, 0.01142227],\n",
      "       ...,\n",
      "       [0.98404413, 0.01595582],\n",
      "       [0.19746764, 0.8025323 ],\n",
      "       [0.07697324, 0.9230268 ]], dtype=float32))\n",
      "\n",
      " class (array([0, 1, 1, ..., 1, 0, 1]), array([1, 1, 0, ..., 0, 1, 1]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n",
      "0\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "1\n",
      "37/37 [==============================] - 0s 1ms/step\n",
      "37/37 [==============================] - 0s 1ms/step\n",
      "TP: 4957     FP: 4835     FN: 43     TN: 165\n",
      "PPV: 0.5062\n",
      "Advantage: 0.0244\n",
      "Accuracy:  0.5122 Precision:  0.5062295751633987\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5582de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset\n",
    "target_dataset = pd.read_csv('data/adult_sds.csv', na_values=[\"?\"], header=None)\n",
    "shadow_dataset = pd.read_csv('data/adultODS10K_to_25K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_nonmembers = pd.read_csv('data/adultODS25K_to_30K.csv', na_values=[\"?\"], header=None)\n",
    "attack_test_members = pd.read_csv('data/adultODS1_to_5K.csv', na_values=[\"?\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e40d7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target Train acc :  85.14285683631897 Target Test acc :  82.73333311080933\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=3\n",
    "n_class = 2\n",
    "is_synthetic = True\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b04575b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "shadow_i_trainX =  3500 shadow_i_trainY =  3500 shadow_i_testX =  1500 shadow_i_testY =  1500\n",
      "Shadow Model  0\n",
      "Training shadow model 0\n",
      "Shadow Train acc :  89.28571343421936 Shadow Test acc :  80.53333163261414\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  1\n",
      "Training shadow model 1\n",
      "Shadow Train acc :  84.85714197158813 Shadow Test acc :  80.80000281333923\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  2\n",
      "Training shadow model 2\n",
      "Shadow Train acc :  86.77142858505249 Shadow Test acc :  83.66666436195374\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  3\n",
      "Training shadow model 3\n",
      "Shadow Train acc :  88.02857398986816 Shadow Test acc :  81.5999984741211\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  4\n",
      "Training shadow model 4\n",
      "Shadow Train acc :  86.45714521408081 Shadow Test acc :  82.33333230018616\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  5\n",
      "Training shadow model 5\n",
      "Shadow Train acc :  86.8571400642395 Shadow Test acc :  82.40000009536743\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  6\n",
      "Training shadow model 6\n",
      "Shadow Train acc :  87.74285912513733 Shadow Test acc :  79.93333339691162\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  7\n",
      "Training shadow model 7\n",
      "Shadow Train acc :  85.88571548461914 Shadow Test acc :  79.13333177566528\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  8\n",
      "Training shadow model 8\n",
      "Shadow Train acc :  87.22857236862183 Shadow Test acc :  81.5999984741211\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 2ms/step\n",
      "Shadow Model  9\n",
      "Training shadow model 9\n",
      "Shadow Train acc :  86.48571372032166 Shadow Test acc :  83.39999914169312\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  10\n",
      "Training shadow model 10\n",
      "Shadow Train acc :  87.51428723335266 Shadow Test acc :  80.46666383743286\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  11\n",
      "Training shadow model 11\n",
      "Shadow Train acc :  87.4571442604065 Shadow Test acc :  83.26666951179504\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  12\n",
      "Training shadow model 12\n",
      "Shadow Train acc :  86.57143115997314 Shadow Test acc :  80.40000200271606\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  13\n",
      "Training shadow model 13\n",
      "Shadow Train acc :  87.628573179245 Shadow Test acc :  81.33333325386047\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  14\n",
      "Training shadow model 14\n",
      "Shadow Train acc :  86.88571453094482 Shadow Test acc :  82.33333230018616\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  15\n",
      "Training shadow model 15\n",
      "Shadow Train acc :  86.51428818702698 Shadow Test acc :  80.13333082199097\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  16\n",
      "Training shadow model 16\n",
      "Shadow Train acc :  86.59999966621399 Shadow Test acc :  82.06666707992554\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  17\n",
      "Training shadow model 17\n",
      "Shadow Train acc :  87.82857060432434 Shadow Test acc :  83.66666436195374\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  18\n",
      "Training shadow model 18\n",
      "Shadow Train acc :  84.77143049240112 Shadow Test acc :  77.26666927337646\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n",
      "Shadow Model  19\n",
      "Training shadow model 19\n",
      "Shadow Train acc :  86.54285669326782 Shadow Test acc :  82.20000267028809\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#train shadow model\n",
    "n_shadow_models = 20\n",
    "shadow_data_size = 5000\n",
    "\n",
    "load_shadow_data(shadow_dataset, n_shadow_models, shadow_data_size, test_ratio, is_synthetic)\n",
    "n_shadow_train_performance, n_shadow_test_performance, n_attack_data, x_shadow_train, y_shadow_train, x_shadow_test, y_shadow_test, shadow_model_init, shadow_accuracy = train_shadow_models(n_shadow_models, n_class, dim, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a2990bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "\n",
      " pred (array([[9.9985862e-01, 1.4152995e-04],\n",
      "       [9.8442662e-01, 1.5573268e-02],\n",
      "       [9.4646138e-01, 5.3538572e-02],\n",
      "       ...,\n",
      "       [9.9994189e-01, 5.8105015e-05],\n",
      "       [9.8555994e-01, 1.4439992e-02],\n",
      "       [9.9721175e-01, 2.7883006e-03]], dtype=float32), array([[9.9999624e-01, 3.7535829e-06],\n",
      "       [2.1646561e-02, 9.7835344e-01],\n",
      "       [5.6454796e-01, 4.3545207e-01],\n",
      "       ...,\n",
      "       [8.2621348e-01, 1.7378657e-01],\n",
      "       [9.9999923e-01, 7.5641776e-07],\n",
      "       [9.9825138e-01, 1.7485529e-03]], dtype=float32))\n",
      "\n",
      " class (array([0, 0, 0, ..., 0, 0, 0]), array([0, 1, 1, ..., 0, 0, 0]))\n",
      "\n",
      " mem status (array([1, 1, 1, ..., 1, 1, 1], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32))\n",
      "0\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "117/117 [==============================] - 0s 1ms/step\n",
      "1\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "TP: 4811     FP: 4805     FN: 189     TN: 195\n",
      "PPV: 0.5003\n",
      "Advantage: 0.0012\n",
      "Accuracy:  0.5006 Precision:  0.5003119800332779\n"
     ]
    }
   ],
   "source": [
    "#train attack model\n",
    "attack_test_data = prepare_attack_test_data(attack_test_members, attack_test_nonmembers, target_model, is_synthetic)\n",
    "mem_validation, nmem_validation = prep_validation_data(attack_test_data)\n",
    "attack_train_df = prep_attack_train_data(n_attack_data)\n",
    "pred_membership, ori_membership, TP_idx_list, TN_idx_list = shokri_attack(attack_train_df, mem_validation, nmem_validation)\n",
    "tp, fp, fn, tn, precision, advj, acc, recall = prety_print_result (ori_membership,pred_membership)\n",
    "print('Accuracy: ', acc, 'Precision: ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24676932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Synthetic Data-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebc7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f5745954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with random index\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "target_dataset = data.sample(n = 10000, replace = False)\n",
    "df_rest = data.loc[~data.index.isin(target_dataset.index)]\n",
    "shadow_dataset = df_rest.sample(n = 12000, replace = False)\n",
    "df_rest = df_rest.loc[~df_rest.index.isin(shadow_dataset.index)]\n",
    "attack_test_nonmembers = df_rest.sample(n = 5000, replace = False)\n",
    "attack_test_members =  target_dataset.iloc[:7000,:].sample(n = 5000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5fd95f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_data(dataset, training_data_size, test_ratio, is_synthetic):\n",
    "    x, y, dim = transform_data(dataset, is_synthetic)\n",
    "    \n",
    "    #trainX,testX, trainY, testY = train_test_split(x, y, test_size=test_ratio, random_state=0, stratify=y)\n",
    "    trainX = x[0:training_data_size,]\n",
    "    testX = x[5000:,]\n",
    "    trainY = y[0:training_data_size,]\n",
    "    testY = y[5000:,]\n",
    "    return (trainX, trainY), (testX, testY), dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "dc02e4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_614 (Dense)           (None, 1024)              15360     \n",
      "                                                                 \n",
      " activation_456 (Activation)  (None, 1024)             0         \n",
      "                                                                 \n",
      " dense_615 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_457 (Activation)  (None, 512)              0         \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 541,186\n",
      "Trainable params: 541,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " Target Train acc :  100.0 Target Test acc :  76.39999985694885\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=2\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "target_model, dim = train_target_model(target_dataset, per_class_sample, EPS, act_layer, n_class, is_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f5f87b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Data Size:  2 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  77.52000093460083\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  54.06000018119812\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  76.16000175476074\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  24.560000002384186\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  75.91999769210815\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  75.52000284194946\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  52.99999713897705\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  75.6600022315979\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  76.48000121116638\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  77.30000019073486\n",
      "\n",
      " Training Data Size:  5 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  76.44000053405762\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  76.0200023651123\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  73.29999804496765\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  54.079997539520264\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  45.86000144481659\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  75.1200020313263\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  52.2599995136261\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  47.96000123023987\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  75.76000094413757\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  69.05999779701233\n",
      "\n",
      " Training Data Size:  10 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  67.0799970626831\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  69.6399986743927\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  75.80000162124634\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  51.9599974155426\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  70.27999758720398\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  76.57999992370605\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  70.20000219345093\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  70.99999785423279\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  73.37999939918518\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  74.80000257492065\n",
      "\n",
      " Training Data Size:  15 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  76.31999850273132\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  63.23999762535095\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  76.05999708175659\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  70.92000246047974\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  55.86000084877014\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  73.91999959945679\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  65.74000120162964\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  71.31999731063843\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  76.38000249862671\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  66.56000018119812\n",
      "\n",
      " Training Data Size:  20 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  71.74000144004822\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  72.69999980926514\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  74.76000189781189\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  65.70000052452087\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  56.58000111579895\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  73.580002784729\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  78.15999984741211\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  75.77999830245972\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  69.95999813079834\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  63.05999755859375\n",
      "\n",
      " Training Data Size:  25 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  75.08000135421753\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  78.57999801635742\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  71.49999737739563\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  73.14000129699707\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  71.17999792098999\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  73.94000291824341\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  78.35999727249146\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  74.47999715805054\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  69.95999813079834\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  77.89999842643738\n",
      "\n",
      " Training Data Size:  50 \n",
      "\n",
      "Iteration  0 Target Train acc :  100.0 Target Test acc :  75.34000277519226\n",
      "Iteration  1 Target Train acc :  100.0 Target Test acc :  73.65999817848206\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  76.75999999046326\n",
      "Iteration  3 Target Train acc :  100.0 Target Test acc :  77.4399995803833\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  69.98000144958496\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  71.61999940872192\n",
      "Iteration  6 Target Train acc :  100.0 Target Test acc :  77.5600016117096\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  79.54000234603882\n",
      "Iteration  8 Target Train acc :  100.0 Target Test acc :  77.48000025749207\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  71.60000205039978\n",
      "\n",
      " Training Data Size:  100 \n",
      "\n",
      "Iteration  0 Target Train acc :  98.00000190734863 Target Test acc :  79.86000180244446\n",
      "Iteration  1 Target Train acc :  97.00000286102295 Target Test acc :  73.68000149726868\n",
      "Iteration  2 Target Train acc :  100.0 Target Test acc :  79.68000173568726\n",
      "Iteration  3 Target Train acc :  98.00000190734863 Target Test acc :  76.92000269889832\n",
      "Iteration  4 Target Train acc :  95.99999785423279 Target Test acc :  76.45999789237976\n",
      "Iteration  5 Target Train acc :  100.0 Target Test acc :  75.62000155448914\n",
      "Iteration  6 Target Train acc :  98.00000190734863 Target Test acc :  76.16000175476074\n",
      "Iteration  7 Target Train acc :  98.00000190734863 Target Test acc :  77.6199996471405\n",
      "Iteration  8 Target Train acc :  99.00000095367432 Target Test acc :  76.74000263214111\n",
      "Iteration  9 Target Train acc :  100.0 Target Test acc :  76.88000202178955\n",
      "\n",
      " Training Data Size:  200 \n",
      "\n",
      "Iteration  0 Target Train acc :  97.50000238418579 Target Test acc :  78.29999923706055\n",
      "Iteration  1 Target Train acc :  99.50000047683716 Target Test acc :  81.51999711990356\n",
      "Iteration  2 Target Train acc :  98.00000190734863 Target Test acc :  77.84000039100647\n",
      "Iteration  3 Target Train acc :  95.99999785423279 Target Test acc :  78.07999849319458\n",
      "Iteration  4 Target Train acc :  100.0 Target Test acc :  77.84000039100647\n",
      "Iteration  5 Target Train acc :  96.49999737739563 Target Test acc :  80.83999752998352\n",
      "Iteration  6 Target Train acc :  98.50000143051147 Target Test acc :  79.19999957084656\n",
      "Iteration  7 Target Train acc :  100.0 Target Test acc :  79.54000234603882\n",
      "Iteration  8 Target Train acc :  98.00000190734863 Target Test acc :  78.14000248908997\n",
      "Iteration  9 Target Train acc :  97.50000238418579 Target Test acc :  75.77999830245972\n",
      "\n",
      " Training Data Size:  500 \n",
      "\n",
      "Iteration  0 Target Train acc :  96.60000205039978 Target Test acc :  80.62000274658203\n",
      "Iteration  1 Target Train acc :  96.79999947547913 Target Test acc :  79.36000227928162\n",
      "Iteration  2 Target Train acc :  94.40000057220459 Target Test acc :  77.06000208854675\n",
      "Iteration  3 Target Train acc :  95.59999704360962 Target Test acc :  80.09999990463257\n",
      "Iteration  4 Target Train acc :  97.60000109672546 Target Test acc :  80.73999881744385\n",
      "Iteration  5 Target Train acc :  96.60000205039978 Target Test acc :  80.94000220298767\n",
      "Iteration  6 Target Train acc :  98.19999933242798 Target Test acc :  79.47999835014343\n",
      "Iteration  7 Target Train acc :  98.60000014305115 Target Test acc :  79.86000180244446\n",
      "Iteration  8 Target Train acc :  96.79999947547913 Target Test acc :  82.09999799728394\n",
      "Iteration  9 Target Train acc :  89.60000276565552 Target Test acc :  81.9599986076355\n",
      "\n",
      " Training Data Size:  1000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 Target Train acc :  97.2000002861023 Target Test acc :  80.95999956130981\n",
      "Iteration  1 Target Train acc :  97.50000238418579 Target Test acc :  80.47999739646912\n",
      "Iteration  2 Target Train acc :  94.9999988079071 Target Test acc :  81.67999982833862\n",
      "Iteration  3 Target Train acc :  97.29999899864197 Target Test acc :  82.3199987411499\n",
      "Iteration  4 Target Train acc :  96.39999866485596 Target Test acc :  81.48000240325928\n",
      "Iteration  5 Target Train acc :  96.79999947547913 Target Test acc :  80.14000058174133\n",
      "Iteration  6 Target Train acc :  97.89999723434448 Target Test acc :  79.86000180244446\n",
      "Iteration  7 Target Train acc :  96.60000205039978 Target Test acc :  80.47999739646912\n",
      "Iteration  8 Target Train acc :  97.2000002861023 Target Test acc :  82.30000138282776\n",
      "Iteration  9 Target Train acc :  98.19999933242798 Target Test acc :  81.84000253677368\n",
      "\n",
      " Training Data Size:  2000 \n",
      "\n",
      "Iteration  0 Target Train acc :  97.39999771118164 Target Test acc :  81.08000159263611\n",
      "Iteration  1 Target Train acc :  96.74999713897705 Target Test acc :  81.49999976158142\n",
      "Iteration  2 Target Train acc :  97.79999852180481 Target Test acc :  80.86000084877014\n",
      "Iteration  3 Target Train acc :  96.39999866485596 Target Test acc :  82.05999732017517\n",
      "Iteration  4 Target Train acc :  96.45000100135803 Target Test acc :  81.98000192642212\n",
      "Iteration  5 Target Train acc :  94.84999775886536 Target Test acc :  80.59999942779541\n",
      "Iteration  6 Target Train acc :  94.70000267028809 Target Test acc :  80.95999956130981\n",
      "Iteration  7 Target Train acc :  97.29999899864197 Target Test acc :  81.49999976158142\n",
      "Iteration  8 Target Train acc :  96.74999713897705 Target Test acc :  81.45999908447266\n",
      "Iteration  9 Target Train acc :  95.24999856948853 Target Test acc :  82.17999935150146\n",
      "\n",
      " Training Data Size:  5000 \n",
      "\n",
      "Iteration  0 Target Train acc :  96.82000279426575 Target Test acc :  82.09999799728394\n",
      "Iteration  1 Target Train acc :  96.28000259399414 Target Test acc :  81.94000124931335\n",
      "Iteration  2 Target Train acc :  95.77999711036682 Target Test acc :  82.05999732017517\n",
      "Iteration  3 Target Train acc :  95.75999975204468 Target Test acc :  81.85999989509583\n",
      "Iteration  4 Target Train acc :  94.91999745368958 Target Test acc :  81.36000037193298\n",
      "Iteration  5 Target Train acc :  95.85999846458435 Target Test acc :  82.6799988746643\n",
      "Iteration  6 Target Train acc :  95.95999717712402 Target Test acc :  82.53999948501587\n",
      "Iteration  7 Target Train acc :  96.42000198364258 Target Test acc :  82.8000009059906\n",
      "Iteration  8 Target Train acc :  95.88000178337097 Target Test acc :  82.56000280380249\n",
      "Iteration  9 Target Train acc :  94.760000705719 Target Test acc :  81.01999759674072\n"
     ]
    }
   ],
   "source": [
    "# trian target model\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "#training_data_size = [2,5]\n",
    "per_class_sample=5000\n",
    "channel=0   \n",
    "EPS=200\n",
    "act_layer=2\n",
    "n_class = 2\n",
    "is_synthetic = False\n",
    "VERBOSE = 0\n",
    "test_ratio = 0.3\n",
    "\n",
    "accuracy_df = pd.DataFrame()\n",
    "accuracy_df['training data size'] = np.nan\n",
    "accuracy_df['training accuracy'] = np.nan\n",
    "accuracy_df['test accuracy'] = np.nan\n",
    "accuracy_df['error'] = np.nan\n",
    "\n",
    "data = pd.read_csv('data/adult.data', na_values=[\"?\"], header=None)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "for j in training_data_size:\n",
    "    print('\\n Training Data Size: ', j, '\\n')\n",
    "    for i in range(10):\n",
    "        target_dataset = data.sample(n = 10000, replace = False)\n",
    "        (target_trainX, target_trainY), (target_testX, target_testY), dim = load_target_data(target_dataset, j, test_ratio, is_synthetic)\n",
    "        target_model,_ = build_simple_mlp(n_class,dim, channel)\n",
    "        #get_trained_keras_models(model, (target_trainX, target_trainY), (target_testX, target_testY), num_models=1)\n",
    "        history = target_model.fit(target_trainX, target_trainY, epochs=EPS, batch_size=32, verbose=VERBOSE)\n",
    "        score = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        _, train_acc = target_model.evaluate(target_trainX, target_trainY, verbose=VERBOSE)\n",
    "        _, test_acc = target_model.evaluate(target_testX, target_testY, verbose=VERBOSE)\n",
    "        print('Iteration ', i, \"Target Train acc : \", (train_acc * 100.0),\"Target Test acc : \", (test_acc * 100.0))\n",
    "        accuracy_df = accuracy_df.append({'training data size':j, 'training accuracy' : (train_acc * 100.0), 'test accuracy': (test_acc * 100.0), 'error': ((train_acc * 100.0)-(test_acc * 100.0))}, ignore_index=True)\n",
    "        #print('\\n', 'Model test accuracy:', score[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ab049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_df.to_csv('data/adult_overfitting_test_trainsize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bb2ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df =pd.read_csv('data/adult_overfitting_test_trainsize')\n",
    "training_data_size = [2,5,10,15,20,25,50,100,200,500,1000,2000,5000]\n",
    "\n",
    "avg_error_ci95_df = pd.DataFrame()\n",
    "avg_error_ci95_df['training data size'] = np.nan\n",
    "avg_error_ci95_df['average training accuracy'] = np.nan\n",
    "avg_error_ci95_df['average test accuracy'] = np.nan\n",
    "avg_error_ci95_df['average error'] = np.nan\n",
    "avg_error_ci95_df['ci95 low'] = np.nan\n",
    "avg_error_ci95_df['ci95 high'] = np.nan\n",
    "\n",
    "for i in training_data_size:\n",
    "    error = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'error'])\n",
    "    training_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'training accuracy'])\n",
    "    test_accuracy = np.array(accuracy_df.loc[accuracy_df['training data size'] == i, 'test accuracy'])\n",
    "    ci95 = st.t.interval(alpha=0.95, df=len(error)-1, loc=np.mean(error), scale=st.sem(error))\n",
    "    row = pd.DataFrame({'training data size': [i], 'average training accuracy': \\\n",
    "            [np.mean(training_accuracy)], 'average test accuracy': [np.mean(test_accuracy)], 'average error': [np.mean(error)],\\\n",
    "                                                  'ci95 low': [ci95[0]], 'ci95 high': [ci95[1]]})\n",
    "    avg_error_ci95_df = pd.concat([avg_error_ci95_df, row], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3440b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training data size</th>\n",
       "      <th>average training accuracy</th>\n",
       "      <th>average test accuracy</th>\n",
       "      <th>average error</th>\n",
       "      <th>ci95 low</th>\n",
       "      <th>ci95 high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.618000</td>\n",
       "      <td>33.382000</td>\n",
       "      <td>20.807564</td>\n",
       "      <td>45.956435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.586000</td>\n",
       "      <td>35.414000</td>\n",
       "      <td>26.202143</td>\n",
       "      <td>44.625857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70.071999</td>\n",
       "      <td>29.928001</td>\n",
       "      <td>24.889006</td>\n",
       "      <td>34.966995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.632000</td>\n",
       "      <td>30.368000</td>\n",
       "      <td>25.542126</td>\n",
       "      <td>35.193875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70.202000</td>\n",
       "      <td>29.798000</td>\n",
       "      <td>25.076107</td>\n",
       "      <td>34.519892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>74.411999</td>\n",
       "      <td>25.588001</td>\n",
       "      <td>23.374596</td>\n",
       "      <td>27.801406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>75.098001</td>\n",
       "      <td>24.901999</td>\n",
       "      <td>22.610291</td>\n",
       "      <td>27.193708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.400001</td>\n",
       "      <td>76.962001</td>\n",
       "      <td>21.438000</td>\n",
       "      <td>20.071513</td>\n",
       "      <td>22.804486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200.0</td>\n",
       "      <td>98.150001</td>\n",
       "      <td>78.708000</td>\n",
       "      <td>19.442001</td>\n",
       "      <td>18.069303</td>\n",
       "      <td>20.814699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>96.080000</td>\n",
       "      <td>80.222000</td>\n",
       "      <td>15.858000</td>\n",
       "      <td>13.580079</td>\n",
       "      <td>18.135921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>97.010000</td>\n",
       "      <td>81.154000</td>\n",
       "      <td>15.856000</td>\n",
       "      <td>14.895328</td>\n",
       "      <td>16.816671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>96.364999</td>\n",
       "      <td>81.418000</td>\n",
       "      <td>14.946999</td>\n",
       "      <td>14.092022</td>\n",
       "      <td>15.801975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>95.844000</td>\n",
       "      <td>82.092000</td>\n",
       "      <td>13.752000</td>\n",
       "      <td>13.416115</td>\n",
       "      <td>14.087886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training data size  average training accuracy  average test accuracy  \\\n",
       "0                  2.0                 100.000000              66.618000   \n",
       "1                  5.0                 100.000000              64.586000   \n",
       "2                 10.0                 100.000000              70.071999   \n",
       "3                 15.0                 100.000000              69.632000   \n",
       "4                 20.0                 100.000000              70.202000   \n",
       "5                 25.0                 100.000000              74.411999   \n",
       "6                 50.0                 100.000000              75.098001   \n",
       "7                100.0                  98.400001              76.962001   \n",
       "8                200.0                  98.150001              78.708000   \n",
       "9                500.0                  96.080000              80.222000   \n",
       "10              1000.0                  97.010000              81.154000   \n",
       "11              2000.0                  96.364999              81.418000   \n",
       "12              5000.0                  95.844000              82.092000   \n",
       "\n",
       "    average error   ci95 low  ci95 high  \n",
       "0       33.382000  20.807564  45.956435  \n",
       "1       35.414000  26.202143  44.625857  \n",
       "2       29.928001  24.889006  34.966995  \n",
       "3       30.368000  25.542126  35.193875  \n",
       "4       29.798000  25.076107  34.519892  \n",
       "5       25.588001  23.374596  27.801406  \n",
       "6       24.901999  22.610291  27.193708  \n",
       "7       21.438000  20.071513  22.804486  \n",
       "8       19.442001  18.069303  20.814699  \n",
       "9       15.858000  13.580079  18.135921  \n",
       "10      15.856000  14.895328  16.816671  \n",
       "11      14.946999  14.092022  15.801975  \n",
       "12      13.752000  13.416115  14.087886  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_error_ci95_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Overfitting Experiment-----------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09c079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df =pd.read_csv('data/adult_overfitting_test_trainsize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ad2ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.47999907, 45.93999982, 23.83999825, 75.44      , 24.08000231,\n",
       "       24.47999716, 47.00000286, 24.33999777, 23.51999879, 22.69999981])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df.loc[accuracy_df['training data size'] == 2, 'error']\n",
    "data = np.array(accuracy_df.loc[accuracy_df['training data size'] == 2, 'error'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "275a4d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.807563944696454, 45.95643521940801)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
